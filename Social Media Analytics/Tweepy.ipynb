{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "# Import our Twitter credentials from credentials.py\n",
    "#from credentials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Screen Name:  elonmusk\n",
      "Twitter Follower Count:  23529913\n"
     ]
    }
   ],
   "source": [
    "# Import our Twitter credentials from credentials.py\n",
    "#from credentials import *\n",
    "consumer_key = 'RRqhLxEzw5RhnGjKoDRUA'\n",
    "consumer_secret ='r9t9toH1yDrVwqAOlxxUtAfteVmGYJJHp7o8xAaBM4'\n",
    "access_token = '280377182-U33H6LT1Fz0Ai5CQdzeanqGZyj19IBExuaXhmGZm'\n",
    "access_token_secret = 'hWwIxPcpypyq548eyhewMrKrTlJvkJQRvCbY4KKo5BlfO'\n",
    "# Access and authorize our Twitter credentials from credentials.py\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth)\n",
    "#user=api.me()\n",
    "user = api.get_user('elonmusk',tweet_mode=\"extended\")\n",
    "#user = api.get_user('NYTimes')\n",
    "\n",
    "print(\"Twitter Screen Name: \", user.screen_name)\n",
    "print(\"Twitter Follower Count: \", user.followers_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This user follows:\n",
      "--------------\n",
      "JimBridenstine\n",
      "universal_sci\n",
      "HardcoreHistory\n",
      "karaswisher\n",
      "Jon_Favreau\n",
      "hiromichimizuno\n",
      "QuilletteM\n",
      "Grimezsz\n",
      "NatGeo\n",
      "yousuck2020\n",
      "Teslarati\n",
      "cleantechnica\n",
      "techreview\n",
      "InsideEVs\n",
      "pmarca\n",
      "Wikipedia\n",
      "engineers_feed\n",
      "bbccomedy\n",
      "levine\n",
      "nichegamer\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThis user follows:\\n--------------\")\n",
    "for friend in user.friends():\n",
    "    print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @arcticpenguin: Was so glad to talk a little about esports: such an interesting and rapidly growing industry https://t.co/0ChBhVrPgp\n",
      "The world's largest economies by 2030:\n",
      "\n",
      "1 China üá®üá≥\n",
      "2 United States üá∫üá∏\n",
      "3 India üáÆüá≥\n",
      "4 Japan üáØüáµ\n",
      "5 Indonesia üáÆüá© \n",
      "6 Russi‚Ä¶ https://t.co/SlJYkiGeSW\n",
      "If you made a mistake, apologize.\n",
      "If you are thankful, show it. \n",
      "If you are confused, ask questions.\n",
      "If you learn s‚Ä¶ https://t.co/BiMcAJFS0C\n",
      "Marketing Review: Starbucks Unicorn Frappuccino and Instagram Influencers¬†https://t.co/kuxfb9kVX1 #marketing #smm https://t.co/7cy1C3ucY8\n",
      "RT @jesslynnrose: So, checked my Twitter interests and I am apparently interested in @anildash ...but only half as much as @yashar?\n",
      "\n",
      "Also,‚Ä¶\n",
      "Even after the latest correction, stocks aren‚Äôt cheap https://t.co/VWaKGetgS5\n",
      "9 To Find Out What Your Prospects Want to Buy https://t.co/cwwtN5EC1O\n",
      "RT @dhinchcliffe: @conversionation @Nintex @dchou1107 @S_dF @nyike @jayferro @mdkail @GNageshRao @vpfetter @tcrawford @DivergentCIO Yes, I'‚Ä¶\n",
      "Pelosi clears first hurdle to regaining House speaker role https://t.co/y6esVzsjb5\n",
      "I‚Äôm still STFR mode until we get some fresh leadership names.  That could happen soon of course\n"
     ]
    }
   ],
   "source": [
    "for tweet in tw.Cursor(api.home_timeline).items(10):\n",
    "    # Process a single status\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 1067884929302835200\n",
      "Tweeted by  AnalyticsFr\n",
      "Created at  2018-11-28 20:56:22\n",
      "Location:  IFTTT\n",
      "Tweet Text:  via @RichardEudes - Extreme Event Forecasting at Uber - with Recurrent Neural Networks https://t.co/edkfJ6BugB‚Ä¶ https://t.co/ngJQsplrGr\n",
      "-------------------------\n",
      "Tweet ID: 1067884775317389312\n",
      "Tweeted by  Kevin_Jackson\n",
      "Created at  2018-11-28 20:55:45\n",
      "Location:  Twitter for Android\n",
      "Tweet Text:  FREAK OUT!!\n",
      "\n",
      " @CHICorg @nilerodgers @intel @hpe @HPE_Discover #HPEinfluencer #HPEdiscover #HPE #cloud #hybridcloud‚Ä¶ https://t.co/DZVY9p6YEY\n",
      "-------------------------\n",
      "Tweet ID: 1067884731616788480\n",
      "Tweeted by  Team_Datalere\n",
      "Created at  2018-11-28 20:55:35\n",
      "Location:  Twitter Web Client\n",
      "Tweet Text:  Learn how the Denver Public Library improved their operations with data visibility: https://t.co/uL7bTA2Ngy‚Ä¶ https://t.co/ivWV3zDFpx\n",
      "-------------------------\n",
      "Tweet ID: 1067884731335876608\n",
      "Tweeted by  worldobigdata\n",
      "Created at  2018-11-28 20:55:34\n",
      "Location:  IFTTT\n",
      "Tweet Text:  Deep Dive into Data Commercialization at Forrester‚Äôs Data Strategy &amp; Insights event #bigdata #analytics https://t.co/u8DxoHPOtU\n",
      "-------------------------\n",
      "Tweet ID: 1067884703108276232\n",
      "Tweeted by  alternative200\n",
      "Created at  2018-11-28 20:55:28\n",
      "Location:  Twitter for Android\n",
      "Tweet Text:  RT @Fisher85M: What are the different factors for #software quality?\n",
      "\n",
      "#infosec #BigData #SMM #Analytics #UX #DevOps #OWASP #automation #CX‚Ä¶\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hash Tage search: term = '#python'\n",
    "# User search: term = '@nytimes'\n",
    "# Keyword search: term = 'data science'\n",
    "# Keyword and Sentiment: term ='data science :)' # Positive attitute\n",
    "\n",
    "term ='#analytics'\n",
    "num_tweets = 5\n",
    "\n",
    "for tweet in tw.Cursor(api.search, q=term).items(num_tweets):\n",
    "    # Process a single status\n",
    "    print(\"Tweet ID:\", tweet.id)\n",
    "    print('Tweeted by ', tweet.user.screen_name)\n",
    "    print(\"Created at \",tweet.created_at)\n",
    "    print(\"Location: \",tweet.source)\n",
    "    print('Tweet Text: ', tweet.text)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the available attributes to display by using Python dir method to perform introspection. In the following code cell we explicitly remove class methods to minimize the display list and focus on the items of interest. After this, we display the Tweet in its raw JSON format by accessing the _json attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '_max_id', '_since_id', 'append', 'clear', 'completed_in', 'copy', 'count',\n",
      "  'extend', 'ids', 'index', 'insert', 'max_id', 'next_results', 'parse', 'pop',\n",
      "  'query', 'refresh_url', 'remove', 'reverse', 'since_id', 'sort']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, depth=2, width=80, compact=True)\n",
    "\n",
    "tweets = api.search(q='elonmusk', rpp=1)\n",
    "\n",
    "pp.pprint([att for att in dir(tweets) if '__' not in att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '_api', '_json', 'author', 'contributors', 'coordinates', 'created_at',\n",
      "  'destroy', 'entities', 'favorite', 'favorite_count', 'favorited', 'geo', 'id',\n",
      "  'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id',\n",
      "  'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "  'is_quote_status', 'lang', 'metadata', 'parse', 'parse_list', 'place',\n",
      "  'quoted_status_id', 'quoted_status_id_str', 'retweet', 'retweet_count',\n",
      "  'retweeted', 'retweeted_status', 'retweets', 'source', 'source_url', 'text',\n",
      "  'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Pick a single tweet to analyze\n",
    "\n",
    "tweet = tweets[1]\n",
    "pp.pprint([att for att in dir(tweet) if '__' not in att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'contributors': None,\n",
      "  'coordinates': None,\n",
      "  'created_at': 'Wed Nov 28 20:40:33 +0000 2018',\n",
      "  'entities': { 'hashtags': [],\n",
      "                'symbols': [],\n",
      "                'urls': [],\n",
      "                'user_mentions': [...]},\n",
      "  'favorite_count': 0,\n",
      "  'favorited': False,\n",
      "  'geo': None,\n",
      "  'id': 1067880950309183490,\n",
      "  'id_str': '1067880950309183490',\n",
      "  'in_reply_to_screen_name': None,\n",
      "  'in_reply_to_status_id': None,\n",
      "  'in_reply_to_status_id_str': None,\n",
      "  'in_reply_to_user_id': None,\n",
      "  'in_reply_to_user_id_str': None,\n",
      "  'is_quote_status': True,\n",
      "  'lang': 'en',\n",
      "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
      "  'place': None,\n",
      "  'quoted_status_id': 1067173497909141504,\n",
      "  'quoted_status_id_str': '1067173497909141504',\n",
      "  'retweet_count': 6213,\n",
      "  'retweeted': False,\n",
      "  'retweeted_status': { 'contributors': None,\n",
      "                        'coordinates': None,\n",
      "                        'created_at': 'Tue Nov 27 16:37:41 +0000 2018',\n",
      "                        'entities': {...},\n",
      "                        'favorite_count': 18756,\n",
      "                        'favorited': False,\n",
      "                        'geo': None,\n",
      "                        'id': 1067457443397959680,\n",
      "                        'id_str': '1067457443397959680',\n",
      "                        'in_reply_to_screen_name': None,\n",
      "                        'in_reply_to_status_id': None,\n",
      "                        'in_reply_to_status_id_str': None,\n",
      "                        'in_reply_to_user_id': None,\n",
      "                        'in_reply_to_user_id_str': None,\n",
      "                        'is_quote_status': True,\n",
      "                        'lang': 'en',\n",
      "                        'metadata': {...},\n",
      "                        'place': None,\n",
      "                        'possibly_sensitive': False,\n",
      "                        'quoted_status': {...},\n",
      "                        'quoted_status_id': 1067173497909141504,\n",
      "                        'quoted_status_id_str': '1067173497909141504',\n",
      "                        'retweet_count': 6213,\n",
      "                        'retweeted': False,\n",
      "                        'source': '<a '\n",
      "                                  'href=\"http://twitter.com/#!/download/ipad\" '\n",
      "                                  'rel=\"nofollow\">Twitter for iPad</a>',\n",
      "                        'text': 'I‚Äôm so over the grind-til-you-die mentality\\n'\n",
      "                                '\\n'\n",
      "                                'Have a life. Go see a movie. Take your kids '\n",
      "                                'to the park. Cuddle a dog.‚Ä¶ '\n",
      "                                'https://t.co/R3B3gTuVEy',\n",
      "                        'truncated': True,\n",
      "                        'user': {...}},\n",
      "  'source': '<a href=\"http://twitter.com/download/iphone\" '\n",
      "            'rel=\"nofollow\">Twitter for iPhone</a>',\n",
      "  'text': 'RT @EvilGalProds: I‚Äôm so over the grind-til-you-die mentality\\n'\n",
      "          '\\n'\n",
      "          'Have a life. Go see a movie. Take your kids to the park. Cuddle a '\n",
      "          'dog. Read‚Ä¶',\n",
      "  'truncated': False,\n",
      "  'user': { 'contributors_enabled': False,\n",
      "            'created_at': 'Tue Jul 19 06:48:31 +0000 2016',\n",
      "            'default_profile': False,\n",
      "            'default_profile_image': False,\n",
      "            'description': 'leo | 21 | nb | KHüèù‚úßTKRBüå∏‚úßHYPMIC‚ú®| sometimes i '\n",
      "                           'draw | im such a mess and all over the place but '\n",
      "                           'im crying my best with all my heart believe it | '\n",
      "                           'ü•Çüëîüé∞üìö',\n",
      "            'entities': {...},\n",
      "            'favourites_count': 60742,\n",
      "            'follow_request_sent': False,\n",
      "            'followers_count': 356,\n",
      "            'following': False,\n",
      "            'friends_count': 878,\n",
      "            'geo_enabled': False,\n",
      "            'has_extended_profile': True,\n",
      "            'id': 755293219777224704,\n",
      "            'id_str': '755293219777224704',\n",
      "            'is_translation_enabled': False,\n",
      "            'is_translator': False,\n",
      "            'lang': 'en',\n",
      "            'listed_count': 8,\n",
      "            'location': 'Reaping/guiding souls w/ mari',\n",
      "            'name': 'hell agent shiro ‚ùÑÔ∏è‚òÉÔ∏è',\n",
      "            'notifications': False,\n",
      "            'profile_background_color': '000000',\n",
      "            'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "            'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "            'profile_background_tile': False,\n",
      "            'profile_banner_url': 'https://pbs.twimg.com/profile_banners/755293219777224704/1542934206',\n",
      "            'profile_image_url': 'http://pbs.twimg.com/profile_images/1065769412358221824/7h9sPBv8_normal.jpg',\n",
      "            'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1065769412358221824/7h9sPBv8_normal.jpg',\n",
      "            'profile_link_color': '7FDBB6',\n",
      "            'profile_sidebar_border_color': '000000',\n",
      "            'profile_sidebar_fill_color': '000000',\n",
      "            'profile_text_color': '000000',\n",
      "            'profile_use_background_image': False,\n",
      "            'protected': False,\n",
      "            'screen_name': 'reottou',\n",
      "            'statuses_count': 27405,\n",
      "            'time_zone': None,\n",
      "            'translator_type': 'none',\n",
      "            'url': 'https://t.co/E81LJBL6ce',\n",
      "            'utc_offset': None,\n",
      "            'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We can display the message data in JSON format\n",
    "\n",
    "pp.pprint(tweet._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter tracks tweet data to identify topics or people that are being frequently mentioned, which is known as trending. The Twitter API enables an application to obtain a list of currently trending topics. These topics include metadata that can be used to learn more about trending topics. One component of the metadata is the physical location of the trending topic. This location is encoded as a WOEID, which is a Yahoo developed standard that is short for where on the earth ID. In the first code cell below, we demonstrate obtaining the locations of currently trending topics before displaying these physical locations. In the second code cell, we display the complete metadata for one location, which can be used to obtain a list of trending topics for a particular location on Earth, via the WOEID. Note that since trending topics change, this Notebook will provide different results when run at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOEID Code (2972): Winnipeg, Canada\n",
      "WOEID Code (3369): Ottawa, Canada\n",
      "WOEID Code (3444): Quebec, Canada\n",
      "WOEID Code (3534): Montreal, Canada\n",
      "WOEID Code (4118): Toronto, Canada\n",
      "WOEID Code (8676): Edmonton, Canada\n",
      "WOEID Code (8775): Calgary, Canada\n",
      "WOEID Code (9807): Vancouver, Canada\n",
      "WOEID Code (12723): Birmingham, United Kingdom\n",
      "WOEID Code (12903): Blackpool, United Kingdom\n",
      "WOEID Code (13383): Bournemouth, United Kingdom\n",
      "WOEID Code (13911): Brighton, United Kingdom\n",
      "WOEID Code (13963): Bristol, United Kingdom\n",
      "WOEID Code (15127): Cardiff, United Kingdom\n",
      "WOEID Code (17044): Coventry, United Kingdom\n",
      "WOEID Code (18114): Derby, United Kingdom\n",
      "WOEID Code (19344): Edinburgh, United Kingdom\n",
      "WOEID Code (21125): Glasgow, United Kingdom\n",
      "WOEID Code (25211): Hull, United Kingdom\n",
      "WOEID Code (26042): Leeds, United Kingdom\n",
      "WOEID Code (26062): Leicester, United Kingdom\n",
      "WOEID Code (26734): Liverpool, United Kingdom\n",
      "WOEID Code (28218): Manchester, United Kingdom\n",
      "WOEID Code (28869): Middlesbrough, United Kingdom\n",
      "WOEID Code (30079): Newcastle, United Kingdom\n",
      "WOEID Code (30720): Nottingham, United Kingdom\n",
      "WOEID Code (32185): Plymouth, United Kingdom\n",
      "WOEID Code (32452): Portsmouth, United Kingdom\n",
      "WOEID Code (32566): Preston, United Kingdom\n",
      "WOEID Code (34503): Sheffield, United Kingdom\n",
      "WOEID Code (36240): Stoke-on-Trent, United Kingdom\n",
      "WOEID Code (36758): Swansea, United Kingdom\n",
      "WOEID Code (44418): London, United Kingdom\n",
      "WOEID Code (44544): Belfast, United Kingdom\n",
      "WOEID Code (76456): Santo Domingo, Dominican Republic\n",
      "WOEID Code (83123): Guatemala City, Guatemala\n",
      "WOEID Code (110978): Acapulco, Mexico\n",
      "WOEID Code (111579): Aguascalientes, Mexico\n",
      "WOEID Code (115958): Chihuahua, Mexico\n",
      "WOEID Code (116545): Mexico City, Mexico\n",
      "WOEID Code (116556): Ciudad Juarez, Mexico\n",
      "WOEID Code (116564): Nezahualc√≥yotl, Mexico\n",
      "WOEID Code (117994): Culiac√°n, Mexico\n",
      "WOEID Code (118466): Ecatepec de Morelos, Mexico\n",
      "WOEID Code (124162): Guadalajara, Mexico\n",
      "WOEID Code (124785): Hermosillo, Mexico\n",
      "WOEID Code (131068): Le√≥n, Mexico\n",
      "WOEID Code (133327): M√©rida, Mexico\n",
      "WOEID Code (133475): Mexicali, Mexico\n",
      "WOEID Code (134047): Monterrey, Mexico\n",
      "WOEID Code (134091): Morelia, Mexico\n",
      "WOEID Code (134395): Naucalpan de Ju√°rez, Mexico\n",
      "WOEID Code (137612): Puebla, Mexico\n",
      "WOEID Code (138045): Quer√©taro, Mexico\n",
      "WOEID Code (141272): Saltillo, Mexico\n",
      "WOEID Code (144265): San Luis Potos√≠, Mexico\n",
      "WOEID Code (149361): Tijuana, Mexico\n",
      "WOEID Code (149769): Toluca, Mexico\n",
      "WOEID Code (151582): Zapopan, Mexico\n",
      "WOEID Code (332471): Mendoza, Argentina\n",
      "WOEID Code (349859): Santiago, Chile\n",
      "WOEID Code (349860): Concepcion, Chile\n",
      "WOEID Code (349861): Valparaiso, Chile\n",
      "WOEID Code (368148): Bogot√°, Colombia\n",
      "WOEID Code (368149): Cali, Colombia\n",
      "WOEID Code (368150): Medell√≠n, Colombia\n",
      "WOEID Code (368151): Barranquilla, Colombia\n",
      "WOEID Code (375732): Quito, Ecuador\n",
      "WOEID Code (375733): Guayaquil, Ecuador\n",
      "WOEID Code (395269): Caracas, Venezuela\n",
      "WOEID Code (395270): Maracaibo, Venezuela\n",
      "WOEID Code (395271): Maracay, Venezuela\n",
      "WOEID Code (395272): Valencia, Venezuela\n",
      "WOEID Code (395273): Barcelona, Venezuela\n",
      "WOEID Code (395275): Ciudad Guayana, Venezuela\n",
      "WOEID Code (395277): Turmero, Venezuela\n",
      "WOEID Code (418440): Lima, Peru\n",
      "WOEID Code (455819): Bras√≠lia, Brazil\n",
      "WOEID Code (455820): Bel√©m, Brazil\n",
      "WOEID Code (455821): Belo Horizonte, Brazil\n",
      "WOEID Code (455822): Curitiba, Brazil\n",
      "WOEID Code (455823): Porto Alegre, Brazil\n",
      "WOEID Code (455824): Recife, Brazil\n",
      "WOEID Code (455825): Rio de Janeiro, Brazil\n",
      "WOEID Code (455826): Salvador, Brazil\n",
      "WOEID Code (455827): S√£o Paulo, Brazil\n",
      "WOEID Code (455828): Campinas, Brazil\n",
      "WOEID Code (455830): Fortaleza, Brazil\n",
      "WOEID Code (455831): Goi√¢nia, Brazil\n",
      "WOEID Code (455833): Manaus, Brazil\n",
      "WOEID Code (455834): S√£o Lu√≠s, Brazil\n",
      "WOEID Code (455867): Guarulhos, Brazil\n",
      "WOEID Code (466861): C√≥rdoba, Argentina\n",
      "WOEID Code (466862): Rosario, Argentina\n",
      "WOEID Code (468382): Barquisimeto, Venezuela\n",
      "WOEID Code (468384): Matur√≠n, Venezuela\n",
      "WOEID Code (468739): Buenos Aires, Argentina\n",
      "WOEID Code (493417): Gda≈Ñsk, Poland\n",
      "WOEID Code (502075): Krak√≥w, Poland\n"
     ]
    }
   ],
   "source": [
    "# Returns a JSON object that contains (a large number of) locations \n",
    "# that are currently trending.\n",
    "\n",
    "top_display = 100\n",
    "trending = api.trends_available()\n",
    "\n",
    "# We skip first value, which is entry for the World in JSON.\n",
    "for trend in trending[1:top_display]:\n",
    "    print('WOEID Code ({2:d}): {0}, {1}'.format(trend['name'], \\\n",
    "                                                trend['country'], trend['woeid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'country': 'Canada',\n",
      "  'countryCode': 'CA',\n",
      "  'name': 'Toronto',\n",
      "  'parentid': 23424775,\n",
      "  'placeType': {'code': 7, 'name': 'Town'},\n",
      "  'url': 'http://where.yahooapis.com/v1/place/4118',\n",
      "  'woeid': 4118}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(trending[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago Trends\n",
      "----------\n",
      "  #WednesdayWisdom\n",
      "  #GivingTuesday\n",
      "  Laquan McDonald\n",
      "  #ThisIsUs\n",
      "  Eddie Jackson\n",
      "  #loyola\n",
      "  #HallmarkMoviesIn5Words\n",
      "  Paul Johnson\n",
      "  New Balance\n",
      "  Liverpool\n"
     ]
    }
   ],
   "source": [
    "# We can use a WOEID to find location specific trends.\n",
    "# Here we use the WOEID for the Canada (from previous example)\n",
    "\n",
    "top_display = 10\n",
    "\n",
    "print(\"Chicago Trends\")\n",
    "print(10*'-')\n",
    "\n",
    "for trends in api.trends_place(id = 2379574):\n",
    "    for trend in trends[\"trends\"][:top_display]:\n",
    "        print(\"  {0:s}\".format(trend[\"name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the application, we will use the NLTK twitter corpus. Otherwise, we would need a separate notebook to obtain the necessary tweets (because of the twitter rate limitation). The NLTK twitter corpus includes thirty thousand tweets retrieved from the twitter streaming API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
       "       '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
       "       '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
       "       ..., '@side556 Hey!  :)  Long time no talk...',\n",
       "       '@staybubbly69 as Matt would say. WELCOME TO ADULTHOOD.... :) http://t.co/zHQy0iyaCP',\n",
       "       '@DanielOConnel18 you could say he will have egg on his face :-)'],\n",
       "      dtype='<U152')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "tws = nltk.corpus.twitter_samples\n",
    "\n",
    "pos_tweets = np.array(tws.strings('positive_tweets.json'))\n",
    "pos_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Positive Tweets\n",
      "5000 Negative Tweets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "tws = nltk.corpus.twitter_samples\n",
    "\n",
    "pos_tweets = np.array(tws.strings('positive_tweets.json'))\n",
    "neg_tweets = np.array(tws.strings('negative_tweets.json'))\n",
    "\n",
    "pos_labels = np.ones(pos_tweets.shape[0])\n",
    "neg_labels = np.zeros(neg_tweets.shape[0])\n",
    "\n",
    "targets = np.concatenate((pos_labels, neg_labels), axis=0)\n",
    "data = np.concatenate((pos_tweets, neg_tweets), axis = 0)\n",
    "\n",
    "print('{0} Positive Tweets'.format(pos_tweets.shape[0]))\n",
    "print('{0} Negative Tweets'.format(neg_tweets.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, targets, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.73      0.79      0.76      1240\n",
      "   Negative       0.78      0.71      0.74      1260\n",
      "\n",
      "avg / total       0.75      0.75      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "tools = [('cv', CountVectorizer()), ('nb', MultinomialNB())]\n",
    "pclf = Pipeline(tools)\n",
    "\n",
    "\n",
    "# Lowercase, English Stop Words, and unigrams and bigrams.\n",
    "pclf.set_params(cv__stop_words = 'english', \\\n",
    "                cv__ngram_range=(1,2), \\\n",
    "                cv__lowercase=True)\n",
    "\n",
    "pclf.fit(x_train, y_train)\n",
    "y_pred = pclf.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_tweets = np.array(tws.strings('tweets.20150430-223406.json'))\n",
    "unknown_pred = pclf.predict(unknown_tweets)\n",
    "\n",
    "unknown_pos = unknown_tweets[unknown_pred == 1]\n",
    "unknown_neg = unknown_tweets[unknown_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 tweets to classify.\n",
      "8508 tweets classified as positive.\n",
      "11492 tweets classified as negative.\n",
      "---------------------------------------------------------------------------\n",
      "Sample Positve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "\"David Cameron: smooth, smiley but unconvincing\" #bbcqt http://t.co/mJ2ZkX1TjB\n",
      "---------------------------------------------------------------------------\n",
      "Sample Negatve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "RT @DouglasDaniel: Miliband's new line 'if you don't vote Labour in Scotland I will punish you by letting the Tories in'.\n"
     ]
    }
   ],
   "source": [
    "tweet_idx = 101\n",
    "\n",
    "print('{0} tweets to classify.'.format(unknown_tweets.shape[0]))\n",
    "print('{0} tweets classified as positive.'.format(unknown_pos.shape[0]))\n",
    "print('{0} tweets classified as negative.'.format(unknown_neg.shape[0]))\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Positve Tweet:')\n",
    "print(75*'-')\n",
    "print(unknown_pos[tweet_idx])\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Negatve Tweet:')\n",
    "print(75*'-')\n",
    "print(unknown_neg[tweet_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained a sample of 91 tweets\n"
     ]
    }
   ],
   "source": [
    "newtweets = api.user_timeline(screen_name='@trump', include_rts=False, count=100)\n",
    "                           \n",
    "print('We obtained a sample of {0} tweets'.format(len(newtweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for tweet in newtweets:\n",
    "    messages.append(tweet.text)\n",
    "    \n",
    "new_tweets = np.array(messages)\n",
    "new_pred = pclf.predict(new_tweets)\n",
    "\n",
    "new_pos = new_tweets[new_pred == 1]\n",
    "new_neg = new_tweets[new_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 tweets to classify.\n",
      "71 tweets classified as positive.\n",
      "20 tweets classified as negative.\n",
      "---------------------------------------------------------------------------\n",
      "Sample Positve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      ".@WollmanRink is officially open for the 2018-2019 season! Time to lace up your skates and head to Central Park ‚õ∏Ô∏è https://t.co/Pdgx0efaPZ\n",
      "---------------------------------------------------------------------------\n",
      "Sample Negatve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "If you can't always get what you want, you must be staying somewhere else. At @TrumpLasVegas, what you want is the‚Ä¶ https://t.co/D876WyJSCB\n"
     ]
    }
   ],
   "source": [
    "tweet_idx = 6\n",
    "\n",
    "print('{0} tweets to classify.'.format(new_tweets.shape[0]))\n",
    "print('{0} tweets classified as positive.'.format(new_pos.shape[0]))\n",
    "print('{0} tweets classified as negative.'.format(new_neg.shape[0]))\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Positve Tweet:')\n",
    "print(75*'-')\n",
    "print(new_pos[tweet_idx])\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Negatve Tweet:')\n",
    "print(75*'-')\n",
    "print(new_neg[tweet_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
