{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitability - Group Project on Stock Price Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = pd.read_csv('fundamentals.csv',index_col = 0)\n",
    "price_split=pd.read_csv('prices-split-adjusted.csv')\n",
    "securities = pd.read_csv('securities.csv')\n",
    "sectors = securities['GICS Sector'].unique()\n",
    "sub_industry = securities['GICS Sub Industry'].unique()\n",
    "accounts = fundamentals.columns.values[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = fundamentals.rename(columns={'Period Ending': 'date'})\n",
    "fundamentals = fundamentals.rename(columns={'Ticker Symbol': 'symbol'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "new_data=pd.merge(fundamentals, price_split, on='date', how='left')\n",
    "new_data1=new_data[new_data[\"symbol_x\"]==new_data[\"symbol_y\"]]\n",
    "new_data1.drop(['symbol_y'], axis=1,inplace=True)\n",
    "new_data1=new_data1.rename(columns={'symbol_x':'symbol'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities=securities.rename(columns={'Ticker symbol':'symbol'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2=pd.merge(new_data1, securities, on='symbol', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the For year column again to get rid of null values\n",
    "new_data2['For Year']=new_data2.date.str.split(\"-\",expand=True,)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEC filings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEC filings\n",
       "count         1357\n",
       "unique           1\n",
       "top        reports\n",
       "freq          1357"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2[['SEC filings']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GICS Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GICS Sector\n",
       "count          1357\n",
       "unique           11\n",
       "top     Industrials\n",
       "freq            208"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2[['GICS Sector']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GICS Sub Industry\n",
       "count                       1357\n",
       "unique                       114\n",
       "top     Industrial Conglomerates\n",
       "freq                          65"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2[['GICS Sub Industry']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2.drop(['symbol'], axis=1,inplace=True)\n",
    "new_data2.drop(['date'], axis=1,inplace=True)\n",
    "new_data2.drop(['CIK'], axis=1,inplace=True)\n",
    "new_data2.drop(['SEC filings'], axis=1,inplace=True)\n",
    "new_data2.drop(['Security'], axis=1,inplace=True)\n",
    "#drop Equity Earnings/Loss Unconsolidated Subsidiary because 60% of the data is zero??\n",
    "new_data2.drop(['Equity Earnings/Loss Unconsolidated Subsidiary'], axis=1,inplace=True)\n",
    "#I believe Sector will be a stronger feature\n",
    "new_data2.drop(['GICS Sub Industry'], axis=1,inplace=True)\n",
    "new_data2.drop(['Address of Headquarters'], axis=1,inplace=True)\n",
    "new_data2.drop(['Date first added'], axis=1,inplace=True)\n",
    "#add back later\n",
    "new_data2.drop(['GICS Sector'], axis=1,inplace=True)\n",
    "new_data2.drop(['For Year'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2['PE'] = new_data2['close'] / new_data2['Earnings Per Share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing EPS valuses as zero because its possible the company wasnt public\n",
    "new_data2[['Earnings Per Share']] = new_data2[['Earnings Per Share']].fillna(value=0)\n",
    "new_data2[['PE']] = new_data2[['PE']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Total      %\n",
      "Accounts Payable                                        0   0.00\n",
      "Accounts Receivable                                     0   0.00\n",
      "Add'l income/expense items                              0   0.00\n",
      "After Tax ROE                                           0   0.00\n",
      "Capital Expenditures                                    0   0.00\n",
      "Capital Surplus                                         0   0.00\n",
      "Cash Ratio                                            272  20.04\n",
      "Cash and Cash Equivalents                               0   0.00\n",
      "Changes in Inventories                                  0   0.00\n",
      "Common Stocks                                           0   0.00\n",
      "Cost of Revenue                                         0   0.00\n",
      "Current Ratio                                         272  20.04\n",
      "Deferred Asset Charges                                  0   0.00\n",
      "Deferred Liability Charges                              0   0.00\n",
      "Depreciation                                            0   0.00\n",
      "Earnings Before Interest and Tax                        0   0.00\n",
      "Earnings Before Tax                                     0   0.00\n",
      "Effect of Exchange Rate                                 0   0.00\n",
      "Fixed Assets                                            0   0.00\n",
      "Goodwill                                                0   0.00\n",
      "Gross Margin                                            0   0.00\n",
      "Gross Profit                                            0   0.00\n",
      "Income Tax                                              0   0.00\n",
      "Intangible Assets                                       0   0.00\n",
      "Interest Expense                                        0   0.00\n",
      "Inventory                                               0   0.00\n",
      "Investments                                             0   0.00\n",
      "Liabilities                                             0   0.00\n",
      "Long-Term Debt                                          0   0.00\n",
      "Long-Term Investments                                   0   0.00\n",
      "Minority Interest                                       0   0.00\n",
      "Misc. Stocks                                            0   0.00\n",
      "Net Borrowings                                          0   0.00\n",
      "Net Cash Flow                                           0   0.00\n",
      "Net Cash Flow-Operating                                 0   0.00\n",
      "Net Cash Flows-Financing                                0   0.00\n",
      "Net Cash Flows-Investing                                0   0.00\n",
      "Net Income                                              0   0.00\n",
      "Net Income Adjustments                                  0   0.00\n",
      "Net Income Applicable to Common Shareholders            0   0.00\n",
      "Net Income-Cont. Operations                             0   0.00\n",
      "Net Receivables                                         0   0.00\n",
      "Non-Recurring Items                                     0   0.00\n",
      "Operating Income                                        0   0.00\n",
      "Operating Margin                                        0   0.00\n",
      "Other Assets                                            0   0.00\n",
      "Other Current Assets                                    0   0.00\n",
      "Other Current Liabilities                               0   0.00\n",
      "Other Equity                                            0   0.00\n",
      "Other Financing Activities                              0   0.00\n",
      "Other Investing Activities                              0   0.00\n",
      "Other Liabilities                                       0   0.00\n",
      "Other Operating Activities                              0   0.00\n",
      "Other Operating Items                                   0   0.00\n",
      "Pre-Tax Margin                                          0   0.00\n",
      "Pre-Tax ROE                                             0   0.00\n",
      "Profit Margin                                           0   0.00\n",
      "Quick Ratio                                           272  20.04\n",
      "Research and Development                                0   0.00\n",
      "Retained Earnings                                       0   0.00\n",
      "Sale and Purchase of Stock                              0   0.00\n",
      "Sales, General and Admin.                               0   0.00\n",
      "Short-Term Debt / Current Portion of Long-Term ...      0   0.00\n",
      "Short-Term Investments                                  0   0.00\n",
      "Total Assets                                            0   0.00\n",
      "Total Current Assets                                    0   0.00\n",
      "Total Current Liabilities                               0   0.00\n",
      "Total Equity                                            0   0.00\n",
      "Total Liabilities                                       0   0.00\n",
      "Total Liabilities & Equity                              0   0.00\n",
      "Total Revenue                                           0   0.00\n",
      "Treasury Stock                                          0   0.00\n",
      "Earnings Per Share                                      0   0.00\n",
      "Estimated Shares Outstanding                           83   6.12\n",
      "open                                                    0   0.00\n",
      "close                                                   0   0.00\n",
      "low                                                     0   0.00\n",
      "high                                                    0   0.00\n",
      "volume                                                  0   0.00\n",
      "PE                                                      0   0.00\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "total = new_data2.isnull().sum()\n",
    "percent_1 = new_data2.isnull().sum()/new_data2.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 2))\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from impyute.imputation.cs import fast_knn\n",
    "sys.setrecursionlimit(100000) #Increase the recursion limit of the OS\n",
    "\n",
    "# start the KNN training\n",
    "fastknn_data=fast_knn(new_data2.values, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>Changes in Inventories</th>\n",
       "      <th>Common Stocks</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.330000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.485500e+10</td>\n",
       "      <td>-367000000.0</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>3.350000e+08</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>13.680000</td>\n",
       "      <td>7005600.0</td>\n",
       "      <td>-2.410714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.175000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.674300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>1.630222e+08</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>24.629999</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>7166600.0</td>\n",
       "      <td>-2.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.768000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.265000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>7.169154e+08</td>\n",
       "      <td>53.900002</td>\n",
       "      <td>53.630001</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>10626000.0</td>\n",
       "      <td>13.340796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.085000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.099000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6.681299e+08</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>6788900.0</td>\n",
       "      <td>3.718174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.448000e+09</td>\n",
       "      <td>681000000.0</td>\n",
       "      <td>-5.400000e+07</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-4.910000e+08</td>\n",
       "      <td>3.671000e+09</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9.595000e+09</td>\n",
       "      <td>-56000000.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.879000e+10</td>\n",
       "      <td>-320000000.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>52.990002</td>\n",
       "      <td>52.810001</td>\n",
       "      <td>52.360001</td>\n",
       "      <td>53.060001</td>\n",
       "      <td>3019700.0</td>\n",
       "      <td>20.468993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accounts Payable  Accounts Receivable  Add'l income/expense items  \\\n",
       "0      3.068000e+09         -222000000.0               -1.961000e+09   \n",
       "1      4.975000e+09          -93000000.0               -2.723000e+09   \n",
       "2      4.668000e+09         -160000000.0               -1.500000e+08   \n",
       "3      5.102000e+09          352000000.0               -7.080000e+08   \n",
       "4      6.448000e+09          681000000.0               -5.400000e+07   \n",
       "\n",
       "   After Tax ROE  Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
       "0           23.0         -1.888000e+09     4.695000e+09        53.0   \n",
       "1           67.0         -3.114000e+09     1.059200e+10        75.0   \n",
       "2          143.0         -5.311000e+09     1.513500e+10        60.0   \n",
       "3          135.0         -6.151000e+09     1.159100e+10        51.0   \n",
       "4           92.0         -4.910000e+08     3.671000e+09       144.0   \n",
       "\n",
       "   Cash and Cash Equivalents  Changes in Inventories  Common Stocks  ...  \\\n",
       "0               1.330000e+09                     0.0    127000000.0  ...   \n",
       "1               2.175000e+09                     0.0      5000000.0  ...   \n",
       "2               1.768000e+09                     0.0      7000000.0  ...   \n",
       "3               1.085000e+09                     0.0      6000000.0  ...   \n",
       "4               9.595000e+09             -56000000.0     16000000.0  ...   \n",
       "\n",
       "   Total Revenue  Treasury Stock  Earnings Per Share  \\\n",
       "0   2.485500e+10    -367000000.0               -5.60   \n",
       "1   2.674300e+10             0.0              -11.25   \n",
       "2   4.265000e+10             0.0                4.02   \n",
       "3   4.099000e+10             0.0               11.39   \n",
       "4   1.879000e+10    -320000000.0                2.58   \n",
       "\n",
       "   Estimated Shares Outstanding       open      close        low       high  \\\n",
       "0                  3.350000e+08  12.850000  13.500000  12.840000  13.680000   \n",
       "1                  1.630222e+08  24.740000  25.250000  24.629999  25.250000   \n",
       "2                  7.169154e+08  53.900002  53.630001  53.320000  54.639999   \n",
       "3                  6.681299e+08  42.540001  42.349998  41.830002  42.570000   \n",
       "4                  1.600000e+09  52.990002  52.810001  52.360001  53.060001   \n",
       "\n",
       "       volume         PE  \n",
       "0   7005600.0  -2.410714  \n",
       "1   7166600.0  -2.244444  \n",
       "2  10626000.0  13.340796  \n",
       "3   6788900.0   3.718174  \n",
       "4   3019700.0  20.468993  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.DataFrame.from_records(fastknn_data, columns = new_data2.columns)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals['For Year'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['For Year']=fundamentals['For Year'].fillna(value=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add categories back\n",
    "clean_data['GICS Sector']=securities['GICS Sector']\n",
    "import category_encoders as ce\n",
    "ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n",
    "clean_data = ohe.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['trend']=np.where(new_data2['PE']>0, '1', '0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accounts Payable', 'Accounts Receivable', 'Add'l income/expense items',\n",
       "       'After Tax ROE', 'Capital Expenditures', 'Capital Surplus',\n",
       "       'Cash Ratio', 'Cash and Cash Equivalents', 'Changes in Inventories',\n",
       "       'Common Stocks', 'Cost of Revenue', 'Current Ratio',\n",
       "       'Deferred Asset Charges', 'Deferred Liability Charges', 'Depreciation',\n",
       "       'Earnings Before Interest and Tax', 'Earnings Before Tax',\n",
       "       'Effect of Exchange Rate', 'Fixed Assets', 'Goodwill', 'Gross Margin',\n",
       "       'Gross Profit', 'Income Tax', 'Intangible Assets', 'Interest Expense',\n",
       "       'Inventory', 'Investments', 'Liabilities', 'Long-Term Debt',\n",
       "       'Long-Term Investments', 'Minority Interest', 'Misc. Stocks',\n",
       "       'Net Borrowings', 'Net Cash Flow', 'Net Cash Flow-Operating',\n",
       "       'Net Cash Flows-Financing', 'Net Cash Flows-Investing', 'Net Income',\n",
       "       'Net Income Adjustments',\n",
       "       'Net Income Applicable to Common Shareholders',\n",
       "       'Net Income-Cont. Operations', 'Net Receivables', 'Non-Recurring Items',\n",
       "       'Operating Income', 'Operating Margin', 'Other Assets',\n",
       "       'Other Current Assets', 'Other Current Liabilities', 'Other Equity',\n",
       "       'Other Financing Activities', 'Other Investing Activities',\n",
       "       'Other Liabilities', 'Other Operating Activities',\n",
       "       'Other Operating Items', 'Pre-Tax Margin', 'Pre-Tax ROE',\n",
       "       'Profit Margin', 'Quick Ratio', 'Research and Development',\n",
       "       'Retained Earnings', 'Sale and Purchase of Stock',\n",
       "       'Sales, General and Admin.',\n",
       "       'Short-Term Debt / Current Portion of Long-Term Debt',\n",
       "       'Short-Term Investments', 'Total Assets', 'Total Current Assets',\n",
       "       'Total Current Liabilities', 'Total Equity', 'Total Liabilities',\n",
       "       'Total Liabilities & Equity', 'Total Revenue', 'Treasury Stock',\n",
       "       'Earnings Per Share', 'Estimated Shares Outstanding', 'open', 'close',\n",
       "       'low', 'high', 'volume', 'PE', 'For Year', 'GICS Sector_Industrials',\n",
       "       'GICS Sector_Health Care', 'GICS Sector_Information Technology',\n",
       "       'GICS Sector_Consumer Discretionary', 'GICS Sector_Utilities',\n",
       "       'GICS Sector_Financials', 'GICS Sector_Materials',\n",
       "       'GICS Sector_Consumer Staples', 'GICS Sector_Real Estate',\n",
       "       'GICS Sector_Energy', 'GICS Sector_Telecommunications Services',\n",
       "       'GICS Sector_nan', 'trend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop PE and columns directly related to profitability\n",
    "clean_data.drop(['PE'], axis=1,inplace=True)\n",
    "clean_data.drop(['Earnings Per Share'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(clean_data.loc[:, clean_data.columns != 'trend'], clean_data['trend'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 92)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample:       Accounts Payable  Accounts Receivable  Add'l income/expense items  \\\n",
      "1061      8.580000e+08        -3.300000e+07                9.100000e+07   \n",
      "235       1.936000e+09        -6.800000e+07                1.064000e+09   \n",
      "1096      2.273380e+09        -1.393800e+07                5.382500e+07   \n",
      "905       1.040800e+09        -5.700000e+07                7.000000e+06   \n",
      "715       5.939000e+08        -1.640000e+07                4.400000e+06   \n",
      "847       3.021000e+09         1.190000e+08               -1.200000e+07   \n",
      "960       1.441000e+09         1.300000e+07                7.900000e+07   \n",
      "144       1.130000e+10        -5.600000e+07                0.000000e+00   \n",
      "129       9.950000e+08        -4.600000e+07                0.000000e+00   \n",
      "749       2.476000e+09        -1.700000e+07                3.800000e+07   \n",
      "508       6.434000e+08        -6.800000e+07               -1.670000e+07   \n",
      "1305      9.180000e+08         2.900000e+07                3.800000e+07   \n",
      "1202      1.114508e+09        -1.057080e+08                0.000000e+00   \n",
      "1300      1.175000e+09         0.000000e+00                1.510000e+07   \n",
      "1278      4.395000e+08        -1.629000e+08                1.880000e+07   \n",
      "357       1.444100e+09         0.000000e+00                3.090000e+07   \n",
      "914       1.873965e+09        -1.791810e+08                0.000000e+00   \n",
      "468       4.273000e+09        -1.330000e+08                4.730000e+08   \n",
      "907       1.019000e+09        -1.600000e+07                4.800000e+07   \n",
      "252       0.000000e+00        -6.200000e+07                0.000000e+00   \n",
      "668       1.524400e+09        -4.489900e+09                2.392000e+08   \n",
      "398       8.620000e+08        -5.400000e+07                0.000000e+00   \n",
      "562       2.817600e+08        -1.731600e+07                1.035300e+07   \n",
      "580       1.504626e+09         0.000000e+00                0.000000e+00   \n",
      "1239      1.226000e+09         1.490000e+08               -7.000000e+06   \n",
      "1001      4.554200e+08         4.498100e+07                1.917100e+07   \n",
      "753       9.940000e+08         3.000000e+07               -8.800000e+07   \n",
      "1110      0.000000e+00         0.000000e+00               -1.600000e+07   \n",
      "141       7.070000e+08        -8.400000e+07                1.800000e+07   \n",
      "1031      9.996750e+08         8.026000e+06               -2.903800e+07   \n",
      "319       1.031600e+10        -2.210000e+09                0.000000e+00   \n",
      "829       6.800000e+09         2.020000e+08               -8.740000e+08   \n",
      "1337      2.338000e+09         6.700000e+07                0.000000e+00   \n",
      "513       7.560000e+08        -4.700000e+07                0.000000e+00   \n",
      "316       3.653800e+08        -2.295100e+07                7.301000e+06   \n",
      "209       1.066400e+10         6.360000e+08                0.000000e+00   \n",
      "1288      1.813000e+09         4.400000e+07               -7.400000e+07   \n",
      "728       1.778000e+09         3.900000e+07                1.800000e+07   \n",
      "627       1.300146e+09        -6.746400e+07               -2.686000e+06   \n",
      "431       3.202983e+09         8.498200e+07               -4.505000e+07   \n",
      "633       2.073500e+10        -1.407000e+09                3.330000e+08   \n",
      "456       2.341000e+09         1.080000e+08               -7.100000e+07   \n",
      "542       9.392000e+09         3.300000e+08               -1.000000e+06   \n",
      "1095      2.098916e+09        -4.815000e+06                5.007410e+08   \n",
      "1337      2.338000e+09         6.700000e+07                0.000000e+00   \n",
      "515       1.024000e+09        -2.000000e+06               -8.500000e+07   \n",
      "964       8.809950e+08        -1.822090e+08                4.489000e+06   \n",
      "792       5.553000e+08        -1.282000e+08                1.040000e+07   \n",
      "497       3.386000e+09         8.130000e+08                4.500000e+07   \n",
      "1067      7.160000e+08         6.900000e+07                8.300000e+07   \n",
      "1050      4.259020e+08        -1.070900e+07                6.200000e+05   \n",
      "621       1.940000e+08        -4.200000e+07                4.300000e+07   \n",
      "\n",
      "      After Tax ROE  Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
      "1061           11.0         -1.092000e+09     0.000000e+00    6.000000   \n",
      "235             5.0         -1.474200e+10     1.229300e+10    6.000000   \n",
      "1096           27.0         -8.412090e+08     9.217363e+09   26.106394   \n",
      "905            17.0         -2.210000e+08     3.776000e+09  186.000000   \n",
      "715            30.0         -1.032000e+08     5.295000e+08   36.000000   \n",
      "847            14.0         -5.160000e+09     6.531000e+09   55.000000   \n",
      "960             9.0         -4.833000e+09     0.000000e+00    8.000000   \n",
      "144            28.0         -1.195000e+09     1.287400e+10   69.796313   \n",
      "129            10.0         -7.300000e+07     9.450000e+09  165.000000   \n",
      "749            10.0         -1.433000e+09     1.231000e+09   56.000000   \n",
      "508             7.0         -1.237000e+08     7.197000e+09   41.000000   \n",
      "1305           34.0         -3.540000e+08     0.000000e+00  172.000000   \n",
      "1202           15.0         -8.225360e+08     0.000000e+00    3.000000   \n",
      "1300           72.0         -8.020000e+07     3.909000e+08   24.000000   \n",
      "1278           14.0         -7.252000e+08     0.000000e+00    2.000000   \n",
      "357            13.0         -5.610000e+07     2.733800e+09   37.199253   \n",
      "914             9.0         -6.679820e+08     1.883356e+09   54.000000   \n",
      "468             8.0         -5.395000e+09     0.000000e+00   23.000000   \n",
      "907             8.0         -1.600000e+08     0.000000e+00  145.000000   \n",
      "252             8.0         -9.000000e+06     1.214000e+09   47.646460   \n",
      "668            12.0         -1.245000e+08     6.197700e+09   67.000000   \n",
      "398            29.0         -9.500000e+07     2.127000e+09  110.000000   \n",
      "562            19.0         -9.859000e+07     2.023960e+08   97.000000   \n",
      "580            10.0         -5.886200e+07     7.221745e+09   69.796313   \n",
      "1239           34.0         -1.720000e+08     1.013900e+10   10.000000   \n",
      "1001           10.0         -8.895510e+08     0.000000e+00    2.000000   \n",
      "753             8.0         -7.600000e+08     1.433900e+10   44.000000   \n",
      "1110            9.0         -2.060000e+08     9.174000e+09   69.796313   \n",
      "141             9.0         -1.160000e+09     6.351000e+09    4.000000   \n",
      "1031            0.0         -1.291499e+09     3.109887e+09    8.000000   \n",
      "319            12.0         -1.984000e+09     2.977700e+10   27.000000   \n",
      "829           132.0         -1.240000e+08     5.688000e+09   35.000000   \n",
      "1337            9.0         -3.680000e+08     4.283000e+09   23.000000   \n",
      "513            18.0         -2.360000e+08     8.440000e+08   30.000000   \n",
      "316            10.0         -1.628890e+08     3.974297e+09   50.000000   \n",
      "209            10.0          0.000000e+00     5.179000e+09   66.120245   \n",
      "1288            2.0         -1.271000e+09     4.596000e+09    8.000000   \n",
      "728            13.0         -1.740000e+08     0.000000e+00   17.000000   \n",
      "627            58.0         -3.459470e+08     7.541860e+08   24.000000   \n",
      "431            16.0         -8.246805e+09     2.837150e+09   62.000000   \n",
      "633            72.0         -3.623000e+09     0.000000e+00   28.000000   \n",
      "456             8.0         -5.930000e+08     1.127100e+10   20.000000   \n",
      "542            21.0         -5.210000e+08     2.548000e+09   32.000000   \n",
      "1095           29.0         -8.024270e+08     9.175724e+09   30.400755   \n",
      "1337            9.0         -3.680000e+08     4.283000e+09   23.000000   \n",
      "515            27.0         -3.590000e+08     9.520000e+08   18.000000   \n",
      "964            28.0         -1.315040e+08     4.923196e+09  311.000000   \n",
      "792           179.0         -4.500000e+07     3.651000e+08  152.000000   \n",
      "497           155.0         -6.353000e+09     2.428300e+10    5.000000   \n",
      "1067           10.0         -2.025000e+09     5.297000e+09    2.000000   \n",
      "1050           14.0         -3.764400e+07     1.325338e+09   97.000000   \n",
      "621             1.0         -3.500000e+08     8.040000e+09   80.000000   \n",
      "\n",
      "      Cash and Cash Equivalents  Changes in Inventories  Common Stocks  ...  \\\n",
      "1061               1.370000e+08           -6.200000e+07   2.378000e+09  ...   \n",
      "235                3.980000e+08            0.000000e+00   7.000000e+06  ...   \n",
      "1096               1.691006e+09            0.000000e+00   3.100000e+04  ...   \n",
      "905                2.291000e+09            1.700000e+07   3.000000e+05  ...   \n",
      "715                2.532000e+08           -4.910000e+07   2.000000e+06  ...   \n",
      "847                2.398000e+09           -1.100000e+07   7.700000e+08  ...   \n",
      "960                4.490000e+08           -2.200000e+07   1.042100e+10  ...   \n",
      "144                2.624900e+10            0.000000e+00   2.050000e+08  ...   \n",
      "129                3.959000e+09           -7.500000e+07   0.000000e+00  ...   \n",
      "749                1.355000e+09            0.000000e+00   8.080000e+08  ...   \n",
      "508                5.176000e+08            0.000000e+00   3.800000e+06  ...   \n",
      "1305               1.580000e+09           -6.600000e+07   6.560000e+08  ...   \n",
      "1202               3.206900e+07            0.000000e+00   9.870000e+05  ...   \n",
      "1300               2.073100e+09            0.000000e+00   5.500000e+06  ...   \n",
      "1278               2.600000e+07            3.130000e+07   0.000000e+00  ...   \n",
      "357                1.393500e+09           -8.950000e+07   3.800000e+06  ...   \n",
      "914                1.024144e+09           -4.596300e+07   1.512370e+08  ...   \n",
      "468                1.776000e+09           -1.000000e+08   1.674100e+10  ...   \n",
      "907                2.868000e+09            4.900000e+07   2.912000e+09  ...   \n",
      "252                5.910000e+08            0.000000e+00   3.970000e+08  ...   \n",
      "668                2.214700e+09            0.000000e+00   9.810000e+07  ...   \n",
      "398                2.068000e+09            1.900000e+07   3.000000e+06  ...   \n",
      "562                6.804700e+08           -1.187000e+06   0.000000e+00  ...   \n",
      "580                1.409189e+10            0.000000e+00   8.131000e+06  ...   \n",
      "1239               3.790000e+08           -5.102000e+09   0.000000e+00  ...   \n",
      "1001               2.620200e+07           -2.304300e+07   2.466923e+09  ...   \n",
      "753                6.380000e+08            0.000000e+00   2.000000e+06  ...   \n",
      "1110               3.643700e+10            0.000000e+00   5.500000e+08  ...   \n",
      "141                6.600000e+07            0.000000e+00   2.000000e+06  ...   \n",
      "1031               3.105090e+08           -1.645000e+06   2.291000e+06  ...   \n",
      "319                4.089000e+09            1.200000e+07   1.700000e+07  ...   \n",
      "829                2.900000e+09            3.300000e+07   9.350000e+08  ...   \n",
      "1337               1.411000e+09           -2.200000e+07   1.124000e+09  ...   \n",
      "513                4.000000e+08            0.000000e+00   4.000000e+06  ...   \n",
      "316                2.807400e+08           -5.591000e+06   2.910000e+05  ...   \n",
      "209                6.150000e+08            0.000000e+00   9.591000e+09  ...   \n",
      "1288               5.800000e+07            0.000000e+00   6.000000e+06  ...   \n",
      "728                4.420000e+08            0.000000e+00   5.799000e+09  ...   \n",
      "627                3.748540e+08           -8.849700e+07   3.599010e+08  ...   \n",
      "431                2.087213e+09           -1.619580e+08   2.054920e+08  ...   \n",
      "633                1.071600e+10           -5.700000e+07   5.159400e+10  ...   \n",
      "456                5.770000e+08            1.660000e+08   5.000000e+06  ...   \n",
      "542                4.388000e+09           -3.030000e+08   4.820000e+08  ...   \n",
      "1095               1.184518e+09            0.000000e+00   3.100000e+04  ...   \n",
      "1337               1.411000e+09           -2.200000e+07   1.124000e+09  ...   \n",
      "515                2.750000e+08            0.000000e+00   4.000000e+06  ...   \n",
      "964                3.149494e+09            0.000000e+00   4.800000e+05  ...   \n",
      "792                1.755400e+09            0.000000e+00   3.400000e+06  ...   \n",
      "497                2.240000e+08            3.790000e+08   1.370000e+08  ...   \n",
      "1067               9.400000e+07            8.000000e+07   1.000000e+06  ...   \n",
      "1050               6.104300e+08            6.349000e+06   1.021000e+06  ...   \n",
      "621                4.530000e+08            0.000000e+00   7.000000e+06  ...   \n",
      "\n",
      "      GICS Sector_Consumer Discretionary  GICS Sector_Utilities  \\\n",
      "1061                                   0                      0   \n",
      "235                                    0                      0   \n",
      "1096                                   0                      0   \n",
      "905                                    0                      0   \n",
      "715                                    0                      0   \n",
      "847                                    0                      0   \n",
      "960                                    0                      0   \n",
      "144                                    1                      0   \n",
      "129                                    0                      0   \n",
      "749                                    0                      0   \n",
      "508                                    0                      0   \n",
      "1305                                   0                      0   \n",
      "1202                                   0                      0   \n",
      "1300                                   0                      0   \n",
      "1278                                   0                      0   \n",
      "357                                    0                      0   \n",
      "914                                    0                      0   \n",
      "468                                    0                      0   \n",
      "907                                    0                      0   \n",
      "252                                    0                      0   \n",
      "668                                    0                      0   \n",
      "398                                    0                      1   \n",
      "562                                    0                      0   \n",
      "580                                    0                      0   \n",
      "1239                                   0                      0   \n",
      "1001                                   0                      0   \n",
      "753                                    0                      0   \n",
      "1110                                   0                      0   \n",
      "141                                    0                      0   \n",
      "1031                                   0                      0   \n",
      "319                                    0                      0   \n",
      "829                                    0                      0   \n",
      "1337                                   0                      0   \n",
      "513                                    0                      0   \n",
      "316                                    0                      0   \n",
      "209                                    1                      0   \n",
      "1288                                   0                      0   \n",
      "728                                    0                      0   \n",
      "627                                    0                      0   \n",
      "431                                    0                      0   \n",
      "633                                    0                      0   \n",
      "456                                    1                      0   \n",
      "542                                    0                      0   \n",
      "1095                                   0                      0   \n",
      "1337                                   0                      0   \n",
      "515                                    0                      0   \n",
      "964                                    0                      0   \n",
      "792                                    0                      0   \n",
      "497                                    0                      0   \n",
      "1067                                   0                      0   \n",
      "1050                                   0                      0   \n",
      "621                                    0                      0   \n",
      "\n",
      "      GICS Sector_Financials  GICS Sector_Materials  \\\n",
      "1061                       0                      0   \n",
      "235                        1                      0   \n",
      "1096                       0                      0   \n",
      "905                        0                      0   \n",
      "715                        0                      0   \n",
      "847                        0                      0   \n",
      "960                        0                      0   \n",
      "144                        0                      0   \n",
      "129                        0                      0   \n",
      "749                        0                      0   \n",
      "508                        0                      0   \n",
      "1305                       0                      0   \n",
      "1202                       0                      0   \n",
      "1300                       0                      0   \n",
      "1278                       0                      0   \n",
      "357                        0                      0   \n",
      "914                        0                      0   \n",
      "468                        0                      0   \n",
      "907                        0                      0   \n",
      "252                        0                      0   \n",
      "668                        0                      0   \n",
      "398                        0                      0   \n",
      "562                        0                      0   \n",
      "580                        0                      0   \n",
      "1239                       0                      0   \n",
      "1001                       0                      0   \n",
      "753                        0                      0   \n",
      "1110                       0                      0   \n",
      "141                        1                      0   \n",
      "1031                       0                      0   \n",
      "319                        0                      0   \n",
      "829                        0                      0   \n",
      "1337                       0                      0   \n",
      "513                        0                      0   \n",
      "316                        0                      0   \n",
      "209                        0                      0   \n",
      "1288                       0                      0   \n",
      "728                        0                      0   \n",
      "627                        0                      0   \n",
      "431                        0                      0   \n",
      "633                        0                      0   \n",
      "456                        0                      0   \n",
      "542                        0                      0   \n",
      "1095                       0                      0   \n",
      "1337                       0                      0   \n",
      "515                        0                      0   \n",
      "964                        0                      0   \n",
      "792                        0                      0   \n",
      "497                        0                      0   \n",
      "1067                       0                      0   \n",
      "1050                       0                      0   \n",
      "621                        0                      0   \n",
      "\n",
      "      GICS Sector_Consumer Staples  GICS Sector_Real Estate  \\\n",
      "1061                             0                        0   \n",
      "235                              0                        0   \n",
      "1096                             0                        0   \n",
      "905                              0                        0   \n",
      "715                              0                        0   \n",
      "847                              0                        0   \n",
      "960                              0                        0   \n",
      "144                              0                        0   \n",
      "129                              0                        0   \n",
      "749                              0                        0   \n",
      "508                              0                        0   \n",
      "1305                             0                        0   \n",
      "1202                             0                        0   \n",
      "1300                             0                        0   \n",
      "1278                             0                        0   \n",
      "357                              1                        0   \n",
      "914                              0                        0   \n",
      "468                              0                        0   \n",
      "907                              0                        0   \n",
      "252                              1                        0   \n",
      "668                              0                        0   \n",
      "398                              0                        0   \n",
      "562                              0                        0   \n",
      "580                              0                        0   \n",
      "1239                             0                        0   \n",
      "1001                             0                        0   \n",
      "753                              0                        0   \n",
      "1110                             0                        0   \n",
      "141                              0                        0   \n",
      "1031                             0                        0   \n",
      "319                              0                        0   \n",
      "829                              0                        0   \n",
      "1337                             0                        0   \n",
      "513                              0                        0   \n",
      "316                              0                        0   \n",
      "209                              0                        0   \n",
      "1288                             0                        0   \n",
      "728                              0                        0   \n",
      "627                              0                        0   \n",
      "431                              0                        0   \n",
      "633                              0                        0   \n",
      "456                              0                        0   \n",
      "542                              0                        0   \n",
      "1095                             0                        0   \n",
      "1337                             0                        0   \n",
      "515                              0                        0   \n",
      "964                              0                        0   \n",
      "792                              0                        0   \n",
      "497                              0                        0   \n",
      "1067                             0                        0   \n",
      "1050                             0                        0   \n",
      "621                              0                        0   \n",
      "\n",
      "      GICS Sector_Energy  GICS Sector_Telecommunications Services  \\\n",
      "1061                   0                                        0   \n",
      "235                    0                                        0   \n",
      "1096                   0                                        0   \n",
      "905                    0                                        0   \n",
      "715                    0                                        0   \n",
      "847                    0                                        0   \n",
      "960                    0                                        0   \n",
      "144                    0                                        0   \n",
      "129                    0                                        0   \n",
      "749                    0                                        0   \n",
      "508                    0                                        0   \n",
      "1305                   0                                        0   \n",
      "1202                   0                                        0   \n",
      "1300                   0                                        0   \n",
      "1278                   0                                        0   \n",
      "357                    0                                        0   \n",
      "914                    0                                        0   \n",
      "468                    0                                        0   \n",
      "907                    0                                        0   \n",
      "252                    0                                        0   \n",
      "668                    0                                        0   \n",
      "398                    0                                        0   \n",
      "562                    0                                        0   \n",
      "580                    0                                        0   \n",
      "1239                   0                                        0   \n",
      "1001                   0                                        0   \n",
      "753                    0                                        0   \n",
      "1110                   0                                        0   \n",
      "141                    0                                        0   \n",
      "1031                   0                                        0   \n",
      "319                    1                                        0   \n",
      "829                    0                                        0   \n",
      "1337                   0                                        0   \n",
      "513                    0                                        0   \n",
      "316                    1                                        0   \n",
      "209                    0                                        0   \n",
      "1288                   0                                        0   \n",
      "728                    0                                        0   \n",
      "627                    0                                        0   \n",
      "431                    0                                        0   \n",
      "633                    0                                        0   \n",
      "456                    0                                        0   \n",
      "542                    0                                        0   \n",
      "1095                   0                                        0   \n",
      "1337                   0                                        0   \n",
      "515                    0                                        0   \n",
      "964                    0                                        0   \n",
      "792                    0                                        0   \n",
      "497                    0                                        0   \n",
      "1067                   0                                        0   \n",
      "1050                   0                                        0   \n",
      "621                    0                                        0   \n",
      "\n",
      "      GICS Sector_nan  trend  \n",
      "1061                1      1  \n",
      "235                 0      0  \n",
      "1096                1      1  \n",
      "905                 1      1  \n",
      "715                 1      1  \n",
      "847                 1      1  \n",
      "960                 1      1  \n",
      "144                 0      0  \n",
      "129                 0      1  \n",
      "749                 1      1  \n",
      "508                 1      1  \n",
      "1305                1      1  \n",
      "1202                1      1  \n",
      "1300                1      1  \n",
      "1278                1      1  \n",
      "357                 0      1  \n",
      "914                 1      1  \n",
      "468                 0      1  \n",
      "907                 1      1  \n",
      "252                 0      1  \n",
      "668                 1      1  \n",
      "398                 0      1  \n",
      "562                 1      1  \n",
      "580                 1      1  \n",
      "1239                1      1  \n",
      "1001                1      1  \n",
      "753                 1      0  \n",
      "1110                1      1  \n",
      "141                 0      1  \n",
      "1031                1      1  \n",
      "319                 0      1  \n",
      "829                 1      1  \n",
      "1337                1      1  \n",
      "513                 1      1  \n",
      "316                 0      1  \n",
      "209                 0      1  \n",
      "1288                1      1  \n",
      "728                 1      1  \n",
      "627                 1      0  \n",
      "431                 0      1  \n",
      "633                 1      1  \n",
      "456                 0      1  \n",
      "542                 1      1  \n",
      "1095                1      1  \n",
      "1337                1      1  \n",
      "515                 1      1  \n",
      "964                 1      1  \n",
      "792                 1      1  \n",
      "497                 0      0  \n",
      "1067                1      1  \n",
      "1050                1      1  \n",
      "621                 1      1  \n",
      "\n",
      "[52 rows x 92 columns]\n",
      "OOB Sample: []\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn bootstrap\n",
    "from sklearn.utils import resample\n",
    "\n",
    "boot = resample(clean_data, replace=True, n_samples=51, random_state=1)\n",
    "print('Bootstrap Sample: %s' % boot)\n",
    "\n",
    "oob = [x for x in clean_data if x not in boot]\n",
    "print('OOB Sample: %s' % oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 92)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean.append(boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409, 92)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(clean.loc[:, clean.columns != 'trend'], \n",
    "                                                    clean['trend'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 91.48\n",
      "Accuracy score (test): 91.02\n"
     ]
    }
   ],
   "source": [
    "#lbfgs would not converge\n",
    "#For small datasets, â€˜liblinearâ€™ is a good choice, whereas â€˜sagâ€™ and â€˜sagaâ€™ are faster for large ones.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "log_model = logreg.fit(X_train, Y_train)\n",
    "\n",
    "log_Y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_log = round(logreg.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_log)\n",
    "print(\"Accuracy score (test):\",test_acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Test Accuracy: 0.71 | ROC Test Error: 0.29\n",
      "ROC Train Accuracy: 0.70 | ROC Train Error: 0.30\n",
      "OVERFIT: False\n",
      "UNDERFIT: True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model=logreg\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "test_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "train_accuracy = roc_auc_score(Y_test, log_Y_pred)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def calc_train_error(X_train, y_train, model):\n",
    "    '''returns in-sample error for already fit model.'''\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = MSE(y_train, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "    \n",
    "def calc_validation_error(X_test, y_test, model):\n",
    "    '''returns out-of-sample error for already fit model.'''\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = MSE(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calc_cv_error(X_train, Y_train, model):\n",
    "    mse = - cross_val_score(model, X_train, Y_train, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1)\n",
    "    \n",
    "    rmse = float((mse.mean())**(1/2))\n",
    "    return rmse\n",
    "    \n",
    "def calc_metrics(X_train, y_train, X_test, y_test, model):\n",
    "    '''fits model and returns the RMSE for in-sample error and out-of-sample error'''\n",
    "    model.fit(X_train, y_train)\n",
    "    train_error = calc_train_error(X_train, y_train, model)\n",
    "    validation_error = calc_validation_error(X_test, y_test, model)\n",
    "    cv_error = calc_cv_error(X_test, y_test, model)\n",
    "    return train_error, validation_error, cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 91.78\n",
      "Accuracy score (test): 87.75\n"
     ]
    }
   ],
   "source": [
    "#lbfgs would not converge\n",
    "#For small datasets, â€˜liblinearâ€™ is a good choice, whereas â€˜sagâ€™ and â€˜sagaâ€™ are faster for large ones.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "log_model = logreg.fit(X_train, Y_train)\n",
    "\n",
    "log_Y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_log = round(logreg.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_log)\n",
    "print(\"Accuracy score (test):\",test_acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.29 | test error: 0.35\n",
      "CV error: 0.38\n",
      "train/test: 1.2\n"
     ]
    }
   ],
   "source": [
    "model=logreg\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "lr_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 30, 'n_neighbors': 5, 'p': 1}\n",
      "0.8914646996838778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_neighbors': [2, 5, 10, 50, 100],\n",
    "    'p' : [1, 2],\n",
    "    'leaf_size' :[30,50]\n",
    "}\n",
    "\n",
    "knn_CV = GridSearchCV(estimator=knn, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "knn_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(knn_CV.best_params_)\n",
    "print(knn_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 91.46\n",
      "Accuracy score (test): 89.95\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=30, n_neighbors=5, p=2) \n",
    "knn_model = knn.fit(X_train, Y_train)  \n",
    "knn_Y_pred = knn.predict(X_test)  \n",
    "\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_knn = round(knn.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_knn)\n",
    "print(\"Accuracy score (test):\",test_acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.29 | test error: 0.32\n",
      "CV error: 0.32\n",
      "train/test: 1.1\n"
     ]
    }
   ],
   "source": [
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data\n",
    "\n",
    "model=knn\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "knn_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 30.14\n",
      "Accuracy score (test): 23.53\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian_model = gaussian.fit(X_train, Y_train) \n",
    "\n",
    "gaussian_Y_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_gaussian = round(gaussian.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_gaussian)\n",
    "print(\"Accuracy score (test):\",test_acc_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.84 | test error: 0.87\n",
      "CV error: 0.84\n",
      "train/test: 1.0\n"
     ]
    }
   ],
   "source": [
    "model=gaussian\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "gaussian_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 89.71\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "svc_model = svc.fit(X_train, Y_train)\n",
    "\n",
    "svc_Y_pred = svc.predict(X_test)\n",
    "\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_svc = round(svc.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_svc)\n",
    "print(\"Accuracy score (test):\",test_acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.00 | test error: 0.32\n",
      "CV error: 0.32\n",
      "train/test: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model=svc\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "svc_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5}\n",
      "0.946259220231823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : depths,\n",
    "    'min_samples_leaf' :[1, 5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "decision_tree_CV = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "decision_tree_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(decision_tree_CV.best_params_)\n",
    "print(decision_tree_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 96.42\n",
      "Accuracy score (test): 94.85\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=5) \n",
    "decision_tree_model = decision_tree.fit(X_train, Y_train)  \n",
    "decision_tree_Y_pred = decision_tree.predict(X_test)  \n",
    "\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_decision_tree = round(decision_tree.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_decision_tree)\n",
    "print(\"Accuracy score (test):\",test_acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.19 | test error: 0.24\n",
      "CV error: 0.27\n",
      "train/test: 1.3\n"
     ]
    }
   ],
   "source": [
    "model=decision_tree\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "dt_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 91.18\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=decision_tree, n_estimators=180, random_state=1)\n",
    "ada_model = ada.fit(X_train, Y_train)\n",
    "\n",
    "ada_Y_pred = ada.predict(X_test)\n",
    "\n",
    "acc_ada = round(ada.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_ada = round(ada.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_ada)\n",
    "print(\"Accuracy score (test):\",test_acc_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.00 | test error: 0.30\n",
      "CV error: 0.32\n",
      "train/test: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "model=ada\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "ada_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 94.94\n",
      "Accuracy score (test): 90.93\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n",
    "    gt_model = gb.fit(X_train, Y_train)\n",
    "    \n",
    "    acc_gb = round(gb.score(X_train, Y_train) * 100, 2)\n",
    "    test_acc_gb = round(gb.score(X_test, Y_test) * 100, 2)\n",
    "    \n",
    "    gb_Y_pred = gb.predict(X_test)\n",
    "    \n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training):\",acc_gb)\n",
    "print(\"Accuracy score (test):\",test_acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.22 | test error: 0.30\n",
      "CV error: 0.36\n",
      "train/test: 1.3\n"
     ]
    }
   ],
   "source": [
    "model=gb\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "gb_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.9420442571127503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : depths,\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "rf_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(rf_CV.best_params_)\n",
    "print(rf_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 99.58\n",
      "Accuracy score (test): 95.1\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='entropy', max_depth=11, max_features='auto', n_estimators=200)\n",
    "random_forest_model = random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_random_forest = round(random_forest.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_random_forest)\n",
    "print(\"Accuracy score (test):\",test_acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.06 | test error: 0.22\n",
      "CV error: 0.23\n",
      "train/test: 3.4\n"
     ]
    }
   ],
   "source": [
    "model=random_forest\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "rf_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".22 > .06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Net Income Applicable to Common Shareholders</th>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income</th>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earnings Before Tax</th>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income-Cont. Operations</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earnings Before Interest and Tax</th>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income Tax</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operating Income</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income Adjustments</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Operating Activities</th>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Recurring Items</th>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retained Earnings</th>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              importance\n",
       "feature                                                 \n",
       "Net Income Applicable to Common Shareholders       0.078\n",
       "Net Income                                         0.076\n",
       "Earnings Before Tax                                0.059\n",
       "Net Income-Cont. Operations                        0.055\n",
       "Earnings Before Interest and Tax                   0.048\n",
       "Estimated Shares Outstanding                       0.032\n",
       "Income Tax                                         0.022\n",
       "Operating Income                                   0.020\n",
       "Cash and Cash Equivalents                          0.018\n",
       "volume                                             0.016\n",
       "Net Income Adjustments                             0.015\n",
       "Total Liabilities & Equity                         0.015\n",
       "Other Operating Activities                         0.013\n",
       "Non-Recurring Items                                0.013\n",
       "Retained Earnings                                  0.013"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier()\n",
    "sgd.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.8788198103266597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "sgd_CV = GridSearchCV(estimator=sgd, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "sgd_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(sgd_CV.best_params_)\n",
    "print(sgd_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 89.46\n",
      "Accuracy score (test): 89.46\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier(loss='squared_hinge', penalty='l2',max_iter=1000)\n",
    "sgd_model = sgd.fit(X_train, Y_train)\n",
    "sgd_Y_pred = sgd.predict(X_test)\n",
    "\n",
    "sgd.score(X_train, Y_train)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_sgd = round(sgd.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_sgd)\n",
    "print(\"Accuracy score (test):\",test_acc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.35 | test error: 0.34\n",
      "CV error: 0.42\n",
      "train/test: 1.0\n"
     ]
    }
   ],
   "source": [
    "model=sgd\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "sgd_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 88.2\n",
      "Accuracy score (test): 89.71\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(max_iter=5)\n",
    "perceptron_model = perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_Y_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_perceptron = round(perceptron.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_perceptron)\n",
    "print(\"Accuracy score (test):\",test_acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.34 | test error: 0.32\n",
      "CV error: 0.37\n",
      "train/test: 0.9\n"
     ]
    }
   ],
   "source": [
    "model=perceptron\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "perceptron_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95.10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94.85</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.95</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.71</th>\n",
       "      <td>Support Vector Classifier (SVC)</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91.18</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.93</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.75</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.71</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.46</th>\n",
       "      <td>Stochastic Gradient Descent (SGD)</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.53</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  CV Error\n",
       "Score                                             \n",
       "95.10                      Random Forest      0.23\n",
       "94.85                     Decision Trees      0.27\n",
       "89.95                K-Nearest Neighbors      0.32\n",
       "89.71    Support Vector Classifier (SVC)      0.32\n",
       "91.18                           AdaBoost      0.32\n",
       "90.93             Gradient Tree Boosting      0.36\n",
       "87.75                Logistic Regression      0.37\n",
       "89.71                         Perceptron      0.37\n",
       "89.46  Stochastic Gradient Descent (SGD)      0.42\n",
       "23.53               Gaussian Naive Bayes      0.84"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression','K-Nearest Neighbors',\n",
    "             'Gaussian Naive Bayes','Support Vector Classifier (SVC)',\n",
    "             'Decision Trees','AdaBoost','Gradient Tree Boosting',\n",
    "             'Random Forest','Stochastic Gradient Descent (SGD)','Perceptron'],\n",
    "    'Score': [test_acc_log,\n",
    "              test_acc_knn,\n",
    "              test_acc_gaussian,\n",
    "              test_acc_svc,\n",
    "              test_acc_decision_tree,\n",
    "              test_acc_ada,\n",
    "              test_acc_gb,\n",
    "              test_acc_random_forest,\n",
    "              test_acc_sgd,\n",
    "              test_acc_perceptron],\n",
    "    'CV Error': [round(lr_cv_error, 2),\n",
    "                round(knn_cv_error, 2),\n",
    "                round(gaussian_cv_error, 2),\n",
    "                round(svc_cv_error, 2),\n",
    "                round(dt_cv_error, 2),\n",
    "                round(ada_cv_error, 2),\n",
    "                round(gb_cv_error, 2),\n",
    "                round(rf_cv_error, 2),\n",
    "                round(sgd_cv_error, 2),\n",
    "                round(perceptron_cv_error, 2)\n",
    "                ]})\n",
    "result_df = results.sort_values(by='CV Error', ascending=True)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_data2=clean_data.copy()\n",
    "#temp dropping trend\n",
    "clean_data2.drop(['trend'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fit_pca(df, n_components):\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(df)   \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    stscaler = StandardScaler().fit(df)\n",
    "    scaled = stscaler.transform(df)    \n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaled = standardize(clean_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = fit_pca(scaled, n_components=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Dataset Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "24.0%:     0.18 * f1 +  0.02 * f2 +  0.06 * f3 + -0.01 * f4 + -0.12 * f5 +  0.13 * f6 + -0.01 * f7 +  0.15 * f8 + -0.03 * f9 +  0.10 * f10 +  0.11 * f11 + -0.02 * f12 +  0.04 * f13 +  0.11 * f14 +  0.14 * f15 +  0.20 * f16 +  0.18 * f17 + -0.09 * f18 +  0.12 * f19 +  0.14 * f20 + -0.01 * f21 +  0.17 * f22 +  0.17 * f23 +  0.08 * f24 +  0.15 * f25 +  0.07 * f26 + -0.09 * f27 +  0.00 * f28 +  0.15 * f29 +  0.15 * f30 +  0.10 * f31 +  0.01 * f32 + -0.03 * f33 + -0.01 * f34 +  0.18 * f35 +  0.00 * f36 + -0.12 * f37 +  0.18 * f38 + -0.02 * f39 +  0.18 * f40 +  0.18 * f41 +  0.15 * f42 +  0.05 * f43 +  0.16 * f44 + -0.02 * f45 +  0.09 * f46 +  0.08 * f47 +  0.14 * f48 + -0.07 * f49 +  0.09 * f50 + -0.01 * f51 +  0.04 * f52 +  0.05 * f53 +  0.11 * f54 + -0.01 * f55 + -0.01 * f56 + -0.01 * f57 + -0.01 * f58 +  0.05 * f59 +  0.17 * f60 + -0.09 * f61 +  0.19 * f62 +  0.15 * f63 +  0.06 * f64 +  0.17 * f65 +  0.10 * f66 +  0.12 * f67 +  0.20 * f68 +  0.16 * f69 +  0.17 * f70 +  0.16 * f71 + -0.11 * f72 +  0.16 * f73 + -0.01 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 +  0.12 * f78 + -0.01 * f79 + -0.00 * f80 + -0.01 * f81 + -0.00 * f82\n",
      "10.0%:    -0.11 * f1 + -0.04 * f2 +  0.09 * f3 + -0.00 * f4 + -0.19 * f5 + -0.07 * f6 + -0.03 * f7 + -0.22 * f8 + -0.08 * f9 + -0.08 * f10 +  0.19 * f11 + -0.03 * f12 +  0.01 * f13 +  0.18 * f14 +  0.14 * f15 +  0.05 * f16 +  0.09 * f17 +  0.05 * f18 +  0.19 * f19 + -0.04 * f20 + -0.02 * f21 +  0.12 * f22 +  0.11 * f23 +  0.08 * f24 + -0.16 * f25 +  0.15 * f26 +  0.14 * f27 + -0.01 * f28 + -0.13 * f29 + -0.23 * f30 + -0.06 * f31 +  0.02 * f32 +  0.12 * f33 + -0.01 * f34 +  0.01 * f35 + -0.10 * f36 +  0.07 * f37 +  0.08 * f38 +  0.07 * f39 +  0.09 * f40 +  0.10 * f41 + -0.02 * f42 + -0.05 * f43 +  0.14 * f44 + -0.02 * f45 + -0.13 * f46 +  0.14 * f47 + -0.23 * f48 + -0.07 * f49 + -0.16 * f50 + -0.04 * f51 + -0.03 * f52 + -0.09 * f53 +  0.06 * f54 + -0.04 * f55 + -0.00 * f56 + -0.04 * f57 + -0.03 * f58 +  0.08 * f59 +  0.09 * f60 + -0.14 * f61 + -0.01 * f62 + -0.20 * f63 +  0.05 * f64 + -0.19 * f65 +  0.19 * f66 +  0.21 * f67 + -0.08 * f68 + -0.21 * f69 + -0.19 * f70 +  0.15 * f71 + -0.16 * f72 + -0.01 * f73 +  0.03 * f74 +  0.03 * f75 +  0.03 * f76 +  0.03 * f77 + -0.07 * f78 + -0.00 * f79 + -0.01 * f80 + -0.01 * f81 +  0.01 * f82\n",
      " 4.9%:     0.02 * f1 + -0.06 * f2 +  0.02 * f3 +  0.02 * f4 +  0.05 * f5 + -0.03 * f6 +  0.24 * f7 +  0.03 * f8 + -0.03 * f9 +  0.01 * f10 + -0.02 * f11 +  0.22 * f12 + -0.04 * f13 + -0.06 * f14 + -0.05 * f15 +  0.04 * f16 +  0.05 * f17 +  0.01 * f18 + -0.06 * f19 + -0.02 * f20 +  0.08 * f21 + -0.00 * f22 +  0.05 * f23 + -0.04 * f24 + -0.04 * f25 +  0.00 * f26 + -0.07 * f27 +  0.05 * f28 + -0.03 * f29 +  0.01 * f30 + -0.00 * f31 + -0.01 * f32 +  0.07 * f33 +  0.02 * f34 +  0.00 * f35 +  0.09 * f36 + -0.07 * f37 +  0.05 * f38 + -0.06 * f39 +  0.05 * f40 +  0.05 * f41 + -0.01 * f42 + -0.05 * f43 +  0.03 * f44 +  0.06 * f45 + -0.02 * f46 + -0.05 * f47 +  0.02 * f48 + -0.00 * f49 +  0.07 * f50 + -0.00 * f51 + -0.03 * f52 + -0.03 * f53 + -0.05 * f54 +  0.07 * f55 +  0.02 * f56 +  0.06 * f57 +  0.23 * f58 +  0.06 * f59 +  0.02 * f60 + -0.03 * f61 +  0.01 * f62 + -0.00 * f63 +  0.04 * f64 +  0.00 * f65 +  0.02 * f66 + -0.02 * f67 + -0.01 * f68 +  0.00 * f69 +  0.00 * f70 + -0.01 * f71 + -0.03 * f72 + -0.03 * f73 +  0.42 * f74 +  0.42 * f75 +  0.42 * f76 +  0.42 * f77 + -0.04 * f78 +  0.01 * f79 + -0.01 * f80 +  0.01 * f81 + -0.02 * f82\n",
      " 4.6%:    -0.02 * f1 +  0.19 * f2 + -0.01 * f3 +  0.05 * f4 + -0.02 * f5 +  0.08 * f6 +  0.10 * f7 + -0.06 * f8 +  0.03 * f9 +  0.04 * f10 + -0.06 * f11 +  0.07 * f12 +  0.01 * f13 +  0.02 * f14 +  0.08 * f15 + -0.05 * f16 + -0.08 * f17 + -0.11 * f18 + -0.00 * f19 +  0.04 * f20 +  0.17 * f21 +  0.08 * f22 + -0.08 * f23 +  0.06 * f24 +  0.11 * f25 + -0.04 * f26 +  0.23 * f27 + -0.17 * f28 +  0.15 * f29 + -0.01 * f30 +  0.03 * f31 + -0.01 * f32 + -0.30 * f33 + -0.02 * f34 +  0.08 * f35 + -0.38 * f36 +  0.28 * f37 + -0.08 * f38 +  0.27 * f39 + -0.07 * f40 + -0.07 * f41 +  0.06 * f42 +  0.20 * f43 +  0.01 * f44 +  0.21 * f45 +  0.01 * f46 +  0.03 * f47 + -0.03 * f48 + -0.08 * f49 + -0.27 * f50 + -0.03 * f51 +  0.02 * f52 +  0.19 * f53 +  0.04 * f54 +  0.18 * f55 +  0.05 * f56 +  0.18 * f57 +  0.10 * f58 +  0.08 * f59 + -0.01 * f60 + -0.02 * f61 +  0.00 * f62 +  0.06 * f63 +  0.07 * f64 +  0.01 * f65 +  0.03 * f66 + -0.00 * f67 +  0.03 * f68 +  0.01 * f69 +  0.01 * f70 + -0.05 * f71 + -0.01 * f72 +  0.03 * f73 +  0.06 * f74 +  0.06 * f75 +  0.06 * f76 +  0.06 * f77 +  0.04 * f78 + -0.01 * f79 + -0.01 * f80 +  0.01 * f81 + -0.01 * f82\n",
      " 3.9%:    -0.04 * f1 + -0.08 * f2 +  0.08 * f3 +  0.11 * f4 + -0.13 * f5 +  0.07 * f6 +  0.11 * f7 +  0.01 * f8 +  0.08 * f9 + -0.07 * f10 + -0.10 * f11 +  0.06 * f12 + -0.10 * f13 +  0.15 * f14 +  0.18 * f15 + -0.01 * f16 + -0.00 * f17 +  0.12 * f18 +  0.11 * f19 +  0.02 * f20 +  0.18 * f21 +  0.02 * f22 +  0.03 * f23 +  0.12 * f24 + -0.03 * f25 + -0.13 * f26 + -0.12 * f27 +  0.02 * f28 + -0.04 * f29 + -0.03 * f30 +  0.06 * f31 + -0.04 * f32 +  0.19 * f33 + -0.02 * f34 +  0.01 * f35 +  0.19 * f36 + -0.18 * f37 + -0.03 * f38 + -0.05 * f39 + -0.03 * f40 + -0.02 * f41 + -0.10 * f42 +  0.10 * f43 + -0.05 * f44 +  0.37 * f45 + -0.08 * f46 +  0.06 * f47 +  0.00 * f48 +  0.11 * f49 +  0.14 * f50 +  0.07 * f51 + -0.09 * f52 + -0.11 * f53 +  0.15 * f54 +  0.39 * f55 +  0.10 * f56 +  0.38 * f57 +  0.10 * f58 +  0.02 * f59 +  0.00 * f60 + -0.01 * f61 + -0.02 * f62 + -0.04 * f63 + -0.00 * f64 + -0.03 * f65 + -0.04 * f66 + -0.04 * f67 +  0.02 * f68 + -0.03 * f69 + -0.03 * f70 + -0.07 * f71 + -0.01 * f72 +  0.04 * f73 + -0.11 * f74 + -0.11 * f75 + -0.11 * f76 + -0.11 * f77 +  0.04 * f78 + -0.01 * f79 + -0.03 * f80 + -0.01 * f81 + -0.01 * f82\n",
      " 3.8%:    -0.01 * f1 + -0.14 * f2 + -0.11 * f3 + -0.02 * f4 +  0.12 * f5 +  0.03 * f6 +  0.23 * f7 + -0.03 * f8 + -0.00 * f9 +  0.18 * f10 + -0.01 * f11 +  0.24 * f12 +  0.15 * f13 + -0.09 * f14 + -0.01 * f15 + -0.06 * f16 + -0.06 * f17 + -0.13 * f18 + -0.15 * f19 +  0.10 * f20 + -0.01 * f21 + -0.04 * f22 + -0.11 * f23 +  0.08 * f24 + -0.04 * f25 +  0.05 * f26 +  0.06 * f27 +  0.18 * f28 + -0.04 * f29 + -0.02 * f30 + -0.09 * f31 + -0.01 * f32 +  0.10 * f33 +  0.07 * f34 + -0.04 * f35 +  0.06 * f36 + -0.01 * f37 + -0.02 * f38 + -0.01 * f39 + -0.02 * f40 + -0.05 * f41 +  0.14 * f42 + -0.04 * f43 + -0.02 * f44 + -0.03 * f45 +  0.05 * f46 +  0.12 * f47 + -0.05 * f48 +  0.03 * f49 +  0.02 * f50 + -0.21 * f51 +  0.09 * f52 + -0.12 * f53 + -0.09 * f54 + -0.03 * f55 + -0.02 * f56 + -0.02 * f57 +  0.25 * f58 +  0.29 * f59 + -0.13 * f60 + -0.06 * f61 + -0.03 * f62 + -0.01 * f63 +  0.34 * f64 + -0.01 * f65 +  0.26 * f66 +  0.12 * f67 + -0.02 * f68 + -0.01 * f69 + -0.01 * f70 + -0.01 * f71 +  0.07 * f72 +  0.19 * f73 + -0.11 * f74 + -0.11 * f75 + -0.11 * f76 + -0.11 * f77 +  0.22 * f78 +  0.03 * f79 + -0.00 * f80 + -0.01 * f81 + -0.00 * f82\n",
      " 3.3%:    -0.04 * f1 + -0.09 * f2 + -0.10 * f3 +  0.01 * f4 + -0.07 * f5 +  0.15 * f6 + -0.13 * f7 + -0.08 * f8 + -0.00 * f9 + -0.12 * f10 +  0.08 * f11 + -0.13 * f12 +  0.35 * f13 +  0.10 * f14 +  0.12 * f15 + -0.08 * f16 + -0.09 * f17 + -0.03 * f18 +  0.06 * f19 + -0.00 * f20 +  0.00 * f21 +  0.07 * f22 + -0.08 * f23 +  0.09 * f24 +  0.01 * f25 + -0.01 * f26 +  0.06 * f27 +  0.25 * f28 +  0.06 * f29 +  0.02 * f30 +  0.05 * f31 +  0.11 * f32 +  0.12 * f33 + -0.02 * f34 + -0.00 * f35 +  0.06 * f36 + -0.05 * f37 + -0.11 * f38 +  0.11 * f39 + -0.11 * f40 + -0.10 * f41 +  0.08 * f42 +  0.06 * f43 + -0.04 * f44 +  0.05 * f45 +  0.31 * f46 + -0.02 * f47 + -0.09 * f48 +  0.21 * f49 + -0.03 * f50 + -0.12 * f51 +  0.41 * f52 + -0.13 * f53 +  0.22 * f54 +  0.02 * f55 +  0.00 * f56 +  0.01 * f57 + -0.13 * f58 + -0.15 * f59 + -0.07 * f60 +  0.03 * f61 + -0.00 * f62 + -0.04 * f63 +  0.00 * f64 +  0.06 * f65 + -0.03 * f66 +  0.00 * f67 +  0.01 * f68 +  0.06 * f69 +  0.06 * f70 +  0.07 * f71 +  0.08 * f72 + -0.08 * f73 +  0.11 * f74 +  0.11 * f75 +  0.11 * f76 +  0.11 * f77 + -0.07 * f78 + -0.02 * f79 + -0.00 * f80 +  0.05 * f81 + -0.01 * f82\n",
      " 2.9%:    -0.11 * f1 +  0.19 * f2 +  0.06 * f3 + -0.09 * f4 +  0.02 * f5 +  0.07 * f6 +  0.24 * f7 + -0.05 * f8 +  0.13 * f9 + -0.16 * f10 + -0.06 * f11 +  0.25 * f12 +  0.19 * f13 +  0.03 * f14 + -0.07 * f15 +  0.09 * f16 +  0.12 * f17 +  0.12 * f18 + -0.02 * f19 + -0.12 * f20 +  0.05 * f21 +  0.04 * f22 +  0.12 * f23 + -0.05 * f24 + -0.12 * f25 + -0.18 * f26 + -0.07 * f27 + -0.14 * f28 + -0.04 * f29 +  0.02 * f30 +  0.03 * f31 + -0.06 * f32 + -0.01 * f33 + -0.02 * f34 +  0.06 * f35 + -0.10 * f36 +  0.04 * f37 +  0.12 * f38 + -0.05 * f39 +  0.13 * f40 +  0.12 * f41 + -0.06 * f42 + -0.12 * f43 +  0.10 * f44 + -0.10 * f45 +  0.22 * f46 + -0.07 * f47 + -0.05 * f48 +  0.20 * f49 + -0.10 * f50 +  0.11 * f51 +  0.29 * f52 +  0.09 * f53 +  0.04 * f54 + -0.06 * f55 + -0.08 * f56 + -0.06 * f57 +  0.25 * f58 + -0.01 * f59 +  0.06 * f60 + -0.06 * f61 + -0.04 * f62 + -0.11 * f63 +  0.06 * f64 +  0.02 * f65 + -0.12 * f66 + -0.16 * f67 +  0.03 * f68 +  0.02 * f69 +  0.02 * f70 + -0.05 * f71 + -0.06 * f72 + -0.08 * f73 + -0.10 * f74 + -0.10 * f75 + -0.10 * f76 + -0.10 * f77 + -0.13 * f78 + -0.02 * f79 + -0.06 * f80 + -0.01 * f81 + -0.02 * f82\n",
      " 2.6%:    -0.00 * f1 + -0.07 * f2 + -0.19 * f3 + -0.19 * f4 + -0.02 * f5 +  0.16 * f6 + -0.00 * f7 + -0.02 * f8 +  0.14 * f9 + -0.10 * f10 + -0.18 * f11 + -0.02 * f12 + -0.19 * f13 +  0.15 * f14 +  0.06 * f15 +  0.02 * f16 +  0.00 * f17 +  0.13 * f18 +  0.00 * f19 +  0.22 * f20 +  0.13 * f21 +  0.07 * f22 + -0.04 * f23 +  0.39 * f24 +  0.08 * f25 + -0.19 * f26 +  0.07 * f27 + -0.05 * f28 +  0.14 * f29 + -0.05 * f30 +  0.23 * f31 + -0.04 * f32 +  0.09 * f33 + -0.05 * f34 +  0.06 * f35 +  0.03 * f36 + -0.07 * f37 +  0.01 * f38 +  0.14 * f39 +  0.01 * f40 + -0.04 * f41 + -0.05 * f42 + -0.10 * f43 +  0.13 * f44 + -0.15 * f45 + -0.15 * f46 +  0.11 * f47 + -0.00 * f48 +  0.11 * f49 + -0.01 * f50 + -0.12 * f51 + -0.16 * f52 +  0.05 * f53 +  0.03 * f54 + -0.21 * f55 + -0.19 * f56 + -0.21 * f57 + -0.00 * f58 +  0.05 * f59 + -0.17 * f60 + -0.01 * f61 + -0.03 * f62 +  0.02 * f63 +  0.00 * f64 + -0.03 * f65 + -0.04 * f66 + -0.05 * f67 + -0.04 * f68 + -0.03 * f69 + -0.03 * f70 + -0.13 * f71 +  0.14 * f72 +  0.04 * f73 +  0.05 * f74 +  0.05 * f75 +  0.05 * f76 +  0.05 * f77 + -0.03 * f78 + -0.02 * f79 +  0.03 * f80 +  0.00 * f81 +  0.03 * f82\n",
      " 2.2%:    -0.05 * f1 +  0.11 * f2 + -0.12 * f3 +  0.33 * f4 +  0.13 * f5 +  0.02 * f6 + -0.23 * f7 + -0.00 * f8 +  0.10 * f9 +  0.12 * f10 + -0.14 * f11 + -0.29 * f12 +  0.06 * f13 + -0.01 * f14 + -0.03 * f15 +  0.01 * f16 +  0.03 * f17 + -0.00 * f18 + -0.13 * f19 +  0.12 * f20 +  0.02 * f21 + -0.03 * f22 + -0.03 * f23 +  0.13 * f24 + -0.07 * f25 + -0.11 * f26 + -0.13 * f27 + -0.11 * f28 + -0.09 * f29 +  0.01 * f30 + -0.10 * f31 + -0.05 * f32 +  0.01 * f33 + -0.07 * f34 +  0.03 * f35 + -0.07 * f36 +  0.02 * f37 +  0.07 * f38 + -0.13 * f39 +  0.07 * f40 +  0.03 * f41 + -0.07 * f42 + -0.13 * f43 +  0.03 * f44 +  0.02 * f45 +  0.08 * f46 +  0.11 * f47 + -0.01 * f48 +  0.05 * f49 + -0.02 * f50 +  0.10 * f51 +  0.10 * f52 +  0.05 * f53 + -0.04 * f54 +  0.02 * f55 +  0.33 * f56 +  0.02 * f57 + -0.27 * f58 +  0.21 * f59 + -0.06 * f60 + -0.19 * f61 + -0.02 * f62 + -0.07 * f63 +  0.20 * f64 + -0.00 * f65 +  0.01 * f66 +  0.02 * f67 + -0.02 * f68 +  0.00 * f69 + -0.00 * f70 + -0.10 * f71 + -0.04 * f72 +  0.11 * f73 +  0.07 * f74 +  0.07 * f75 +  0.07 * f76 +  0.07 * f77 +  0.02 * f78 +  0.05 * f79 + -0.02 * f80 + -0.03 * f81 + -0.03 * f82\n",
      " 2.2%:     0.09 * f1 + -0.06 * f2 + -0.08 * f3 +  0.46 * f4 +  0.08 * f5 +  0.05 * f6 +  0.09 * f7 + -0.00 * f8 + -0.13 * f9 + -0.23 * f10 +  0.10 * f11 +  0.12 * f12 + -0.02 * f13 + -0.11 * f14 + -0.07 * f15 +  0.02 * f16 +  0.02 * f17 +  0.09 * f18 + -0.07 * f19 + -0.06 * f20 +  0.00 * f21 +  0.09 * f22 +  0.01 * f23 +  0.01 * f24 +  0.02 * f25 +  0.14 * f26 +  0.09 * f27 +  0.02 * f28 +  0.16 * f29 + -0.01 * f30 +  0.25 * f31 +  0.07 * f32 +  0.07 * f33 + -0.08 * f34 +  0.03 * f35 +  0.06 * f36 + -0.09 * f37 +  0.01 * f38 +  0.16 * f39 +  0.01 * f40 + -0.00 * f41 +  0.07 * f42 + -0.04 * f43 +  0.10 * f44 + -0.03 * f45 + -0.05 * f46 + -0.09 * f47 +  0.01 * f48 + -0.02 * f49 +  0.00 * f50 + -0.17 * f51 + -0.05 * f52 +  0.08 * f53 + -0.10 * f54 + -0.06 * f55 +  0.47 * f56 + -0.07 * f57 +  0.11 * f58 + -0.06 * f59 + -0.05 * f60 +  0.03 * f61 +  0.02 * f62 +  0.04 * f63 + -0.07 * f64 +  0.00 * f65 +  0.06 * f66 +  0.03 * f67 + -0.08 * f68 +  0.01 * f69 +  0.00 * f70 +  0.07 * f71 +  0.06 * f72 + -0.13 * f73 + -0.07 * f74 + -0.07 * f75 + -0.07 * f76 + -0.07 * f77 + -0.15 * f78 + -0.09 * f79 + -0.06 * f80 + -0.03 * f81 + -0.05 * f82\n",
      " 1.9%:    -0.08 * f1 + -0.03 * f2 +  0.06 * f3 +  0.33 * f4 + -0.16 * f5 + -0.06 * f6 +  0.13 * f7 + -0.01 * f8 +  0.20 * f9 +  0.16 * f10 + -0.07 * f11 +  0.10 * f12 + -0.04 * f13 +  0.18 * f14 +  0.08 * f15 +  0.02 * f16 +  0.01 * f17 + -0.06 * f18 +  0.14 * f19 +  0.04 * f20 + -0.06 * f21 + -0.06 * f22 +  0.04 * f23 +  0.04 * f24 +  0.05 * f25 + -0.21 * f26 +  0.04 * f27 +  0.04 * f28 + -0.09 * f29 + -0.00 * f30 + -0.15 * f31 + -0.11 * f32 + -0.05 * f33 +  0.11 * f34 + -0.03 * f35 + -0.03 * f36 +  0.07 * f37 + -0.02 * f38 + -0.08 * f39 + -0.02 * f40 +  0.01 * f41 + -0.00 * f42 + -0.02 * f43 + -0.04 * f44 + -0.18 * f45 + -0.01 * f46 +  0.02 * f47 + -0.02 * f48 +  0.01 * f49 + -0.02 * f50 +  0.01 * f51 + -0.01 * f52 + -0.11 * f53 +  0.16 * f54 + -0.18 * f55 +  0.34 * f56 + -0.19 * f57 +  0.13 * f58 + -0.12 * f59 +  0.05 * f60 +  0.06 * f61 + -0.01 * f62 +  0.00 * f63 + -0.09 * f64 + -0.01 * f65 + -0.12 * f66 + -0.12 * f67 +  0.07 * f68 + -0.02 * f69 + -0.01 * f70 + -0.04 * f71 + -0.03 * f72 +  0.07 * f73 +  0.01 * f74 +  0.01 * f75 +  0.01 * f76 +  0.01 * f77 +  0.13 * f78 + -0.03 * f79 +  0.13 * f80 +  0.06 * f81 +  0.11 * f82\n",
      " 1.8%:     0.07 * f1 +  0.06 * f2 + -0.01 * f3 +  0.03 * f4 + -0.07 * f5 + -0.10 * f6 +  0.09 * f7 +  0.02 * f8 + -0.09 * f9 +  0.15 * f10 +  0.13 * f11 +  0.12 * f12 + -0.08 * f13 +  0.11 * f14 +  0.13 * f15 + -0.06 * f16 + -0.07 * f17 + -0.00 * f18 +  0.10 * f19 +  0.13 * f20 + -0.22 * f21 + -0.04 * f22 + -0.05 * f23 +  0.11 * f24 +  0.01 * f25 +  0.07 * f26 +  0.05 * f27 + -0.02 * f28 + -0.08 * f29 +  0.00 * f30 +  0.03 * f31 +  0.14 * f32 + -0.10 * f33 +  0.14 * f34 + -0.01 * f35 + -0.07 * f36 +  0.10 * f37 + -0.09 * f38 + -0.10 * f39 + -0.10 * f40 + -0.07 * f41 + -0.03 * f42 + -0.16 * f43 + -0.08 * f44 + -0.04 * f45 + -0.01 * f46 +  0.01 * f47 +  0.00 * f48 +  0.18 * f49 + -0.03 * f50 +  0.03 * f51 + -0.04 * f52 +  0.01 * f53 +  0.17 * f54 + -0.02 * f55 +  0.03 * f56 + -0.01 * f57 +  0.09 * f58 + -0.23 * f59 + -0.06 * f60 +  0.06 * f61 +  0.05 * f62 +  0.01 * f63 + -0.15 * f64 +  0.01 * f65 + -0.07 * f66 +  0.00 * f67 +  0.02 * f68 +  0.00 * f69 +  0.01 * f70 +  0.11 * f71 +  0.09 * f72 +  0.09 * f73 +  0.03 * f74 +  0.03 * f75 +  0.03 * f76 +  0.03 * f77 +  0.21 * f78 +  0.04 * f79 + -0.10 * f80 + -0.14 * f81 + -0.19 * f82\n",
      " 1.7%:    -0.08 * f1 + -0.22 * f2 +  0.15 * f3 +  0.01 * f4 +  0.01 * f5 + -0.02 * f6 + -0.01 * f7 + -0.02 * f8 +  0.06 * f9 +  0.00 * f10 + -0.12 * f11 + -0.02 * f12 + -0.07 * f13 + -0.00 * f14 + -0.08 * f15 +  0.04 * f16 +  0.02 * f17 + -0.24 * f18 + -0.03 * f19 + -0.04 * f20 +  0.12 * f21 +  0.06 * f22 +  0.04 * f23 + -0.00 * f24 +  0.11 * f25 + -0.16 * f26 +  0.09 * f27 +  0.33 * f28 +  0.08 * f29 + -0.01 * f30 + -0.08 * f31 + -0.10 * f32 +  0.02 * f33 + -0.08 * f34 + -0.09 * f35 + -0.01 * f36 +  0.06 * f37 +  0.01 * f38 +  0.14 * f39 +  0.01 * f40 +  0.02 * f41 + -0.04 * f42 +  0.21 * f43 +  0.06 * f44 + -0.05 * f45 +  0.02 * f46 + -0.01 * f47 + -0.02 * f48 + -0.19 * f49 + -0.02 * f50 +  0.06 * f51 +  0.00 * f52 + -0.25 * f53 + -0.02 * f54 + -0.06 * f55 +  0.01 * f56 + -0.07 * f57 + -0.01 * f58 +  0.02 * f59 +  0.08 * f60 + -0.05 * f61 +  0.02 * f62 +  0.09 * f63 + -0.07 * f64 + -0.01 * f65 + -0.10 * f66 + -0.06 * f67 + -0.03 * f68 + -0.00 * f69 + -0.01 * f70 + -0.09 * f71 + -0.14 * f72 + -0.02 * f73 + -0.01 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 +  0.00 * f79 + -0.10 * f80 + -0.12 * f81 + -0.10 * f82\n",
      " 1.4%:    -0.05 * f1 + -0.04 * f2 + -0.07 * f3 +  0.01 * f4 +  0.04 * f5 +  0.18 * f6 +  0.10 * f7 +  0.00 * f8 + -0.23 * f9 + -0.19 * f10 +  0.04 * f11 +  0.10 * f12 + -0.03 * f13 +  0.03 * f14 +  0.03 * f15 + -0.03 * f16 + -0.06 * f17 +  0.01 * f18 + -0.06 * f19 +  0.07 * f20 + -0.01 * f21 +  0.03 * f22 + -0.04 * f23 +  0.13 * f24 +  0.10 * f25 +  0.16 * f26 + -0.15 * f27 + -0.03 * f28 + -0.01 * f29 + -0.00 * f30 + -0.23 * f31 +  0.10 * f32 + -0.05 * f33 + -0.50 * f34 + -0.06 * f35 + -0.08 * f36 +  0.00 * f37 + -0.03 * f38 + -0.16 * f39 + -0.03 * f40 + -0.05 * f41 + -0.16 * f42 +  0.13 * f43 + -0.05 * f44 + -0.07 * f45 +  0.02 * f46 + -0.03 * f47 +  0.01 * f48 + -0.03 * f49 +  0.03 * f50 +  0.14 * f51 +  0.01 * f52 +  0.02 * f53 +  0.05 * f54 + -0.07 * f55 +  0.01 * f56 + -0.05 * f57 +  0.08 * f58 +  0.02 * f59 + -0.03 * f60 + -0.28 * f61 +  0.05 * f62 + -0.03 * f63 + -0.10 * f64 + -0.01 * f65 + -0.08 * f66 +  0.00 * f67 + -0.01 * f68 + -0.01 * f69 + -0.01 * f70 +  0.04 * f71 +  0.03 * f72 +  0.05 * f73 + -0.01 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 +  0.05 * f78 +  0.16 * f79 +  0.06 * f80 +  0.17 * f81 + -0.06 * f82\n",
      " 1.4%:     0.03 * f1 + -0.28 * f2 +  0.07 * f3 + -0.04 * f4 +  0.08 * f5 + -0.20 * f6 + -0.05 * f7 + -0.03 * f8 + -0.05 * f9 +  0.17 * f10 + -0.02 * f11 + -0.04 * f12 + -0.05 * f13 + -0.02 * f14 + -0.08 * f15 +  0.07 * f16 +  0.07 * f17 + -0.01 * f18 + -0.06 * f19 +  0.03 * f20 +  0.21 * f21 +  0.02 * f22 +  0.09 * f23 +  0.00 * f24 + -0.00 * f25 + -0.13 * f26 +  0.22 * f27 +  0.12 * f28 + -0.02 * f29 + -0.01 * f30 + -0.06 * f31 +  0.29 * f32 + -0.09 * f33 + -0.22 * f34 + -0.01 * f35 + -0.08 * f36 +  0.03 * f37 +  0.07 * f38 + -0.02 * f39 +  0.07 * f40 +  0.08 * f41 +  0.17 * f42 + -0.31 * f43 +  0.12 * f44 +  0.10 * f45 +  0.02 * f46 + -0.23 * f47 + -0.04 * f48 +  0.06 * f49 +  0.02 * f50 + -0.15 * f51 +  0.02 * f52 +  0.05 * f53 +  0.07 * f54 +  0.09 * f55 + -0.03 * f56 +  0.10 * f57 + -0.02 * f58 + -0.10 * f59 + -0.04 * f60 + -0.22 * f61 +  0.03 * f62 +  0.03 * f63 + -0.07 * f64 + -0.02 * f65 + -0.14 * f66 + -0.15 * f67 + -0.07 * f68 + -0.01 * f69 + -0.02 * f70 + -0.00 * f71 + -0.01 * f72 +  0.03 * f73 + -0.04 * f74 + -0.04 * f75 + -0.04 * f76 + -0.04 * f77 +  0.04 * f78 +  0.13 * f79 +  0.07 * f80 +  0.01 * f81 + -0.05 * f82\n",
      " 1.4%:     0.05 * f1 +  0.03 * f2 + -0.07 * f3 +  0.02 * f4 +  0.10 * f5 + -0.00 * f6 +  0.03 * f7 +  0.01 * f8 + -0.24 * f9 +  0.06 * f10 +  0.01 * f11 + -0.03 * f12 + -0.14 * f13 + -0.04 * f14 + -0.06 * f15 +  0.05 * f16 +  0.06 * f17 +  0.04 * f18 + -0.10 * f19 +  0.11 * f20 +  0.08 * f21 +  0.07 * f22 +  0.06 * f23 +  0.10 * f24 + -0.02 * f25 +  0.12 * f26 + -0.02 * f27 +  0.25 * f28 + -0.04 * f29 +  0.01 * f30 +  0.14 * f31 +  0.08 * f32 + -0.01 * f33 +  0.31 * f34 + -0.01 * f35 + -0.10 * f36 +  0.16 * f37 +  0.04 * f38 +  0.03 * f39 +  0.04 * f40 +  0.02 * f41 + -0.16 * f42 + -0.12 * f43 +  0.11 * f44 +  0.03 * f45 +  0.02 * f46 + -0.06 * f47 +  0.00 * f48 +  0.17 * f49 + -0.12 * f50 +  0.31 * f51 +  0.03 * f52 + -0.19 * f53 + -0.03 * f54 +  0.04 * f55 +  0.02 * f56 +  0.04 * f57 + -0.03 * f58 +  0.07 * f59 + -0.06 * f60 + -0.03 * f61 +  0.06 * f62 + -0.00 * f63 + -0.02 * f64 +  0.01 * f65 + -0.09 * f66 + -0.03 * f67 + -0.01 * f68 +  0.01 * f69 +  0.01 * f70 +  0.03 * f71 +  0.03 * f72 +  0.01 * f73 + -0.03 * f74 + -0.03 * f75 + -0.03 * f76 + -0.03 * f77 +  0.00 * f78 + -0.14 * f79 +  0.16 * f80 +  0.18 * f81 +  0.09 * f82\n",
      " 1.3%:    -0.03 * f1 + -0.09 * f2 +  0.07 * f3 +  0.05 * f4 + -0.00 * f5 +  0.03 * f6 +  0.03 * f7 + -0.02 * f8 +  0.02 * f9 + -0.04 * f10 +  0.09 * f11 + -0.01 * f12 + -0.07 * f13 + -0.02 * f14 + -0.08 * f15 +  0.04 * f16 +  0.03 * f17 +  0.12 * f18 + -0.02 * f19 +  0.01 * f20 +  0.10 * f21 +  0.07 * f22 +  0.05 * f23 + -0.05 * f24 +  0.08 * f25 +  0.02 * f26 + -0.04 * f27 + -0.03 * f28 +  0.02 * f29 + -0.00 * f30 + -0.07 * f31 +  0.25 * f32 + -0.09 * f33 +  0.20 * f34 +  0.00 * f35 +  0.00 * f36 +  0.04 * f37 +  0.03 * f38 +  0.09 * f39 +  0.03 * f40 +  0.01 * f41 + -0.11 * f42 +  0.18 * f43 +  0.04 * f44 + -0.03 * f45 + -0.01 * f46 + -0.01 * f47 + -0.01 * f48 +  0.10 * f49 +  0.05 * f50 +  0.11 * f51 + -0.01 * f52 + -0.01 * f53 +  0.03 * f54 + -0.03 * f55 +  0.06 * f56 + -0.03 * f57 + -0.00 * f58 +  0.02 * f59 + -0.08 * f60 +  0.06 * f61 +  0.02 * f62 + -0.00 * f63 +  0.13 * f64 + -0.01 * f65 +  0.01 * f66 + -0.01 * f67 +  0.02 * f68 + -0.01 * f69 + -0.01 * f70 +  0.08 * f71 +  0.16 * f72 + -0.02 * f73 +  0.00 * f74 +  0.00 * f75 +  0.00 * f76 +  0.00 * f77 + -0.02 * f78 +  0.54 * f79 +  0.11 * f80 + -0.05 * f81 +  0.05 * f82\n",
      " 1.2%:     0.06 * f1 +  0.05 * f2 + -0.02 * f3 + -0.00 * f4 + -0.07 * f5 + -0.13 * f6 +  0.00 * f7 + -0.01 * f8 + -0.07 * f9 +  0.15 * f10 + -0.00 * f11 + -0.02 * f12 + -0.04 * f13 +  0.02 * f14 +  0.02 * f15 + -0.02 * f16 + -0.03 * f17 +  0.24 * f18 +  0.07 * f19 + -0.12 * f20 + -0.07 * f21 +  0.04 * f22 + -0.02 * f23 + -0.10 * f24 +  0.01 * f25 + -0.03 * f26 +  0.10 * f27 +  0.06 * f28 +  0.01 * f29 +  0.01 * f30 +  0.12 * f31 + -0.31 * f32 + -0.04 * f33 + -0.20 * f34 + -0.07 * f35 + -0.01 * f36 +  0.01 * f37 + -0.03 * f38 +  0.17 * f39 + -0.04 * f40 + -0.01 * f41 +  0.08 * f42 +  0.05 * f43 + -0.01 * f44 + -0.03 * f45 + -0.05 * f46 + -0.09 * f47 + -0.00 * f48 +  0.19 * f49 +  0.07 * f50 +  0.11 * f51 + -0.02 * f52 + -0.14 * f53 + -0.10 * f54 + -0.02 * f55 +  0.00 * f56 + -0.04 * f57 + -0.02 * f58 +  0.01 * f59 +  0.01 * f60 + -0.16 * f61 +  0.07 * f62 +  0.06 * f63 +  0.15 * f64 +  0.01 * f65 + -0.01 * f66 + -0.02 * f67 +  0.01 * f68 +  0.01 * f69 +  0.01 * f70 +  0.01 * f71 + -0.02 * f72 +  0.01 * f73 +  0.01 * f74 +  0.01 * f75 +  0.01 * f76 +  0.01 * f77 +  0.15 * f78 + -0.09 * f79 + -0.16 * f80 +  0.45 * f81 + -0.28 * f82\n",
      " 1.2%:     0.05 * f1 + -0.02 * f2 +  0.04 * f3 +  0.00 * f4 +  0.03 * f5 + -0.01 * f6 + -0.04 * f7 +  0.01 * f8 +  0.10 * f9 +  0.00 * f10 +  0.01 * f11 +  0.01 * f12 +  0.07 * f13 +  0.00 * f14 +  0.03 * f15 +  0.00 * f16 +  0.01 * f17 + -0.03 * f18 + -0.03 * f19 +  0.01 * f20 + -0.17 * f21 + -0.02 * f22 +  0.02 * f23 +  0.05 * f24 + -0.01 * f25 + -0.00 * f26 +  0.12 * f27 +  0.09 * f28 +  0.03 * f29 +  0.02 * f30 +  0.03 * f31 + -0.35 * f32 + -0.00 * f33 + -0.16 * f34 +  0.01 * f35 + -0.05 * f36 +  0.00 * f37 +  0.00 * f38 +  0.01 * f39 + -0.00 * f40 +  0.01 * f41 +  0.07 * f42 + -0.16 * f43 +  0.02 * f44 +  0.06 * f45 + -0.04 * f46 + -0.01 * f47 +  0.01 * f48 +  0.02 * f49 + -0.02 * f50 + -0.10 * f51 + -0.02 * f52 +  0.01 * f53 + -0.10 * f54 +  0.10 * f55 +  0.00 * f56 +  0.08 * f57 + -0.01 * f58 + -0.11 * f59 + -0.01 * f60 + -0.14 * f61 + -0.00 * f62 +  0.03 * f63 + -0.13 * f64 +  0.01 * f65 + -0.03 * f66 + -0.01 * f67 + -0.02 * f68 +  0.01 * f69 +  0.01 * f70 + -0.01 * f71 + -0.02 * f72 + -0.03 * f73 +  0.00 * f74 +  0.00 * f75 +  0.00 * f76 +  0.00 * f77 + -0.01 * f78 +  0.26 * f79 +  0.10 * f80 + -0.16 * f81 +  0.24 * f82\n",
      " 1.2%:     0.08 * f1 +  0.14 * f2 +  0.03 * f3 +  0.01 * f4 + -0.04 * f5 + -0.12 * f6 +  0.02 * f7 + -0.00 * f8 +  0.05 * f9 +  0.05 * f10 +  0.03 * f11 + -0.01 * f12 +  0.01 * f13 + -0.02 * f14 + -0.03 * f15 + -0.04 * f16 + -0.03 * f17 +  0.02 * f18 +  0.07 * f19 + -0.09 * f20 +  0.14 * f21 +  0.04 * f22 + -0.02 * f23 + -0.14 * f24 + -0.04 * f25 + -0.01 * f26 +  0.06 * f27 +  0.07 * f28 +  0.04 * f29 +  0.00 * f30 +  0.15 * f31 +  0.12 * f32 +  0.05 * f33 + -0.08 * f34 + -0.03 * f35 +  0.03 * f36 + -0.02 * f37 + -0.04 * f38 +  0.05 * f39 + -0.04 * f40 + -0.02 * f41 + -0.01 * f42 + -0.04 * f43 +  0.01 * f44 +  0.01 * f45 + -0.00 * f46 +  0.11 * f47 + -0.01 * f48 +  0.07 * f49 + -0.02 * f50 +  0.06 * f51 +  0.00 * f52 + -0.02 * f53 + -0.04 * f54 + -0.02 * f55 +  0.00 * f56 + -0.02 * f57 + -0.00 * f58 +  0.00 * f59 +  0.03 * f60 +  0.07 * f61 +  0.02 * f62 +  0.06 * f63 +  0.04 * f64 +  0.01 * f65 +  0.01 * f66 +  0.03 * f67 + -0.00 * f68 +  0.01 * f69 +  0.01 * f70 +  0.02 * f71 + -0.02 * f72 +  0.02 * f73 +  0.01 * f74 +  0.01 * f75 +  0.01 * f76 +  0.01 * f77 +  0.09 * f78 +  0.01 * f79 +  0.08 * f80 +  0.29 * f81 +  0.55 * f82\n",
      " 1.2%:     0.02 * f1 +  0.13 * f2 + -0.05 * f3 + -0.02 * f4 +  0.01 * f5 + -0.00 * f6 +  0.02 * f7 +  0.02 * f8 +  0.10 * f9 +  0.01 * f10 +  0.03 * f11 + -0.00 * f12 +  0.01 * f13 + -0.02 * f14 +  0.01 * f15 + -0.02 * f16 + -0.01 * f17 + -0.06 * f18 +  0.02 * f19 +  0.03 * f20 + -0.09 * f21 + -0.00 * f22 + -0.03 * f23 + -0.05 * f24 + -0.06 * f25 + -0.06 * f26 + -0.02 * f27 + -0.02 * f28 +  0.00 * f29 +  0.00 * f30 +  0.02 * f31 +  0.12 * f32 +  0.07 * f33 + -0.09 * f34 + -0.03 * f35 +  0.01 * f36 + -0.01 * f37 + -0.00 * f38 + -0.01 * f39 + -0.00 * f40 +  0.00 * f41 +  0.05 * f42 + -0.02 * f43 + -0.02 * f44 +  0.02 * f45 + -0.05 * f46 + -0.01 * f47 +  0.02 * f48 + -0.03 * f49 + -0.05 * f50 + -0.09 * f51 + -0.05 * f52 + -0.05 * f53 + -0.00 * f54 +  0.03 * f55 + -0.02 * f56 +  0.04 * f57 +  0.01 * f58 + -0.02 * f59 +  0.05 * f60 +  0.03 * f61 +  0.02 * f62 + -0.01 * f63 +  0.02 * f64 +  0.00 * f65 +  0.00 * f66 +  0.02 * f67 +  0.01 * f68 +  0.00 * f69 +  0.00 * f70 +  0.03 * f71 + -0.06 * f72 + -0.00 * f73 +  0.00 * f74 +  0.00 * f75 +  0.00 * f76 +  0.00 * f77 + -0.02 * f78 + -0.08 * f79 +  0.69 * f80 +  0.08 * f81 + -0.38 * f82\n",
      " 1.2%:    -0.01 * f1 +  0.12 * f2 + -0.18 * f3 + -0.01 * f4 +  0.09 * f5 +  0.00 * f6 + -0.01 * f7 +  0.01 * f8 +  0.04 * f9 +  0.03 * f10 + -0.02 * f11 +  0.03 * f12 +  0.03 * f13 + -0.04 * f14 +  0.02 * f15 + -0.01 * f16 + -0.00 * f17 +  0.01 * f18 + -0.04 * f19 +  0.11 * f20 +  0.06 * f21 +  0.02 * f22 + -0.04 * f23 +  0.07 * f24 + -0.03 * f25 + -0.04 * f26 +  0.00 * f27 + -0.05 * f28 + -0.02 * f29 + -0.00 * f30 +  0.02 * f31 +  0.09 * f32 +  0.07 * f33 +  0.04 * f34 + -0.08 * f35 +  0.02 * f36 +  0.04 * f37 +  0.01 * f38 + -0.09 * f39 +  0.01 * f40 +  0.01 * f41 +  0.07 * f42 + -0.09 * f43 +  0.01 * f44 +  0.04 * f45 + -0.02 * f46 + -0.14 * f47 + -0.00 * f48 + -0.23 * f49 + -0.00 * f50 + -0.17 * f51 +  0.01 * f52 + -0.13 * f53 +  0.11 * f54 + -0.02 * f55 + -0.02 * f56 +  0.00 * f57 +  0.02 * f58 +  0.01 * f59 +  0.13 * f60 + -0.05 * f61 +  0.00 * f62 + -0.02 * f63 + -0.14 * f64 + -0.01 * f65 + -0.07 * f66 + -0.07 * f67 + -0.02 * f68 + -0.00 * f69 + -0.01 * f70 + -0.00 * f71 + -0.25 * f72 + -0.00 * f73 + -0.01 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 + -0.12 * f79 + -0.20 * f80 +  0.19 * f81 +  0.08 * f82\n",
      " 1.1%:     0.01 * f1 +  0.02 * f2 +  0.01 * f3 + -0.02 * f4 +  0.04 * f5 +  0.03 * f6 + -0.01 * f7 +  0.04 * f8 +  0.18 * f9 + -0.03 * f10 +  0.10 * f11 +  0.02 * f12 + -0.02 * f13 + -0.03 * f14 + -0.01 * f15 +  0.02 * f16 +  0.01 * f17 + -0.04 * f18 + -0.05 * f19 +  0.03 * f20 + -0.18 * f21 + -0.04 * f22 +  0.03 * f23 +  0.04 * f24 +  0.03 * f25 + -0.00 * f26 + -0.08 * f27 +  0.01 * f28 + -0.01 * f29 +  0.01 * f30 + -0.08 * f31 +  0.15 * f32 + -0.01 * f33 + -0.09 * f34 + -0.01 * f35 + -0.07 * f36 +  0.05 * f37 +  0.00 * f38 + -0.08 * f39 +  0.00 * f40 + -0.00 * f41 +  0.06 * f42 +  0.02 * f43 + -0.03 * f44 + -0.00 * f45 + -0.09 * f46 +  0.06 * f47 +  0.04 * f48 +  0.06 * f49 + -0.05 * f50 + -0.01 * f51 + -0.10 * f52 + -0.06 * f53 +  0.02 * f54 +  0.05 * f55 + -0.02 * f56 +  0.05 * f57 +  0.01 * f58 + -0.11 * f59 + -0.08 * f60 + -0.13 * f61 +  0.01 * f62 + -0.01 * f63 + -0.02 * f64 + -0.00 * f65 +  0.02 * f66 +  0.03 * f67 +  0.00 * f68 + -0.00 * f69 + -0.00 * f70 +  0.08 * f71 +  0.13 * f72 +  0.01 * f73 +  0.01 * f74 +  0.01 * f75 +  0.01 * f76 +  0.01 * f77 +  0.02 * f78 +  0.07 * f79 + -0.39 * f80 +  0.20 * f81 +  0.20 * f82\n",
      " 1.1%:    -0.05 * f1 + -0.10 * f2 +  0.02 * f3 +  0.02 * f4 + -0.02 * f5 +  0.03 * f6 + -0.00 * f7 +  0.02 * f8 +  0.06 * f9 + -0.05 * f10 +  0.01 * f11 +  0.01 * f12 + -0.01 * f13 +  0.03 * f14 + -0.01 * f15 +  0.01 * f16 +  0.01 * f17 + -0.05 * f18 +  0.01 * f19 + -0.01 * f20 + -0.08 * f21 + -0.04 * f22 +  0.03 * f23 +  0.04 * f24 + -0.00 * f25 + -0.02 * f26 + -0.06 * f27 + -0.07 * f28 + -0.02 * f29 +  0.00 * f30 + -0.11 * f31 + -0.02 * f32 +  0.00 * f33 + -0.02 * f34 +  0.09 * f35 +  0.00 * f36 + -0.07 * f37 +  0.00 * f38 + -0.01 * f39 +  0.00 * f40 +  0.00 * f41 + -0.06 * f42 +  0.11 * f43 + -0.04 * f44 + -0.01 * f45 +  0.00 * f46 +  0.03 * f47 +  0.02 * f48 + -0.02 * f49 +  0.01 * f50 + -0.11 * f51 + -0.01 * f52 +  0.11 * f53 +  0.03 * f54 +  0.03 * f55 +  0.02 * f56 +  0.01 * f57 +  0.01 * f58 + -0.04 * f59 + -0.03 * f60 + -0.03 * f61 + -0.02 * f62 + -0.05 * f63 + -0.00 * f64 + -0.00 * f65 +  0.01 * f66 + -0.01 * f67 + -0.01 * f68 + -0.00 * f69 + -0.00 * f70 +  0.01 * f71 +  0.06 * f72 +  0.01 * f73 +  0.00 * f74 +  0.00 * f75 +  0.00 * f76 +  0.00 * f77 + -0.07 * f78 + -0.06 * f79 +  0.13 * f80 +  0.35 * f81 + -0.06 * f82\n"
     ]
    }
   ],
   "source": [
    "vars = pca.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10',\n",
    "           'f11','f12','f13','f14','f15','f16','f17','f18','f19','f20',\n",
    "           'f21','f22','f23','f24','f25','f26','f27','f28','f29','f30',\n",
    "           'f31','f32','f33','f34','f35','f36','f37','f38','f39','f40',\n",
    "           'f41','f42','f43','f44','f45','f46','f47','f48','f49','f50',\n",
    "           'f51','f52','f53','f54','f55','f56','f57','f58','f59','f60',\n",
    "           'f61','f62','f63','f64','f65','f66','f67','f68','f69','f70',\n",
    "           'f71','f72','f73','f74','f75','f76','f77','f78','f79','f80',\n",
    "           'f81','f82']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(pca.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "reduced = pca.fit_transform(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.529243</td>\n",
       "      <td>-0.481346</td>\n",
       "      <td>-2.197566</td>\n",
       "      <td>0.090869</td>\n",
       "      <td>-0.731091</td>\n",
       "      <td>0.606685</td>\n",
       "      <td>0.598433</td>\n",
       "      <td>-1.636677</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093330</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>-0.799428</td>\n",
       "      <td>-1.049478</td>\n",
       "      <td>0.462469</td>\n",
       "      <td>-0.032835</td>\n",
       "      <td>0.600083</td>\n",
       "      <td>1.213314</td>\n",
       "      <td>0.229505</td>\n",
       "      <td>0.310986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.926681</td>\n",
       "      <td>-0.245931</td>\n",
       "      <td>-1.709170</td>\n",
       "      <td>0.236085</td>\n",
       "      <td>-0.314797</td>\n",
       "      <td>1.279131</td>\n",
       "      <td>1.113337</td>\n",
       "      <td>-1.488044</td>\n",
       "      <td>1.260740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327529</td>\n",
       "      <td>0.356832</td>\n",
       "      <td>-0.994108</td>\n",
       "      <td>-1.567556</td>\n",
       "      <td>1.288602</td>\n",
       "      <td>-1.569016</td>\n",
       "      <td>0.971225</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>2.691992</td>\n",
       "      <td>-0.843703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.399064</td>\n",
       "      <td>1.138583</td>\n",
       "      <td>-0.939195</td>\n",
       "      <td>0.386344</td>\n",
       "      <td>-0.274704</td>\n",
       "      <td>-0.011861</td>\n",
       "      <td>0.170389</td>\n",
       "      <td>-0.947434</td>\n",
       "      <td>0.428108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237320</td>\n",
       "      <td>0.924914</td>\n",
       "      <td>-1.382001</td>\n",
       "      <td>-0.657229</td>\n",
       "      <td>1.262096</td>\n",
       "      <td>-0.616028</td>\n",
       "      <td>1.009561</td>\n",
       "      <td>0.398582</td>\n",
       "      <td>2.580320</td>\n",
       "      <td>-0.731612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.256706</td>\n",
       "      <td>1.542268</td>\n",
       "      <td>-1.092788</td>\n",
       "      <td>0.084575</td>\n",
       "      <td>0.064238</td>\n",
       "      <td>-0.090029</td>\n",
       "      <td>-0.116590</td>\n",
       "      <td>-0.242789</td>\n",
       "      <td>0.376564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039250</td>\n",
       "      <td>0.458381</td>\n",
       "      <td>-2.280771</td>\n",
       "      <td>-0.770656</td>\n",
       "      <td>0.423003</td>\n",
       "      <td>-0.196471</td>\n",
       "      <td>0.334632</td>\n",
       "      <td>0.531126</td>\n",
       "      <td>-1.148052</td>\n",
       "      <td>1.080912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679101</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.507259</td>\n",
       "      <td>1.303147</td>\n",
       "      <td>0.602425</td>\n",
       "      <td>1.715374</td>\n",
       "      <td>-1.717681</td>\n",
       "      <td>0.726001</td>\n",
       "      <td>0.258326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184980</td>\n",
       "      <td>0.438936</td>\n",
       "      <td>-1.938343</td>\n",
       "      <td>-0.961541</td>\n",
       "      <td>-0.923906</td>\n",
       "      <td>-0.185684</td>\n",
       "      <td>1.726113</td>\n",
       "      <td>0.760963</td>\n",
       "      <td>-1.901051</td>\n",
       "      <td>0.497231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trend         0         1         2         3         4         5  \\\n",
       "0      0 -1.529243 -0.481346 -2.197566  0.090869 -0.731091  0.606685   \n",
       "1      0 -0.926681 -0.245931 -1.709170  0.236085 -0.314797  1.279131   \n",
       "2      1  1.399064  1.138583 -0.939195  0.386344 -0.274704 -0.011861   \n",
       "3      1  2.256706  1.542268 -1.092788  0.084575  0.064238 -0.090029   \n",
       "4      1  0.679101  0.681263  0.507259  1.303147  0.602425  1.715374   \n",
       "\n",
       "          6         7         8    ...           10        11        12  \\\n",
       "0  0.598433 -1.636677  0.831224    ...    -0.093330  0.667153 -0.799428   \n",
       "1  1.113337 -1.488044  1.260740    ...     0.327529  0.356832 -0.994108   \n",
       "2  0.170389 -0.947434  0.428108    ...     0.237320  0.924914 -1.382001   \n",
       "3 -0.116590 -0.242789  0.376564    ...    -0.039250  0.458381 -2.280771   \n",
       "4 -1.717681  0.726001  0.258326    ...     0.184980  0.438936 -1.938343   \n",
       "\n",
       "         13        14        15        16        17        18        19  \n",
       "0 -1.049478  0.462469 -0.032835  0.600083  1.213314  0.229505  0.310986  \n",
       "1 -1.567556  1.288602 -1.569016  0.971225  0.064266  2.691992 -0.843703  \n",
       "2 -0.657229  1.262096 -0.616028  1.009561  0.398582  2.580320 -0.731612  \n",
       "3 -0.770656  0.423003 -0.196471  0.334632  0.531126 -1.148052  1.080912  \n",
       "4 -0.961541 -0.923906 -0.185684  1.726113  0.760963 -1.901051  0.497231  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df = pd.DataFrame.from_records(reduced)\n",
    "reduced_df.insert(0, column='trend', value=clean_data.trend)\n",
    "reduced_df['trend']=reduced_df['trend'].astype(np.int)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_df.iloc[:,1:], reduced_df['trend'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 89.57\n",
      "Accuracy score (test): 90.93\n"
     ]
    }
   ],
   "source": [
    "#lbfgs would not converge\n",
    "#For small datasets, â€˜liblinearâ€™ is a good choice, whereas â€˜sagâ€™ and â€˜sagaâ€™ are faster for large ones.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "log_model = logreg.fit(X_train, Y_train)\n",
    "\n",
    "log_Y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_log = round(logreg.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_log)\n",
    "print(\"Accuracy score (test):\",test_acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.32 | test error: 0.30\n",
      "CV error: 0.32\n",
      "train/test: 0.9\n"
     ]
    }
   ],
   "source": [
    "model=logreg\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "lr_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 30, 'n_neighbors': 5, 'p': 2}\n",
      "0.8840885142255005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_neighbors': [2, 5, 10, 50, 100],\n",
    "    'p' : [1, 2],\n",
    "    'leaf_size' :[30,50]\n",
    "}\n",
    "\n",
    "knn_CV = GridSearchCV(estimator=knn, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "knn_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(knn_CV.best_params_)\n",
    "print(knn_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 91.36\n",
      "Accuracy score (test): 89.95\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=30, n_neighbors=5, p=2) \n",
    "knn_model = knn.fit(X_train, Y_train)  \n",
    "knn_Y_pred = knn.predict(X_test)  \n",
    "\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_knn = round(knn.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_knn)\n",
    "print(\"Accuracy score (test):\",test_acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.29 | test error: 0.32\n",
      "CV error: 0.32\n",
      "train/test: 1.1\n"
     ]
    }
   ],
   "source": [
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data\n",
    "\n",
    "model=knn\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "knn_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 50.79\n",
      "Accuracy score (test): 48.28\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian_model = gaussian.fit(X_train, Y_train) \n",
    "\n",
    "gaussian_Y_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_gaussian = round(gaussian.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_gaussian)\n",
    "print(\"Accuracy score (test):\",test_acc_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.70 | test error: 0.72\n",
      "CV error: 0.34\n",
      "train/test: 1.0\n"
     ]
    }
   ],
   "source": [
    "model=gaussian\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "gaussian_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 90.73\n",
      "Accuracy score (test): 90.2\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "svc_model = svc.fit(X_train, Y_train)\n",
    "\n",
    "svc_Y_pred = svc.predict(X_test)\n",
    "\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_svc = round(svc.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_svc)\n",
    "print(\"Accuracy score (test):\",test_acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.30 | test error: 0.31\n",
      "CV error: 0.32\n",
      "train/test: 1.0\n"
     ]
    }
   ],
   "source": [
    "model=svc\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "svc_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 1}\n",
      "0.8819810326659642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : depths,\n",
    "    'min_samples_leaf' :[1, 5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "decision_tree_CV = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "decision_tree_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(decision_tree_CV.best_params_)\n",
    "print(decision_tree_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 88.62\n",
      "Accuracy score (test): 90.2\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='entropy', max_depth=2, min_samples_leaf=1) \n",
    "decision_tree_model = decision_tree.fit(X_train, Y_train)  \n",
    "decision_tree_Y_pred = decision_tree.predict(X_test)  \n",
    "\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_decision_tree = round(decision_tree.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_decision_tree)\n",
    "print(\"Accuracy score (test):\",test_acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.34 | test error: 0.31\n",
      "CV error: 0.34\n",
      "train/test: 0.9\n"
     ]
    }
   ],
   "source": [
    "model=decision_tree\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "dt_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 86.52\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=decision_tree, n_estimators=180, random_state=1)\n",
    "ada_model = ada.fit(X_train, Y_train)\n",
    "\n",
    "ada_Y_pred = ada.predict(X_test)\n",
    "\n",
    "acc_ada = round(ada.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_ada = round(ada.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_ada)\n",
    "print(\"Accuracy score (test):\",test_acc_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.00 | test error: 0.37\n",
      "CV error: 0.42\n",
      "train/test: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "model=ada\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "ada_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 92.62\n",
      "Accuracy score (test): 88.48\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n",
    "    gt_model = gb.fit(X_train, Y_train)\n",
    "    \n",
    "    acc_gb = round(gb.score(X_train, Y_train) * 100, 2)\n",
    "    test_acc_gb = round(gb.score(X_test, Y_test) * 100, 2)\n",
    "    \n",
    "    gb_Y_pred = gb.predict(X_test)\n",
    "    \n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training):\",acc_gb)\n",
    "print(\"Accuracy score (test):\",test_acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.27 | test error: 0.34\n",
      "CV error: 0.35\n",
      "train/test: 1.2\n"
     ]
    }
   ],
   "source": [
    "model=gb\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "gb_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.8956796628029505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : depths,\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "rf_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(rf_CV.best_params_)\n",
    "print(rf_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 98.74\n",
      "Accuracy score (test): 90.93\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini', max_depth=11, max_features='sqrt', n_estimators=200)\n",
    "random_forest_model = random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_random_forest = round(random_forest.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_random_forest)\n",
    "print(\"Accuracy score (test):\",test_acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.13 | test error: 0.30\n",
      "CV error: 0.34\n",
      "train/test: 2.4\n"
     ]
    }
   ],
   "source": [
    "model=random_forest\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "rf_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "feature            \n",
       "0             0.087\n",
       "2             0.079\n",
       "1             0.073\n",
       "4             0.062\n",
       "8             0.051\n",
       "12            0.049\n",
       "11            0.048\n",
       "3             0.047\n",
       "18            0.047\n",
       "9             0.047\n",
       "17            0.046\n",
       "14            0.045\n",
       "10            0.045\n",
       "7             0.045\n",
       "15            0.044"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier()\n",
    "sgd.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.8872497365648051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "sgd_CV = GridSearchCV(estimator=sgd, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "sgd_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(sgd_CV.best_params_)\n",
    "print(sgd_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 78.5\n",
      "Accuracy score (test): 77.45\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier(loss='squared_hinge', penalty='l2',max_iter=1000)\n",
    "sgd_model = sgd.fit(X_train, Y_train)\n",
    "sgd_Y_pred = sgd.predict(X_test)\n",
    "\n",
    "sgd.score(X_train, Y_train)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_sgd = round(sgd.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_sgd)\n",
    "print(\"Accuracy score (test):\",test_acc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.44 | test error: 0.48\n",
      "CV error: 0.43\n",
      "train/test: 1.1\n"
     ]
    }
   ],
   "source": [
    "model=sgd\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "sgd_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 87.25\n",
      "Accuracy score (test): 88.24\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(max_iter=5)\n",
    "perceptron_model = perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_Y_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_perceptron = round(perceptron.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_perceptron)\n",
    "print(\"Accuracy score (test):\",test_acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.36 | test error: 0.34\n",
      "CV error: 0.43\n",
      "train/test: 1.0\n"
     ]
    }
   ],
   "source": [
    "model=perceptron\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "train_error, test_error, cv_error = calc_metrics(X_train, Y_train, X_test, Y_test, model)\n",
    "\n",
    "perceptron_cv_error = cv_error\n",
    "\n",
    "print('train error: {:.2f} | test error: {:.2f}'.format(train_error, test_error))\n",
    "print('CV error: {:.2f}'.format(cv_error))\n",
    "print('train/test: {}'.format(round(test_error/train_error, 1)))\n",
    "\n",
    "#RMSE of test > RMSE of train => OVER FITTING of the data.\n",
    "#RMSE of test < RMSE of train => UNDER FITTING of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90.93</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.93</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.20</th>\n",
       "      <td>Support Vector Classifier (SVC)</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.20</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.95</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88.48</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88.24</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86.52</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77.45</th>\n",
       "      <td>Stochastic Gradient Descent (SGD)</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.28</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  CV Error\n",
       "Score                                             \n",
       "90.93                Logistic Regression      0.32\n",
       "90.93                      Random Forest      0.34\n",
       "90.20    Support Vector Classifier (SVC)      0.32\n",
       "90.20                     Decision Trees      0.34\n",
       "89.95                K-Nearest Neighbors      0.32\n",
       "88.48             Gradient Tree Boosting      0.35\n",
       "88.24                         Perceptron      0.43\n",
       "86.52                           AdaBoost      0.42\n",
       "77.45  Stochastic Gradient Descent (SGD)      0.43\n",
       "48.28               Gaussian Naive Bayes      0.34"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression','K-Nearest Neighbors',\n",
    "             'Gaussian Naive Bayes','Support Vector Classifier (SVC)',\n",
    "             'Decision Trees','AdaBoost','Gradient Tree Boosting',\n",
    "             'Random Forest','Stochastic Gradient Descent (SGD)','Perceptron'],\n",
    "    'Score': [test_acc_log,\n",
    "              test_acc_knn,\n",
    "              test_acc_gaussian,\n",
    "              test_acc_svc,\n",
    "              test_acc_decision_tree,\n",
    "              test_acc_ada,\n",
    "              test_acc_gb,\n",
    "              test_acc_random_forest,\n",
    "              test_acc_sgd,\n",
    "              test_acc_perceptron],\n",
    "    'CV Error': [round(lr_cv_error, 2),\n",
    "                round(knn_cv_error, 2),\n",
    "                round(gaussian_cv_error, 2),\n",
    "                round(svc_cv_error, 2),\n",
    "                round(dt_cv_error, 2),\n",
    "                round(ada_cv_error, 2),\n",
    "                round(gb_cv_error, 2),\n",
    "                round(rf_cv_error, 2),\n",
    "                round(sgd_cv_error, 2),\n",
    "                round(perceptron_cv_error, 2)\n",
    "                ]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
