{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitability - Group Project on Stock Price Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>...</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>PE</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.330000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.350000e+08</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>13.680000</td>\n",
       "      <td>7005600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.410714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.175000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630222e+08</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>24.629999</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>7166600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.244444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.768000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.169154e+08</td>\n",
       "      <td>53.900002</td>\n",
       "      <td>53.630001</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>10626000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13.340796</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.085000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>6.681299e+08</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>6788900.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.718174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>6.448000e+09</td>\n",
       "      <td>681000000.0</td>\n",
       "      <td>-5.400000e+07</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-4.910000e+08</td>\n",
       "      <td>3.671000e+09</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9.595000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>52.990002</td>\n",
       "      <td>52.810001</td>\n",
       "      <td>52.360001</td>\n",
       "      <td>53.060001</td>\n",
       "      <td>3019700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>20.468993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date  Accounts Payable  Accounts Receivable  \\\n",
       "0    AAL  2012-12-31      3.068000e+09         -222000000.0   \n",
       "1    AAL  2013-12-31      4.975000e+09          -93000000.0   \n",
       "2    AAL  2014-12-31      4.668000e+09         -160000000.0   \n",
       "3    AAL  2015-12-31      5.102000e+09          352000000.0   \n",
       "4   ABBV  2013-12-31      6.448000e+09          681000000.0   \n",
       "\n",
       "   Add'l income/expense items  After Tax ROE  Capital Expenditures  \\\n",
       "0               -1.961000e+09           23.0         -1.888000e+09   \n",
       "1               -2.723000e+09           67.0         -3.114000e+09   \n",
       "2               -1.500000e+08          143.0         -5.311000e+09   \n",
       "3               -7.080000e+08          135.0         -6.151000e+09   \n",
       "4               -5.400000e+07           92.0         -4.910000e+08   \n",
       "\n",
       "   Capital Surplus  Cash Ratio  Cash and Cash Equivalents  ...    \\\n",
       "0     4.695000e+09        53.0               1.330000e+09  ...     \n",
       "1     1.059200e+10        75.0               2.175000e+09  ...     \n",
       "2     1.513500e+10        60.0               1.768000e+09  ...     \n",
       "3     1.159100e+10        51.0               1.085000e+09  ...     \n",
       "4     3.671000e+09       144.0               9.595000e+09  ...     \n",
       "\n",
       "   Estimated Shares Outstanding       open      close        low       high  \\\n",
       "0                  3.350000e+08  12.850000  13.500000  12.840000  13.680000   \n",
       "1                  1.630222e+08  24.740000  25.250000  24.629999  25.250000   \n",
       "2                  7.169154e+08  53.900002  53.630001  53.320000  54.639999   \n",
       "3                  6.681299e+08  42.540001  42.349998  41.830002  42.570000   \n",
       "4                  1.600000e+09  52.990002  52.810001  52.360001  53.060001   \n",
       "\n",
       "       volume  GICS Sector  GICS Sub Industry         PE  trend  \n",
       "0   7005600.0            5                  4  -2.410714    0.0  \n",
       "1   7166600.0            5                  4  -2.244444    0.0  \n",
       "2  10626000.0            5                  4  13.340796    1.0  \n",
       "3   6788900.0            5                  4   3.718174    1.0  \n",
       "4   3019700.0            4                 87  20.468993    1.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_csv('final_merged_data.csv',index_col = 0)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'date', 'Accounts Payable', 'Accounts Receivable',\n",
       "       'Add'l income/expense items', 'After Tax ROE', 'Capital Expenditures',\n",
       "       'Capital Surplus', 'Cash Ratio', 'Cash and Cash Equivalents',\n",
       "       'Changes in Inventories', 'Common Stocks', 'Cost of Revenue',\n",
       "       'Current Ratio', 'Deferred Asset Charges', 'Deferred Liability Charges',\n",
       "       'Depreciation', 'Earnings Before Interest and Tax',\n",
       "       'Earnings Before Tax', 'Effect of Exchange Rate', 'Fixed Assets',\n",
       "       'Goodwill', 'Gross Margin', 'Gross Profit', 'Income Tax',\n",
       "       'Intangible Assets', 'Interest Expense', 'Inventory', 'Investments',\n",
       "       'Liabilities', 'Long-Term Debt', 'Long-Term Investments',\n",
       "       'Minority Interest', 'Misc. Stocks', 'Net Borrowings', 'Net Cash Flow',\n",
       "       'Net Cash Flow-Operating', 'Net Cash Flows-Financing',\n",
       "       'Net Cash Flows-Investing', 'Net Income', 'Net Income Adjustments',\n",
       "       'Net Income Applicable to Common Shareholders',\n",
       "       'Net Income-Cont. Operations', 'Net Receivables', 'Non-Recurring Items',\n",
       "       'Operating Income', 'Operating Margin', 'Other Assets',\n",
       "       'Other Current Assets', 'Other Current Liabilities', 'Other Equity',\n",
       "       'Other Financing Activities', 'Other Investing Activities',\n",
       "       'Other Liabilities', 'Other Operating Activities',\n",
       "       'Other Operating Items', 'Pre-Tax Margin', 'Pre-Tax ROE',\n",
       "       'Profit Margin', 'Quick Ratio', 'Research and Development',\n",
       "       'Retained Earnings', 'Sale and Purchase of Stock',\n",
       "       'Sales, General and Admin.',\n",
       "       'Short-Term Debt / Current Portion of Long-Term Debt',\n",
       "       'Short-Term Investments', 'Total Assets', 'Total Current Assets',\n",
       "       'Total Current Liabilities', 'Total Equity', 'Total Liabilities',\n",
       "       'Total Liabilities & Equity', 'Total Revenue', 'Treasury Stock',\n",
       "       'Earnings Per Share', 'For Year', 'Estimated Shares Outstanding',\n",
       "       'open', 'close', 'low', 'high', 'volume', 'GICS Sector',\n",
       "       'GICS Sub Industry', 'PE', 'trend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import category_encoders as ce\n",
    "#ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n",
    "#clean_data = ohe.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.drop(['symbol'], axis=1,inplace=True)\n",
    "clean_data.drop(['date'], axis=1,inplace=True)\n",
    "#drop PE and columns directly related to profitability\n",
    "clean_data.drop(['PE'], axis=1,inplace=True)\n",
    "clean_data.drop(['Earnings Per Share'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>Changes in Inventories</th>\n",
       "      <th>Common Stocks</th>\n",
       "      <th>...</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.330000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.350000e+08</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>13.680000</td>\n",
       "      <td>7005600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.175000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.630222e+08</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>24.629999</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>7166600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.768000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.169154e+08</td>\n",
       "      <td>53.900002</td>\n",
       "      <td>53.630001</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>10626000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.085000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.681299e+08</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>6788900.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.448000e+09</td>\n",
       "      <td>681000000.0</td>\n",
       "      <td>-5.400000e+07</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-4.910000e+08</td>\n",
       "      <td>3.671000e+09</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9.595000e+09</td>\n",
       "      <td>-56000000.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>52.990002</td>\n",
       "      <td>52.810001</td>\n",
       "      <td>52.360001</td>\n",
       "      <td>53.060001</td>\n",
       "      <td>3019700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accounts Payable  Accounts Receivable  Add'l income/expense items  \\\n",
       "0      3.068000e+09         -222000000.0               -1.961000e+09   \n",
       "1      4.975000e+09          -93000000.0               -2.723000e+09   \n",
       "2      4.668000e+09         -160000000.0               -1.500000e+08   \n",
       "3      5.102000e+09          352000000.0               -7.080000e+08   \n",
       "4      6.448000e+09          681000000.0               -5.400000e+07   \n",
       "\n",
       "   After Tax ROE  Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
       "0           23.0         -1.888000e+09     4.695000e+09        53.0   \n",
       "1           67.0         -3.114000e+09     1.059200e+10        75.0   \n",
       "2          143.0         -5.311000e+09     1.513500e+10        60.0   \n",
       "3          135.0         -6.151000e+09     1.159100e+10        51.0   \n",
       "4           92.0         -4.910000e+08     3.671000e+09       144.0   \n",
       "\n",
       "   Cash and Cash Equivalents  Changes in Inventories  Common Stocks  ...    \\\n",
       "0               1.330000e+09                     0.0    127000000.0  ...     \n",
       "1               2.175000e+09                     0.0      5000000.0  ...     \n",
       "2               1.768000e+09                     0.0      7000000.0  ...     \n",
       "3               1.085000e+09                     0.0      6000000.0  ...     \n",
       "4               9.595000e+09             -56000000.0     16000000.0  ...     \n",
       "\n",
       "   For Year  Estimated Shares Outstanding       open      close        low  \\\n",
       "0      2012                  3.350000e+08  12.850000  13.500000  12.840000   \n",
       "1      2013                  1.630222e+08  24.740000  25.250000  24.629999   \n",
       "2      2014                  7.169154e+08  53.900002  53.630001  53.320000   \n",
       "3      2015                  6.681299e+08  42.540001  42.349998  41.830002   \n",
       "4      2013                  1.600000e+09  52.990002  52.810001  52.360001   \n",
       "\n",
       "        high      volume  GICS Sector  GICS Sub Industry  trend  \n",
       "0  13.680000   7005600.0            5                  4    0.0  \n",
       "1  25.250000   7166600.0            5                  4    0.0  \n",
       "2  54.639999  10626000.0            5                  4    1.0  \n",
       "3  42.570000   6788900.0            5                  4    1.0  \n",
       "4  53.060001   3019700.0            4                 87    1.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(clean_data.loc[:, clean_data.columns != 'trend'], clean_data['trend'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 94.94\n",
      "Accuracy score (test): 90.93\n"
     ]
    }
   ],
   "source": [
    "#lbfgs would not converge\n",
    "#For small datasets, â€˜liblinearâ€™ is a good choice, whereas â€˜sagâ€™ and â€˜sagaâ€™ are faster for large ones.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "log_model = logreg.fit(X_train, Y_train)\n",
    "\n",
    "log_Y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_log = round(logreg.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_log)\n",
    "print(\"Accuracy score (test):\",test_acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.83 | ROC Train Error: 0.17\n",
      "ROC Test Accuracy: 0.76 | ROC Test Error: 0.24\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.57      0.56        42\n",
      "         1.0       0.95      0.95      0.95       366\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       408\n",
      "   macro avg       0.75      0.76      0.76       408\n",
      "weighted avg       0.91      0.91      0.91       408\n",
      "\n",
      "F1: 0.9493844049247606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=logreg\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, log_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, log_Y_pred))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "log_f1 = f1_score(Y_test,log_Y_pred)\n",
    "\n",
    "print('F1:',log_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 30, 'n_neighbors': 5, 'p': 1}\n",
      "0.8914646996838778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_neighbors': [2, 5, 10, 50, 100],\n",
    "    'p' : [1, 2],\n",
    "    'leaf_size' :[30,50]\n",
    "}\n",
    "\n",
    "knn_CV = GridSearchCV(estimator=knn, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "knn_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(knn_CV.best_params_)\n",
    "print(knn_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 92.1\n",
      "Accuracy score (test): 90.93\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=30, n_neighbors=5, p=1) \n",
    "knn_model = knn.fit(X_train, Y_train)  \n",
    "knn_Y_pred = knn.predict(X_test)  \n",
    "\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_knn = round(knn.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_knn)\n",
    "print(\"Accuracy score (test):\",test_acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.70 | ROC Train Error: 0.30\n",
      "ROC Test Accuracy: 0.60 | ROC Test Error: 0.40\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.21      0.33        42\n",
      "         1.0       0.92      0.99      0.95       366\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       408\n",
      "   macro avg       0.80      0.60      0.64       408\n",
      "weighted avg       0.89      0.91      0.89       408\n",
      "\n",
      "F1: 0.9513797634691196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=knn\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, knn_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, knn_Y_pred))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "knn_f1 = f1_score(Y_test,knn_Y_pred)\n",
    "\n",
    "print('F1:',knn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 30.24\n",
      "Accuracy score (test): 23.77\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian_model = gaussian.fit(X_train, Y_train) \n",
    "\n",
    "gaussian_Y_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_gaussian = round(gaussian.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_gaussian)\n",
    "print(\"Accuracy score (test):\",test_acc_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.57 | ROC Train Error: 0.43\n",
      "ROC Test Accuracy: 0.55 | ROC Test Error: 0.45\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.11      0.95      0.20        42\n",
      "         1.0       0.97      0.16      0.27       366\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       408\n",
      "   macro avg       0.54      0.55      0.24       408\n",
      "weighted avg       0.88      0.24      0.26       408\n",
      "\n",
      "F1: 0.26823529411764707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=gaussian\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, gaussian_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, gaussian_Y_pred))\n",
    "\n",
    "gaussian_f1 = f1_score(Y_test,gaussian_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',gaussian_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 89.71\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "svc_model = svc.fit(X_train, Y_train)\n",
    "\n",
    "svc_Y_pred = svc.predict(X_test)\n",
    "\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_svc = round(svc.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_svc)\n",
    "print(\"Accuracy score (test):\",test_acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 1.00 | ROC Train Error: 0.00\n",
      "ROC Test Accuracy: 0.50 | ROC Test Error: 0.50\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        42\n",
      "         1.0       0.90      1.00      0.95       366\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       408\n",
      "   macro avg       0.45      0.50      0.47       408\n",
      "weighted avg       0.80      0.90      0.85       408\n",
      "\n",
      "F1: 0.9457364341085273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=svc\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, svc_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, svc_Y_pred))\n",
    "\n",
    "svc_f1 = f1_score(Y_test,svc_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',svc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 1}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : depths,\n",
    "    'min_samples_leaf' :[1, 5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "decision_tree_CV = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "decision_tree_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(decision_tree_CV.best_params_)\n",
    "print(decision_tree_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 99.51\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth=2, min_samples_leaf=1) \n",
    "decision_tree_model = decision_tree.fit(X_train, Y_train)  \n",
    "decision_tree_Y_pred = decision_tree.predict(X_test)  \n",
    "\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_decision_tree = round(decision_tree.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_decision_tree)\n",
    "print(\"Accuracy score (test):\",test_acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 1.00 | ROC Train Error: 0.00\n",
      "ROC Test Accuracy: 0.99 | ROC Test Error: 0.01\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98        42\n",
      "         1.0       1.00      1.00      1.00       366\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       408\n",
      "   macro avg       0.99      0.99      0.99       408\n",
      "weighted avg       1.00      1.00      1.00       408\n",
      "\n",
      "F1: 0.9972677595628415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=decision_tree\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, decision_tree_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, decision_tree_Y_pred))\n",
    "\n",
    "dt_f1 = f1_score(Y_test,decision_tree_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',dt_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 99.51\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=decision_tree, n_estimators=180, random_state=1)\n",
    "ada_model = ada.fit(X_train, Y_train)\n",
    "\n",
    "ada_Y_pred = ada.predict(X_test)\n",
    "\n",
    "acc_ada = round(ada.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_ada = round(ada.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_ada)\n",
    "print(\"Accuracy score (test):\",test_acc_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 1.00 | ROC Train Error: 0.00\n",
      "ROC Test Accuracy: 0.99 | ROC Test Error: 0.01\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98        42\n",
      "         1.0       1.00      1.00      1.00       366\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       408\n",
      "   macro avg       0.99      0.99      0.99       408\n",
      "weighted avg       1.00      1.00      1.00       408\n",
      "\n",
      "F1: 0.9972677595628415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=ada\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, ada_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, ada_Y_pred))\n",
    "\n",
    "ada_f1 = f1_score(Y_test,ada_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',ada_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 97.79\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n",
    "    gt_model = gb.fit(X_train, Y_train)\n",
    "    \n",
    "    acc_gb = round(gb.score(X_train, Y_train) * 100, 2)\n",
    "    test_acc_gb = round(gb.score(X_test, Y_test) * 100, 2)\n",
    "    \n",
    "    gb_Y_pred = gb.predict(X_test)\n",
    "    \n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training):\",acc_gb)\n",
    "print(\"Accuracy score (test):\",test_acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 1.00 | ROC Train Error: 0.00\n",
      "ROC Test Accuracy: 0.97 | ROC Test Error: 0.03\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90        42\n",
      "         1.0       0.99      0.98      0.99       366\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       408\n",
      "   macro avg       0.92      0.97      0.94       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "F1: 0.9876203576341127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=gb\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, gb_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, gb_Y_pred))\n",
    "\n",
    "gb_f1 = f1_score(Y_test,gb_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.9989462592202318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : depths,\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "rf_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(rf_CV.best_params_)\n",
    "print(rf_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 99.26\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini', max_depth=7, max_features='auto', n_estimators=200)\n",
    "random_forest_model = random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_random_forest = round(random_forest.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_random_forest)\n",
    "print(\"Accuracy score (test):\",test_acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 1.00 | ROC Train Error: 0.00\n",
      "ROC Test Accuracy: 1.00 | ROC Test Error: 0.00\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97        42\n",
      "         1.0       1.00      0.99      1.00       366\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       408\n",
      "   macro avg       0.97      1.00      0.98       408\n",
      "weighted avg       0.99      0.99      0.99       408\n",
      "\n",
      "F1: 0.9958847736625513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=random_forest\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, random_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, random_Y_pred))\n",
    "\n",
    "rf_f1 = f1_score(Y_test,random_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income</th>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income Applicable to Common Shareholders</th>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earnings Before Tax</th>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earnings Before Interest and Tax</th>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income-Cont. Operations</th>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operating Income</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income Tax</th>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Recurring Items</th>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Tax Margin</th>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Income Adjustments</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GICS Sector</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Assets</th>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              importance\n",
       "feature                                                 \n",
       "Estimated Shares Outstanding                       0.270\n",
       "Net Income                                         0.102\n",
       "Net Income Applicable to Common Shareholders       0.100\n",
       "Earnings Before Tax                                0.071\n",
       "Earnings Before Interest and Tax                   0.064\n",
       "Net Income-Cont. Operations                        0.061\n",
       "Operating Income                                   0.029\n",
       "Income Tax                                         0.017\n",
       "Non-Recurring Items                                0.013\n",
       "Pre-Tax Margin                                     0.012\n",
       "Net Income Adjustments                             0.010\n",
       "GICS Sector                                        0.009\n",
       "volume                                             0.009\n",
       "Total Liabilities & Equity                         0.009\n",
       "Total Assets                                       0.008"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier()\n",
    "sgd.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.863013698630137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "sgd_CV = GridSearchCV(estimator=sgd, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "sgd_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(sgd_CV.best_params_)\n",
    "print(sgd_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 89.04\n",
      "Accuracy score (test): 88.24\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier(loss='hinge', penalty='l1',max_iter=1000)\n",
    "sgd_model = sgd.fit(X_train, Y_train)\n",
    "sgd_Y_pred = sgd.predict(X_test)\n",
    "\n",
    "sgd.score(X_train, Y_train)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_sgd = round(sgd.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_sgd)\n",
    "print(\"Accuracy score (test):\",test_acc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.74 | ROC Train Error: 0.26\n",
      "ROC Test Accuracy: 0.68 | ROC Test Error: 0.32\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.43      0.43        42\n",
      "         1.0       0.93      0.93      0.93       366\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       408\n",
      "   macro avg       0.68      0.68      0.68       408\n",
      "weighted avg       0.88      0.88      0.88       408\n",
      "\n",
      "F1: 0.9344262295081968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=sgd\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, sgd_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, sgd_Y_pred))\n",
    "\n",
    "sgd_f1 = f1_score(Y_test,sgd_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',sgd_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 88.2\n",
      "Accuracy score (test): 89.71\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(max_iter=5)\n",
    "perceptron_model = perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_Y_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_perceptron = round(perceptron.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_perceptron)\n",
    "print(\"Accuracy score (test):\",test_acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.53 | ROC Train Error: 0.47\n",
      "ROC Test Accuracy: 0.52 | ROC Test Error: 0.48\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.05      0.09        42\n",
      "         1.0       0.90      0.99      0.95       366\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       408\n",
      "   macro avg       0.70      0.52      0.52       408\n",
      "weighted avg       0.86      0.90      0.86       408\n",
      "\n",
      "F1: 0.9454545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=perceptron\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, perceptron_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, perceptron_Y_pred))\n",
    "\n",
    "perceptron_f1 = f1_score(Y_test,perceptron_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',perceptron_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99.51</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.51</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.26</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.79</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.93</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.93</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.71</th>\n",
       "      <td>Support Vector Classifier (SVC)</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.71</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88.24</th>\n",
       "      <td>Stochastic Gradient Descent (SGD)</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.77</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model    F1\n",
       "Score                                         \n",
       "99.51                     Decision Trees  1.00\n",
       "99.51                           AdaBoost  1.00\n",
       "99.26                      Random Forest  1.00\n",
       "97.79             Gradient Tree Boosting  0.99\n",
       "90.93                Logistic Regression  0.95\n",
       "90.93                K-Nearest Neighbors  0.95\n",
       "89.71    Support Vector Classifier (SVC)  0.95\n",
       "89.71                         Perceptron  0.95\n",
       "88.24  Stochastic Gradient Descent (SGD)  0.93\n",
       "23.77               Gaussian Naive Bayes  0.27"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression','K-Nearest Neighbors',\n",
    "             'Gaussian Naive Bayes','Support Vector Classifier (SVC)',\n",
    "             'Decision Trees','AdaBoost','Gradient Tree Boosting',\n",
    "             'Random Forest','Stochastic Gradient Descent (SGD)','Perceptron'],\n",
    "    'Score': [test_acc_log,\n",
    "              test_acc_knn,\n",
    "              test_acc_gaussian,\n",
    "              test_acc_svc,\n",
    "              test_acc_decision_tree,\n",
    "              test_acc_ada,\n",
    "              test_acc_gb,\n",
    "              test_acc_random_forest,\n",
    "              test_acc_sgd,\n",
    "              test_acc_perceptron],\n",
    "    'F1': [round(log_f1, 2),\n",
    "                round(knn_f1, 2),\n",
    "                round(gaussian_f1, 2),\n",
    "                round(svc_f1, 2),\n",
    "                round(dt_f1, 2),\n",
    "                round(ada_f1, 2),\n",
    "                round(gb_f1, 2),\n",
    "                round(rf_f1, 2),\n",
    "                round(sgd_f1, 2),\n",
    "                round(perceptron_f1, 2)\n",
    "                ]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_data2=clean_data.copy()\n",
    "#temp dropping trend\n",
    "clean_data2.drop(['trend'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fit_pca(df, n_components):\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(df)   \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    stscaler = StandardScaler().fit(df)\n",
    "    scaled = stscaler.transform(df)    \n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaled = standardize(clean_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = fit_pca(scaled, n_components=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFYxJREFUeJzt3X+wZGV95/H3BxEVUH6EgaAQRwlhZS0zkgExJKigBtCg7K6rVJIi5Q+ipRHcNRuMKRbXSpZojJvdMlokGNkEURNFiRoFCQgxQhyQH4MQER10AJlRk4UYjCLf/eOcG9vxdve5w3T3MM/7VdXVp/t+zzlP3+f2/fT59XSqCklSu3ZadAMkSYtlEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIat/OiGzDEPvvsU6tXr150MyTpIeWaa675RlWtmlb3kAiC1atXs27dukU3Q5IeUpLcPqTOXUOS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktS4h8SVxQ/G6jM+Nqhuw9nPm3FLJGn75BaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkho3syBIcmCSy5LcnOSmJKf1z++d5JIkt/b3e82qDZKk6Wa5RXA/8F+r6knAkcCrkxwKnAFcWlUHA5f2jyVJCzKzIKiqu6rq2n76XuBm4HHAC4Dz+rLzgBfOqg2SpOnmcowgyWrgqcDVwH5VdRd0YQHsO482SJKWN/MgSLI78EHg9Kq6ZwXznZpkXZJ1mzdvnl0DJalxMw2CJA+nC4Hzq+pD/dN3J9m///n+wKbl5q2qc6pqbVWtXbVq1SybKUlNm+VZQwHOBW6uqj8Y+dFFwCn99CnAR2bVBknSdLP8zuKjgF8BbkxyXf/cbwFnAx9I8jLgq8CLZtgGSdIUMwuCqvpbIGN+fOys1itJWhmvLJakxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxMwuCJO9OsinJ+pHnzkpyR5Lr+tsJs1q/JGmYWW4RvAc4bpnn315Va/rbx2e4fknSADMLgqq6AvjWrJYvSdo2FnGM4DVJbuh3He01rijJqUnWJVm3efPmebZPkpoy7yB4J3AQsAa4C3jbuMKqOqeq1lbV2lWrVs2rfZLUnLkGQVXdXVXfr6oHgD8Gjpjn+iVJP2quQZBk/5GHJwHrx9VKkuZj51ktOMkFwDOBfZJsBP478Mwka4ACNgC/Nqv1S5KGmVkQVNXJyzx97qzWJ0naOl5ZLEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjZsaBOn8cpIz+8c/kcTB4iRpBzFki+CPgKcDS0NG3Au8Y2YtkiTN1ZCxhp5WVYcl+TxAVf1jkl1m3C5J0pwM2SL4XpKH0Y0YSpJVwAMzbZUkaW6GBMH/Bi4E9k3yO8DfAr8701ZJkuZm6q6hqjo/yTXAsUCAF1bVzTNvmSRpLqYGQZIjgZuq6h3940cneVpVXT3z1kmSZm7IrqF3Av888vjb/XOSpB3AkCBIVdXSg/6L52f2zWaSpPkaEgRfTvLaJA/vb6cBX551wyRJ8zEkCF4J/CxwB7AReBpw6iwbJUmanyFnDW0CXjKHtkiSFmDIWUOrgFcAq0frq+qls2uWJGlehhz0/QhwJfAp4PuzbY4kad6GBMGuVfWbM2+JJGkhhhws/miSE2beEknSQgwJgtPowuC+JPckuTfJPbNumCRpPoacNfToeTREkrQYg64QTrIXcDDwyKXnquqKWTVKkjQ/Q04ffTnd7qEDgOuAI4HPAsfMtmmSpHkYeozgcOD2qnoW8FRg80xbJUmamyFB8J2q+g5AkkdU1S3AIbNtliRpXoYcI9iYZE/gw8AlSf4RuHO2zZIkzcuQs4ZO6ifPSnIZsAfwiZm2SpI0N2ODIMljquqeJHuPPH1jf7878K2ZtkySNBeTtgjeCzwfuAYouu8rHr1/4sxbJ0maubFBUFXPTxLgGVX11Tm2SZI0RxPPGuq/ovLCObVFkrQAQ04fvSrJ4TNviSRpIYYEwbOAzya5LckNSW5McsO0mZK8O8mmJOtHnts7ySVJbu3v93owjZckPXhDguB44CC6ISV+ke4A8i8OmO89wHFbPHcGcGlVHQxc2j+WJC3Q1CCoqtur6nbgPrqzhZZu0+a7gh89xfQFwHn99HnAC1fUWknSNjc1CJKcmORW4CvAp4ENwF9v5fr2q6q7APr7fbdyOZKkbWTIrqE30404+sWqegJwLPCZmbYKSHJqknVJ1m3e7Bh3kjQrQ4Lge1X1TWCnJDtV1WXAmq1c391J9gfo7zeNK6yqc6pqbVWtXbVq1VauTpI0zZAg+KckuwNXAucn+UPg/q1c30XAKf30KcBHtnI5kqRtZEgQXAHsSfe9BJ8AbmPAWUNJLqD7AptDkmxM8jLgbOA5/TGH5/SPJUkLNGQY6gCfpDsD6H3A+/tdRRNV1cljfnTs8OZJkmZtyOmjb6qqfw+8Gngs8Okkn5p5yyRJczFk19CSTcDXgW/iaZ+StMMYch3Bq5JcTncl8D7AK6rqKbNumCRpPoYcI3g8cHpVXTfrxmwPVp/xsUF1G85+3oxbIknzMeSrKh0PSJJ2YCs5RiBJ2gEZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1LidF7HSJBuAe4HvA/dX1dpFtEOStKAg6D2rqr6xwPVLknDXkCQ1b1FBUMDFSa5JcupyBUlOTbIuybrNmzfPuXmS1I5FBcFRVXUYcDzw6iRHb1lQVedU1dqqWrtq1ar5t1CSGrGQIKiqO/v7TcCFwBGLaIckaQFBkGS3JI9emgaeC6yfdzskSZ1FnDW0H3BhkqX1v7eqPrGAdkiSWEAQVNWXgZ+e93olSctb5HUEO4zVZ3xsUN2Gs58345ZI0sp5HYEkNc4tggVwC0LS9sQtAklqnEEgSY0zCCSpcQaBJDXOIJCkxnnW0EOAZxlJmiWDYAc1JDwMDkngriFJap5BIEmNMwgkqXEeIxDgAWmpZW4RSFLjDAJJapxBIEmN8xiBtorHFKQdh1sEktQ4twg0F25BSNsvtwgkqXEGgSQ1ziCQpMZ5jEDbrZWOoOpxCGnruEUgSY1zi0DNcgtC6rhFIEmNMwgkqXHuGpIGcleSdlRuEUhS49wikGZopVsRbnVoEQwC6SHM4NC2YBBIjZn1hXqG00OPQSBpobYmOLzqfNsyCCRpC60Fh0EgSQ/SrLZqtpxnVjx9VJIaZxBIUuMWEgRJjkvyD0m+lOSMRbRBktSZexAkeRjwDuB44FDg5CSHzrsdkqTOIrYIjgC+VFVfrqrvAu8DXrCAdkiSWEwQPA742sjjjf1zkqQFSFXNd4XJi4BfqKqX949/BTiiqn59i7pTgVP7h4cA/7ANm7EP8I0Z1s9jHS2+hnmsw9ewfaxjR2jTPF7DNI+vqlVTq6pqrjfg6cAnRx6/AXjDnNuwbpb181hHi69he2yTr2H7qN8e2zSP17CtbovYNfQ54OAkT0iyC/AS4KIFtEOSxAKuLK6q+5O8Bvgk8DDg3VV107zbIUnqLGSIiar6OPDxRay7d86M6+exjhZfwzzW4WvYPtaxI7RpHq9hm5j7wWJJ0vbFISYkqXHNBcFKhrdI8u4km5KsH7jsA5NcluTmJDclOW3API9M8vdJru/nedOAeR6W5PNJPjqwXRuS3JjkuiTrBtTvmeQvk9zSv5anT6k/pF/20u2eJKdPmed1/etdn+SCJI+cUn9aX3vTuGUv119J9k5ySZJb+/u9ptS/qF/HA0nWDlj+W/vf0w1JLkyy55T6N/e11yW5OMljp61j5GevT1JJ9pmyjrOS3DHSHydMW36SX+/fFzclecuU5b9/ZNkbklw34Pe0JslVS3+DSY6YUv/TST7b/93+VZLHjPxs2ffZuL6eUL9sX0+on9TX4+ZZtr/H1U/q65laxKlKi7rRHZy+DXgisAtwPXDohPqjgcOA9QOXvz9wWD/9aOCLk5bf1wXYvZ9+OHA1cOSUef4L8F7gowPbtQHYZwW/p/OAl/fTuwB7rvB3/HW685fH1TwO+ArwqP7xB4BfnVD/ZGA9sCvdca1PAQcP6S/gLcAZ/fQZwO9NqX8S3XUrlwNrByz/ucDO/fTvDVj+Y0amXwu8a8jfHHAg3QkWt4/25Zh1nAW8fujfNPCs/nf6iP7xvkPfA8DbgDMHrONi4Ph++gTg8in1nwOe0U+/FHjztPfZuL6eUL9sX0+on9TX4+ZZtr/H1U/q61neWtsiWNHwFlV1BfCtoQuvqruq6tp++l7gZqZcNV2df+4fPry/jT1wk+QA4HnAnwxt10r0n7yOBs7t2/fdqvqnFSziWOC2qrp9St3OwKOS7Ez3D/7OCbVPAq6qqn+pqvuBTwMnbVk0pr9eQBds9PcvnFRfVTdX1bIXL46pv7hvE8BVwAFT6u8ZebgbW/T1hL+5twP/bQX1yxpT/yrg7Kr6175m05DlJwnwn4ELBqyjgKVP9Xsw0t9j6g8BruinLwH+40j9uPfZsn09rn5cX0+on9TX4+ZZtr+n/K9Ytq9nqbUgmNvwFklWA0+l+4Q/rfZh/eb1JuCSqpo0z/+i+yN5YAXNKeDiJNeku2J7kicCm4E/Tbf76U+S7LaCdb2ELf4x/Ehjqu4Afh/4KnAX8P+q6uIJs6wHjk7yY0l2pftEeeDA9uxXVXf1670L2HfgfFvjpcBfTytK8jtJvgb8EnDmgPoTgTuq6voVtOU1/S6Jd2dkd9gYPwX8fJKrk3w6yeED1/HzwN1VdeuA2tOBt/av+/fpLiSdZD1wYj/9Isb09xbvs6l9vZL35ZT6sX295TzT+nu0fiv7+kFrLQiyzHPbPHWT7A58EDh9i08Ey6qq71fVGrpPGEckefKY5T4f2FRV16ywSUdV1WF0I76+OsnRE2p3pttMf2dVPRX4Nt1m9lTpLhA8EfiLKXV70X16ewLwWGC3JL88rr6qbqbbFL8E+ATdLr37x9UvQpI30rXp/Gm1VfXGqjqwr33NlOXuCryRAYEx4p3AQcAauqB925T6nYG9gCOB3wA+0H/an+ZkpoT+iFcBr+tf9+votzgneCnd3+o1dLtOvrtlwUrfZ9uqflJfLzfPpP4ere+XudK+3iZaC4KN/PAniwOYvEtixZI8nK5jz6+qD61k3n4XzOXAcWNKjgJOTLKBbrfWMUn+fMBy7+zvNwEX0u0iG2cjsHFkq+Qv6YJhiOOBa6vq7il1zwa+UlWbq+p7wIeAn500Q1WdW1WHVdXRdLsRhnwKBbg7yf4A/f2mKfUrluQU4PnAL1W/k3eg9zKyy2OMg+gC8/q+3w8Ark3y4+NmqKq7+w8XDwB/zOT+hq7PP9Tvpvx7uq3NiQcp+116/wF4/5RlLzmFrp+h+6AwsU1VdUtVPbeqfoYubG7bYv3Lvc/G9vVK35fj6if19YB1/FB/L1O/4r7eVloLgpkOb9F/ijoXuLmq/mDgPKuWzj5I8ii6f5K3LFdbVW+oqgOqajVd2/+mqsZ+ku6XuVuSRy9N0x3wGnsWVFV9HfhakkP6p44FvjDktTD8E+JXgSOT7Nr/zo6l20c6VpJ9+/ufoPsHNPST6EV0/4To7z8ycL5BkhwH/CZwYlX9y4D6g0censiYvl5SVTdW1b5Vtbrv9410Bxm/PmEd+488PIkJ/d37MHBMP+9P0Z0gMG3gs2cDt1TVxil1S+4EntFPH8OUIB/p752A3wbeNfKzce+zZft6pe/LcfWT+nrCPMv293L1W9PX20zN4Yj09nSj27/8RbpPGG+cUnsB3ab19/pOedmU+p+j29V0A3BdfzthyjxPAT7fz7OeLc7AmDDfMxlw1hDdPv/r+9tN015zP88aYF3fpg8Dew2YZ1fgm8AeA9v/Jro3xXrgz+jPWJlQfyVdIF0PHDu0v4AfAy6l+8dzKbD3lPqT+ul/Be7mhwdIXK7+S3THnZb6+11T6j/Yv+YbgL+iO6A4+G+OLc4AG7OOPwNu7NdxEbD/lPpdgD/v23UtcMy09gDvAV65gn74OeCavv+uBn5mSv1pdO/TLwJn01/8Oul9Nq6vJ9Qv29cT6if19bh5lu3vcfWT+nqWN68slqTGtbZrSJK0BYNAkhpnEEhS4wwCSWqcQSBJjTMItENJ8v1+pMf1Sf6ivzKXJD+e5H1JbkvyhSQf78+ZX5rvdUm+k2SPCct+az9S5Fu3ol1rMjIKqLQ9MQi0o7mvqtZU1ZPphiV4ZX/xzoV0I14eVFWHAr8F7Dcy38l0Fxz+yGB2I36N7gKf39iKdq2hO698sHR8j2rm/CPTjuxK4Cfphln+XlX929WpVXVdVV0JkOQgYHe6K1hPXm5BSS6iGz3y6iQv7q8I/2CSz/W3o/q6I5L8XboB+/4u3Xc17AL8D+DF/dbKi9N9Z8DrR5a/Psnq/nZzkj+iu7jrwCTPTTc2/7X9Vs7us/hlqV0GgXZI/Vg4x9NdYftkuqtax1kaGuNK4JCl4Q1GVdWJ/GBr4/3AHwJvr6rD6caPWRoW/Bbg6OoG7DsT+N3qhjw/E3j/yPyTHAL83/rBoH+/DTy7uoED19F9H4W0zSzky+ulGXpUfvCNWVfSjefyyinzvAQ4qaoeSPIhumGP3zFlnmcDh44M0vmYfkynPYDz+jFmiu77JVbq9qq6qp8+ku4LTj7Tr2sX4LNbsUxpLINAO5r7qhvS+98kuQn4T8sVJ3kKcDBwycg/2i8zPQh2Ap5eVfdtsbz/A1xWVSelG2f+8jHz388Pb5GPflXnt0cXSfcdFcvuspK2BXcNqQV/AzwiySuWnkhyeJJn0O0WOqv6ER+r6rHA45I8fsoyL2ZkbPkkS+GzB3BHP/2rI/X30o2rv2QD/fDeSQ6jG354OVcBRyX5yb5219GznaRtwSDQDq+6kRVPAp7Tnz56E933+t5Jt1vowi1mubB/fpLXAmvTfQvYF/jB7qe3AP8zyWfovr95yWV0u5KuS/JiulEp9+53Y72KbpTN5dq+mS5QLkhyA10w/Lvpr1oaztFHJalxbhFIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGvf/AZesYyQsn48sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Dataset Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "26.9%:     0.18 * f1 +  0.02 * f2 +  0.06 * f3 + -0.01 * f4 + -0.12 * f5 +  0.13 * f6 + -0.01 * f7 +  0.15 * f8 + -0.03 * f9 +  0.10 * f10 +  0.11 * f11 + -0.02 * f12 +  0.04 * f13 +  0.11 * f14 +  0.14 * f15 +  0.20 * f16 +  0.18 * f17 + -0.09 * f18 +  0.12 * f19 +  0.14 * f20 + -0.01 * f21 +  0.17 * f22 +  0.17 * f23 +  0.08 * f24 +  0.15 * f25 +  0.07 * f26 + -0.09 * f27 +  0.00 * f28 +  0.15 * f29 +  0.15 * f30 +  0.10 * f31 +  0.01 * f32 + -0.03 * f33 + -0.01 * f34 +  0.18 * f35 +  0.00 * f36 + -0.12 * f37 +  0.18 * f38 + -0.02 * f39 +  0.18 * f40 +  0.18 * f41 +  0.15 * f42 +  0.05 * f43 +  0.16 * f44 + -0.02 * f45 +  0.09 * f46 +  0.08 * f47 +  0.14 * f48 + -0.07 * f49 +  0.09 * f50 + -0.01 * f51 +  0.04 * f52 +  0.05 * f53 +  0.11 * f54 + -0.01 * f55 + -0.01 * f56 + -0.01 * f57 + -0.01 * f58 +  0.05 * f59 +  0.17 * f60 + -0.09 * f61 +  0.19 * f62 +  0.15 * f63 +  0.06 * f64 +  0.17 * f65 +  0.10 * f66 +  0.12 * f67 +  0.20 * f68 +  0.16 * f69 +  0.17 * f70 +  0.16 * f71 + -0.11 * f72 + -0.01 * f73 +  0.16 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 +  0.12 * f79 + -0.02 * f80 + -0.03 * f81\n",
      "11.3%:    -0.11 * f1 + -0.04 * f2 +  0.09 * f3 + -0.00 * f4 + -0.19 * f5 + -0.07 * f6 + -0.03 * f7 + -0.22 * f8 + -0.08 * f9 + -0.08 * f10 +  0.19 * f11 + -0.03 * f12 +  0.01 * f13 +  0.18 * f14 +  0.14 * f15 +  0.05 * f16 +  0.09 * f17 +  0.05 * f18 +  0.19 * f19 + -0.04 * f20 + -0.02 * f21 +  0.12 * f22 +  0.11 * f23 +  0.08 * f24 + -0.16 * f25 +  0.15 * f26 +  0.14 * f27 + -0.01 * f28 + -0.13 * f29 + -0.23 * f30 + -0.06 * f31 +  0.02 * f32 +  0.12 * f33 + -0.01 * f34 +  0.01 * f35 + -0.10 * f36 +  0.08 * f37 +  0.08 * f38 +  0.07 * f39 +  0.09 * f40 +  0.10 * f41 + -0.02 * f42 + -0.05 * f43 +  0.14 * f44 + -0.02 * f45 + -0.13 * f46 +  0.14 * f47 + -0.23 * f48 + -0.07 * f49 + -0.16 * f50 + -0.04 * f51 + -0.03 * f52 + -0.09 * f53 +  0.06 * f54 + -0.04 * f55 + -0.00 * f56 + -0.04 * f57 + -0.03 * f58 +  0.08 * f59 +  0.09 * f60 + -0.14 * f61 + -0.01 * f62 + -0.20 * f63 +  0.05 * f64 + -0.19 * f65 +  0.19 * f66 +  0.21 * f67 + -0.08 * f68 + -0.21 * f69 + -0.19 * f70 +  0.15 * f71 + -0.16 * f72 +  0.01 * f73 + -0.01 * f74 +  0.03 * f75 +  0.03 * f76 +  0.03 * f77 +  0.03 * f78 + -0.07 * f79 +  0.01 * f80 +  0.04 * f81\n",
      " 5.5%:     0.02 * f1 + -0.06 * f2 +  0.02 * f3 +  0.02 * f4 +  0.06 * f5 + -0.04 * f6 +  0.24 * f7 +  0.03 * f8 + -0.03 * f9 +  0.01 * f10 + -0.01 * f11 +  0.22 * f12 + -0.03 * f13 + -0.07 * f14 + -0.05 * f15 +  0.04 * f16 +  0.05 * f17 + -0.00 * f18 + -0.07 * f19 + -0.02 * f20 +  0.08 * f21 + -0.00 * f22 +  0.04 * f23 + -0.04 * f24 + -0.04 * f25 +  0.01 * f26 + -0.06 * f27 +  0.05 * f28 + -0.03 * f29 +  0.01 * f30 + -0.01 * f31 + -0.01 * f32 +  0.06 * f33 +  0.02 * f34 + -0.00 * f35 +  0.08 * f36 + -0.06 * f37 +  0.05 * f38 + -0.06 * f39 +  0.05 * f40 +  0.05 * f41 + -0.00 * f42 + -0.05 * f43 +  0.03 * f44 +  0.05 * f45 + -0.02 * f46 + -0.05 * f47 +  0.02 * f48 + -0.01 * f49 +  0.06 * f50 + -0.01 * f51 + -0.03 * f52 + -0.03 * f53 + -0.06 * f54 +  0.07 * f55 +  0.02 * f56 +  0.06 * f57 +  0.23 * f58 +  0.07 * f59 +  0.02 * f60 + -0.03 * f61 +  0.01 * f62 + -0.00 * f63 +  0.04 * f64 +  0.00 * f65 +  0.03 * f66 + -0.01 * f67 + -0.01 * f68 +  0.00 * f69 +  0.00 * f70 + -0.00 * f71 + -0.03 * f72 +  0.06 * f73 + -0.03 * f74 +  0.43 * f75 +  0.43 * f76 +  0.43 * f77 +  0.43 * f78 + -0.04 * f79 + -0.08 * f80 + -0.03 * f81\n",
      " 5.1%:    -0.02 * f1 +  0.20 * f2 + -0.01 * f3 +  0.05 * f4 + -0.03 * f5 +  0.08 * f6 +  0.10 * f7 + -0.05 * f8 +  0.04 * f9 +  0.04 * f10 + -0.06 * f11 +  0.07 * f12 +  0.01 * f13 +  0.03 * f14 +  0.08 * f15 + -0.05 * f16 + -0.08 * f17 + -0.11 * f18 + -0.00 * f19 +  0.05 * f20 +  0.17 * f21 +  0.08 * f22 + -0.08 * f23 +  0.07 * f24 +  0.11 * f25 + -0.05 * f26 +  0.22 * f27 + -0.18 * f28 +  0.15 * f29 + -0.01 * f30 +  0.03 * f31 + -0.01 * f32 + -0.30 * f33 + -0.02 * f34 +  0.08 * f35 + -0.38 * f36 +  0.27 * f37 + -0.08 * f38 +  0.27 * f39 + -0.07 * f40 + -0.07 * f41 +  0.05 * f42 +  0.20 * f43 +  0.01 * f44 +  0.22 * f45 +  0.01 * f46 +  0.03 * f47 + -0.03 * f48 + -0.08 * f49 + -0.27 * f50 + -0.02 * f51 +  0.01 * f52 +  0.19 * f53 +  0.05 * f54 +  0.18 * f55 +  0.05 * f56 +  0.19 * f57 +  0.09 * f58 +  0.08 * f59 + -0.01 * f60 + -0.03 * f61 +  0.00 * f62 +  0.06 * f63 +  0.07 * f64 +  0.01 * f65 +  0.02 * f66 + -0.01 * f67 +  0.03 * f68 +  0.01 * f69 +  0.01 * f70 + -0.05 * f71 + -0.01 * f72 +  0.04 * f73 +  0.04 * f74 +  0.05 * f75 +  0.05 * f76 +  0.05 * f77 +  0.05 * f78 +  0.04 * f79 +  0.01 * f80 +  0.04 * f81\n",
      " 4.4%:    -0.04 * f1 + -0.09 * f2 +  0.08 * f3 +  0.10 * f4 + -0.13 * f5 +  0.07 * f6 +  0.11 * f7 +  0.01 * f8 +  0.08 * f9 + -0.07 * f10 + -0.10 * f11 +  0.05 * f12 + -0.11 * f13 +  0.16 * f14 +  0.17 * f15 + -0.00 * f16 +  0.00 * f17 +  0.13 * f18 +  0.12 * f19 +  0.02 * f20 +  0.18 * f21 +  0.02 * f22 +  0.04 * f23 +  0.12 * f24 + -0.02 * f25 + -0.14 * f26 + -0.12 * f27 +  0.03 * f28 + -0.04 * f29 + -0.03 * f30 +  0.06 * f31 + -0.03 * f32 +  0.20 * f33 + -0.02 * f34 +  0.01 * f35 +  0.21 * f36 + -0.19 * f37 + -0.02 * f38 + -0.06 * f39 + -0.02 * f40 + -0.01 * f41 + -0.11 * f42 +  0.10 * f43 + -0.04 * f44 +  0.36 * f45 + -0.08 * f46 +  0.05 * f47 +  0.00 * f48 +  0.12 * f49 +  0.15 * f50 +  0.07 * f51 + -0.09 * f52 + -0.11 * f53 +  0.15 * f54 +  0.38 * f55 +  0.09 * f56 +  0.37 * f57 +  0.09 * f58 +  0.01 * f59 +  0.01 * f60 + -0.01 * f61 + -0.02 * f62 + -0.04 * f63 + -0.02 * f64 + -0.03 * f65 + -0.05 * f66 + -0.05 * f67 +  0.02 * f68 + -0.03 * f69 + -0.03 * f70 + -0.07 * f71 + -0.01 * f72 + -0.02 * f73 +  0.04 * f74 + -0.08 * f75 + -0.08 * f76 + -0.08 * f77 + -0.08 * f78 +  0.03 * f79 +  0.08 * f80 +  0.08 * f81\n",
      " 4.2%:    -0.01 * f1 + -0.14 * f2 + -0.11 * f3 + -0.01 * f4 +  0.11 * f5 +  0.03 * f6 +  0.23 * f7 + -0.03 * f8 + -0.00 * f9 +  0.18 * f10 + -0.01 * f11 +  0.24 * f12 +  0.15 * f13 + -0.08 * f14 + -0.00 * f15 + -0.06 * f16 + -0.06 * f17 + -0.13 * f18 + -0.14 * f19 +  0.11 * f20 + -0.01 * f21 + -0.04 * f22 + -0.11 * f23 +  0.09 * f24 + -0.04 * f25 +  0.04 * f26 +  0.05 * f27 +  0.18 * f28 + -0.04 * f29 + -0.02 * f30 + -0.09 * f31 + -0.01 * f32 +  0.11 * f33 +  0.07 * f34 + -0.04 * f35 +  0.06 * f36 + -0.01 * f37 + -0.02 * f38 + -0.01 * f39 + -0.02 * f40 + -0.05 * f41 +  0.14 * f42 + -0.03 * f43 + -0.03 * f44 + -0.02 * f45 +  0.05 * f46 +  0.12 * f47 + -0.05 * f48 +  0.04 * f49 +  0.02 * f50 + -0.21 * f51 +  0.09 * f52 + -0.12 * f53 + -0.08 * f54 + -0.01 * f55 + -0.01 * f56 + -0.00 * f57 +  0.25 * f58 +  0.29 * f59 + -0.13 * f60 + -0.06 * f61 + -0.03 * f62 + -0.02 * f63 +  0.34 * f64 + -0.01 * f65 +  0.26 * f66 +  0.12 * f67 + -0.02 * f68 + -0.01 * f69 + -0.01 * f70 + -0.01 * f71 +  0.07 * f72 +  0.02 * f73 +  0.19 * f74 + -0.12 * f75 + -0.12 * f76 + -0.12 * f77 + -0.12 * f78 +  0.22 * f79 + -0.02 * f80 + -0.03 * f81\n",
      " 3.7%:    -0.05 * f1 + -0.07 * f2 + -0.10 * f3 +  0.00 * f4 + -0.06 * f5 +  0.15 * f6 + -0.12 * f7 + -0.08 * f8 + -0.00 * f9 + -0.13 * f10 +  0.08 * f11 + -0.13 * f12 +  0.36 * f13 +  0.10 * f14 +  0.11 * f15 + -0.08 * f16 + -0.09 * f17 + -0.03 * f18 +  0.05 * f19 + -0.01 * f20 +  0.00 * f21 +  0.07 * f22 + -0.08 * f23 +  0.09 * f24 +  0.01 * f25 + -0.02 * f26 +  0.06 * f27 +  0.24 * f28 +  0.06 * f29 +  0.02 * f30 +  0.05 * f31 +  0.11 * f32 +  0.11 * f33 + -0.02 * f34 + -0.00 * f35 +  0.05 * f36 + -0.04 * f37 + -0.10 * f38 +  0.11 * f39 + -0.10 * f40 + -0.10 * f41 +  0.07 * f42 +  0.05 * f43 + -0.03 * f44 +  0.05 * f45 +  0.33 * f46 + -0.02 * f47 + -0.09 * f48 +  0.22 * f49 + -0.04 * f50 + -0.11 * f51 +  0.43 * f52 + -0.12 * f53 +  0.22 * f54 +  0.01 * f55 +  0.00 * f56 +  0.01 * f57 + -0.13 * f58 + -0.15 * f59 + -0.07 * f60 +  0.03 * f61 + -0.00 * f62 + -0.05 * f63 +  0.01 * f64 +  0.06 * f65 + -0.04 * f66 + -0.00 * f67 +  0.01 * f68 +  0.07 * f69 +  0.06 * f70 +  0.06 * f71 +  0.08 * f72 +  0.01 * f73 + -0.08 * f74 +  0.11 * f75 +  0.11 * f76 +  0.11 * f77 +  0.11 * f78 + -0.07 * f79 + -0.02 * f80 +  0.03 * f81\n",
      " 3.2%:    -0.12 * f1 +  0.18 * f2 +  0.07 * f3 + -0.11 * f4 +  0.01 * f5 +  0.07 * f6 +  0.26 * f7 + -0.05 * f8 +  0.14 * f9 + -0.15 * f10 + -0.08 * f11 +  0.27 * f12 +  0.17 * f13 +  0.05 * f14 + -0.07 * f15 +  0.10 * f16 +  0.13 * f17 +  0.13 * f18 + -0.01 * f19 + -0.12 * f20 +  0.06 * f21 +  0.04 * f22 +  0.13 * f23 + -0.05 * f24 + -0.12 * f25 + -0.19 * f26 + -0.07 * f27 + -0.14 * f28 + -0.05 * f29 +  0.02 * f30 +  0.01 * f31 + -0.08 * f32 + -0.02 * f33 + -0.01 * f34 +  0.06 * f35 + -0.09 * f36 +  0.04 * f37 +  0.13 * f38 + -0.06 * f39 +  0.13 * f40 +  0.13 * f41 + -0.07 * f42 + -0.13 * f43 +  0.11 * f44 + -0.11 * f45 +  0.20 * f46 + -0.07 * f47 + -0.04 * f48 +  0.19 * f49 + -0.09 * f50 +  0.12 * f51 +  0.26 * f52 +  0.08 * f53 +  0.04 * f54 + -0.08 * f55 + -0.11 * f56 + -0.08 * f57 +  0.28 * f58 + -0.00 * f59 +  0.07 * f60 + -0.05 * f61 + -0.05 * f62 + -0.11 * f63 +  0.05 * f64 +  0.02 * f65 + -0.12 * f66 + -0.17 * f67 +  0.03 * f68 +  0.02 * f69 +  0.02 * f70 + -0.06 * f71 + -0.06 * f72 + -0.08 * f73 + -0.08 * f74 + -0.10 * f75 + -0.10 * f76 + -0.10 * f77 + -0.10 * f78 + -0.13 * f79 +  0.03 * f80 +  0.06 * f81\n",
      " 3.0%:    -0.01 * f1 + -0.07 * f2 + -0.18 * f3 + -0.21 * f4 + -0.02 * f5 +  0.14 * f6 + -0.02 * f7 + -0.01 * f8 +  0.14 * f9 + -0.06 * f10 + -0.18 * f11 + -0.04 * f12 + -0.19 * f13 +  0.15 * f14 +  0.06 * f15 +  0.01 * f16 + -0.00 * f17 +  0.11 * f18 +  0.01 * f19 +  0.22 * f20 +  0.12 * f21 +  0.06 * f22 + -0.04 * f23 +  0.37 * f24 +  0.09 * f25 + -0.18 * f26 +  0.06 * f27 + -0.03 * f28 +  0.13 * f29 + -0.05 * f30 +  0.19 * f31 + -0.03 * f32 +  0.07 * f33 + -0.03 * f34 +  0.05 * f35 +  0.02 * f36 + -0.06 * f37 +  0.00 * f38 +  0.12 * f39 +  0.00 * f40 + -0.04 * f41 + -0.05 * f42 + -0.11 * f43 +  0.12 * f44 + -0.16 * f45 + -0.14 * f46 +  0.11 * f47 + -0.00 * f48 +  0.10 * f49 + -0.00 * f50 + -0.11 * f51 + -0.16 * f52 +  0.04 * f53 +  0.03 * f54 + -0.22 * f55 + -0.21 * f56 + -0.21 * f57 + -0.02 * f58 +  0.06 * f59 + -0.17 * f60 + -0.01 * f61 + -0.03 * f62 +  0.02 * f63 +  0.01 * f64 + -0.03 * f65 + -0.03 * f66 + -0.05 * f67 + -0.03 * f68 + -0.03 * f69 + -0.03 * f70 + -0.13 * f71 +  0.14 * f72 + -0.03 * f73 +  0.05 * f74 +  0.07 * f75 +  0.07 * f76 +  0.07 * f77 +  0.07 * f78 + -0.01 * f79 +  0.20 * f80 +  0.05 * f81\n",
      " 2.5%:     0.09 * f1 + -0.10 * f2 + -0.04 * f3 +  0.21 * f4 + -0.00 * f5 +  0.06 * f6 +  0.19 * f7 + -0.01 * f8 + -0.15 * f9 + -0.29 * f10 +  0.14 * f11 +  0.25 * f12 + -0.06 * f13 + -0.07 * f14 + -0.02 * f15 +  0.01 * f16 + -0.00 * f17 +  0.11 * f18 +  0.00 * f19 + -0.08 * f20 +  0.00 * f21 +  0.10 * f22 +  0.02 * f23 +  0.00 * f24 +  0.05 * f25 +  0.16 * f26 +  0.14 * f27 +  0.04 * f28 +  0.19 * f29 + -0.02 * f30 +  0.29 * f31 +  0.09 * f32 +  0.06 * f33 + -0.06 * f34 +  0.02 * f35 +  0.08 * f36 + -0.09 * f37 + -0.03 * f38 +  0.22 * f39 + -0.03 * f40 + -0.02 * f41 +  0.07 * f42 +  0.02 * f43 +  0.08 * f44 + -0.04 * f45 + -0.10 * f46 + -0.11 * f47 +  0.01 * f48 + -0.01 * f49 +  0.01 * f50 + -0.21 * f51 + -0.10 * f52 +  0.07 * f53 + -0.05 * f54 + -0.06 * f55 +  0.21 * f56 + -0.08 * f57 +  0.23 * f58 + -0.17 * f59 + -0.04 * f60 +  0.10 * f61 +  0.03 * f62 +  0.06 * f63 + -0.17 * f64 + -0.00 * f65 +  0.04 * f66 +  0.01 * f67 + -0.06 * f68 +  0.00 * f69 + -0.00 * f70 +  0.10 * f71 +  0.09 * f72 + -0.04 * f73 + -0.16 * f74 + -0.09 * f75 + -0.09 * f76 + -0.09 * f77 + -0.09 * f78 + -0.14 * f79 + -0.11 * f80 + -0.16 * f81\n",
      " 2.4%:    -0.03 * f1 +  0.07 * f2 + -0.13 * f3 +  0.55 * f4 +  0.12 * f5 +  0.06 * f6 + -0.11 * f7 + -0.01 * f8 +  0.08 * f9 + -0.01 * f10 + -0.11 * f11 + -0.16 * f12 +  0.04 * f13 + -0.03 * f14 + -0.06 * f15 +  0.04 * f16 +  0.05 * f17 +  0.06 * f18 + -0.13 * f19 +  0.07 * f20 +  0.04 * f21 +  0.02 * f22 +  0.00 * f23 +  0.12 * f24 + -0.06 * f25 + -0.09 * f26 + -0.08 * f27 + -0.10 * f28 + -0.01 * f29 + -0.00 * f30 +  0.01 * f31 + -0.06 * f32 +  0.05 * f33 + -0.10 * f34 +  0.05 * f35 + -0.03 * f36 + -0.02 * f37 +  0.09 * f38 + -0.05 * f39 +  0.09 * f40 +  0.05 * f41 + -0.04 * f42 + -0.13 * f43 +  0.09 * f44 + -0.04 * f45 +  0.04 * f46 +  0.05 * f47 + -0.01 * f48 +  0.04 * f49 + -0.02 * f50 +  0.01 * f51 +  0.06 * f52 +  0.08 * f53 + -0.06 * f54 + -0.06 * f55 +  0.56 * f56 + -0.06 * f57 + -0.15 * f58 +  0.15 * f59 + -0.07 * f60 + -0.15 * f61 + -0.02 * f62 + -0.06 * f63 +  0.14 * f64 + -0.00 * f65 +  0.01 * f66 + -0.00 * f67 + -0.05 * f68 +  0.00 * f69 + -0.00 * f70 + -0.08 * f71 + -0.01 * f72 + -0.00 * f73 +  0.03 * f74 +  0.02 * f75 +  0.02 * f76 +  0.02 * f77 +  0.02 * f78 + -0.07 * f79 + -0.02 * f80 + -0.01 * f81\n",
      " 2.1%:    -0.03 * f1 + -0.06 * f2 +  0.09 * f3 +  0.26 * f4 + -0.19 * f5 + -0.12 * f6 +  0.15 * f7 +  0.00 * f8 +  0.13 * f9 +  0.23 * f10 +  0.01 * f11 +  0.16 * f12 + -0.07 * f13 +  0.19 * f14 +  0.12 * f15 + -0.01 * f16 + -0.04 * f17 + -0.10 * f18 +  0.19 * f19 +  0.07 * f20 + -0.14 * f21 + -0.07 * f22 +  0.01 * f23 +  0.04 * f24 +  0.08 * f25 + -0.15 * f26 +  0.10 * f27 +  0.10 * f28 + -0.09 * f29 + -0.00 * f30 + -0.13 * f31 + -0.04 * f32 + -0.11 * f33 +  0.18 * f34 + -0.05 * f35 + -0.05 * f36 +  0.12 * f37 + -0.08 * f38 + -0.07 * f39 + -0.08 * f40 + -0.03 * f41 +  0.01 * f42 + -0.04 * f43 + -0.08 * f44 + -0.17 * f45 + -0.01 * f46 +  0.02 * f47 + -0.02 * f48 +  0.04 * f49 + -0.02 * f50 +  0.02 * f51 + -0.03 * f52 + -0.14 * f53 +  0.21 * f54 + -0.17 * f55 +  0.26 * f56 + -0.17 * f57 +  0.16 * f58 + -0.23 * f59 +  0.04 * f60 +  0.10 * f61 +  0.03 * f62 +  0.04 * f63 + -0.17 * f64 + -0.00 * f65 + -0.13 * f66 + -0.10 * f67 +  0.07 * f68 + -0.01 * f69 + -0.00 * f70 +  0.02 * f71 + -0.00 * f72 + -0.10 * f73 +  0.09 * f74 +  0.03 * f75 +  0.03 * f76 +  0.03 * f77 +  0.03 * f78 +  0.22 * f79 +  0.08 * f80 + -0.01 * f81\n",
      " 1.8%:    -0.09 * f1 + -0.28 * f2 +  0.17 * f3 +  0.02 * f4 +  0.01 * f5 + -0.02 * f6 + -0.04 * f7 + -0.04 * f8 +  0.13 * f9 + -0.02 * f10 + -0.17 * f11 + -0.06 * f12 + -0.01 * f13 + -0.04 * f14 + -0.13 * f15 +  0.07 * f16 +  0.05 * f17 + -0.20 * f18 + -0.03 * f19 + -0.13 * f20 +  0.24 * f21 +  0.07 * f22 +  0.07 * f23 + -0.11 * f24 +  0.10 * f25 + -0.21 * f26 +  0.15 * f27 +  0.31 * f28 +  0.12 * f29 + -0.01 * f30 + -0.07 * f31 + -0.17 * f32 +  0.03 * f33 + -0.12 * f34 + -0.08 * f35 +  0.05 * f36 + -0.01 * f37 +  0.05 * f38 +  0.22 * f39 +  0.05 * f40 +  0.07 * f41 +  0.05 * f42 +  0.23 * f43 +  0.10 * f44 + -0.04 * f45 +  0.03 * f46 + -0.06 * f47 + -0.03 * f48 + -0.28 * f49 +  0.04 * f50 + -0.01 * f51 +  0.03 * f52 + -0.22 * f53 + -0.09 * f54 + -0.08 * f55 +  0.03 * f56 + -0.09 * f57 + -0.03 * f58 +  0.09 * f59 +  0.13 * f60 + -0.03 * f61 + -0.02 * f62 +  0.10 * f63 + -0.00 * f64 + -0.01 * f65 + -0.07 * f66 + -0.09 * f67 + -0.03 * f68 + -0.00 * f69 + -0.01 * f70 + -0.14 * f71 + -0.19 * f72 + -0.03 * f73 + -0.07 * f74 + -0.02 * f75 + -0.02 * f76 + -0.02 * f77 + -0.02 * f78 + -0.10 * f79 +  0.03 * f80 +  0.11 * f81\n",
      " 1.6%:    -0.11 * f1 +  0.09 * f2 + -0.03 * f3 + -0.01 * f4 + -0.10 * f5 +  0.22 * f6 +  0.05 * f7 +  0.02 * f8 +  0.15 * f9 + -0.23 * f10 + -0.03 * f11 +  0.09 * f12 +  0.09 * f13 +  0.08 * f14 +  0.10 * f15 + -0.08 * f16 + -0.09 * f17 + -0.09 * f18 +  0.05 * f19 + -0.01 * f20 + -0.19 * f21 + -0.05 * f22 + -0.08 * f23 +  0.06 * f24 +  0.04 * f25 +  0.01 * f26 + -0.20 * f27 + -0.20 * f28 +  0.01 * f29 + -0.00 * f30 + -0.20 * f31 + -0.28 * f32 +  0.06 * f33 + -0.25 * f34 + -0.00 * f35 +  0.07 * f36 + -0.11 * f37 + -0.07 * f38 + -0.05 * f39 + -0.07 * f40 + -0.07 * f41 + -0.09 * f42 +  0.34 * f43 + -0.17 * f44 + -0.13 * f45 + -0.00 * f46 +  0.19 * f47 +  0.03 * f48 + -0.21 * f49 +  0.05 * f50 + -0.03 * f51 + -0.02 * f52 +  0.04 * f53 +  0.02 * f54 + -0.09 * f55 + -0.01 * f56 + -0.11 * f57 +  0.06 * f58 +  0.02 * f59 +  0.07 * f60 + -0.02 * f61 + -0.04 * f62 + -0.05 * f63 + -0.05 * f64 +  0.00 * f65 +  0.06 * f66 +  0.08 * f67 +  0.05 * f68 + -0.01 * f69 +  0.00 * f70 + -0.04 * f71 + -0.04 * f72 +  0.22 * f73 + -0.02 * f74 +  0.02 * f75 +  0.02 * f76 +  0.02 * f77 +  0.02 * f78 + -0.05 * f79 + -0.12 * f80 + -0.25 * f81\n",
      " 1.6%:    -0.03 * f1 + -0.19 * f2 + -0.03 * f3 + -0.04 * f4 +  0.10 * f5 +  0.04 * f6 +  0.05 * f7 + -0.01 * f8 + -0.24 * f9 + -0.04 * f10 +  0.02 * f11 +  0.07 * f12 + -0.10 * f13 +  0.02 * f14 + -0.01 * f15 +  0.01 * f16 + -0.01 * f17 + -0.02 * f18 + -0.11 * f19 +  0.15 * f20 +  0.06 * f21 +  0.05 * f22 +  0.01 * f23 +  0.19 * f24 +  0.08 * f25 +  0.06 * f26 + -0.02 * f27 +  0.10 * f28 + -0.04 * f29 + -0.01 * f30 + -0.23 * f31 +  0.21 * f32 + -0.11 * f33 + -0.50 * f34 + -0.08 * f35 + -0.15 * f36 +  0.07 * f37 +  0.00 * f38 + -0.14 * f39 +  0.01 * f40 + -0.01 * f41 + -0.08 * f42 + -0.05 * f43 +  0.01 * f44 + -0.01 * f45 +  0.03 * f46 + -0.15 * f47 + -0.01 * f48 +  0.01 * f49 +  0.01 * f50 +  0.09 * f51 +  0.02 * f52 + -0.05 * f53 +  0.11 * f54 +  0.02 * f55 + -0.04 * f56 +  0.02 * f57 +  0.05 * f58 + -0.05 * f59 + -0.05 * f60 + -0.41 * f61 +  0.09 * f62 + -0.01 * f63 + -0.18 * f64 + -0.01 * f65 + -0.18 * f66 + -0.09 * f67 + -0.05 * f68 + -0.01 * f69 + -0.01 * f70 +  0.04 * f71 + -0.01 * f72 +  0.02 * f73 +  0.08 * f74 + -0.03 * f75 + -0.03 * f76 + -0.03 * f77 + -0.03 * f78 +  0.11 * f79 + -0.10 * f80 + -0.07 * f81\n",
      " 1.4%:     0.02 * f1 + -0.05 * f2 +  0.02 * f3 + -0.03 * f4 + -0.00 * f5 + -0.16 * f6 + -0.08 * f7 +  0.01 * f8 +  0.26 * f9 +  0.10 * f10 + -0.02 * f11 + -0.01 * f12 +  0.11 * f13 +  0.00 * f14 +  0.03 * f15 +  0.00 * f16 +  0.02 * f17 + -0.10 * f18 +  0.04 * f19 + -0.01 * f20 + -0.08 * f21 + -0.10 * f22 +  0.02 * f23 + -0.06 * f24 + -0.09 * f25 + -0.22 * f26 +  0.16 * f27 + -0.15 * f28 + -0.01 * f29 + -0.01 * f30 + -0.06 * f31 +  0.07 * f32 +  0.05 * f33 + -0.25 * f34 +  0.06 * f35 +  0.03 * f36 + -0.12 * f37 +  0.02 * f38 + -0.09 * f39 +  0.02 * f40 +  0.06 * f41 +  0.30 * f42 + -0.29 * f43 + -0.02 * f44 +  0.08 * f45 + -0.06 * f46 + -0.09 * f47 +  0.00 * f48 + -0.10 * f49 +  0.01 * f50 + -0.51 * f51 + -0.05 * f52 +  0.23 * f53 +  0.08 * f54 +  0.10 * f55 + -0.04 * f56 +  0.09 * f57 +  0.01 * f58 + -0.17 * f59 +  0.05 * f60 + -0.05 * f61 + -0.07 * f62 + -0.01 * f63 + -0.06 * f64 + -0.01 * f65 +  0.00 * f66 + -0.07 * f67 + -0.03 * f68 + -0.01 * f69 + -0.01 * f70 + -0.03 * f71 + -0.07 * f72 +  0.17 * f73 + -0.00 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 + -0.04 * f79 +  0.01 * f80 + -0.02 * f81\n",
      " 1.3%:     0.08 * f1 +  0.01 * f2 +  0.07 * f3 +  0.00 * f4 + -0.11 * f5 + -0.13 * f6 + -0.02 * f7 + -0.01 * f8 +  0.01 * f9 +  0.09 * f10 +  0.03 * f11 + -0.00 * f12 +  0.04 * f13 +  0.04 * f14 +  0.05 * f15 + -0.04 * f16 + -0.05 * f17 +  0.24 * f18 +  0.12 * f19 + -0.23 * f20 + -0.15 * f21 + -0.01 * f22 + -0.04 * f23 + -0.16 * f24 +  0.02 * f25 +  0.04 * f26 +  0.09 * f27 +  0.03 * f28 +  0.04 * f29 +  0.01 * f30 +  0.10 * f31 + -0.39 * f32 + -0.07 * f33 + -0.44 * f34 + -0.01 * f35 + -0.03 * f36 + -0.07 * f37 + -0.06 * f38 +  0.09 * f39 + -0.06 * f40 + -0.02 * f41 +  0.12 * f42 + -0.00 * f43 + -0.05 * f44 + -0.01 * f45 + -0.03 * f46 +  0.01 * f47 + -0.00 * f48 +  0.24 * f49 +  0.08 * f50 +  0.10 * f51 + -0.01 * f52 +  0.02 * f53 + -0.17 * f54 +  0.00 * f55 + -0.00 * f56 + -0.00 * f57 + -0.01 * f58 + -0.02 * f59 + -0.06 * f60 + -0.19 * f61 +  0.03 * f62 +  0.07 * f63 +  0.17 * f64 +  0.02 * f65 +  0.08 * f66 +  0.04 * f67 + -0.00 * f68 +  0.02 * f69 +  0.02 * f70 +  0.01 * f71 +  0.11 * f72 + -0.32 * f73 +  0.03 * f74 +  0.04 * f75 +  0.05 * f76 +  0.04 * f77 +  0.04 * f78 +  0.16 * f79 +  0.13 * f80 +  0.03 * f81\n",
      " 1.3%:    -0.08 * f1 + -0.13 * f2 +  0.04 * f3 +  0.06 * f4 + -0.07 * f5 +  0.01 * f6 +  0.04 * f7 + -0.01 * f8 +  0.05 * f9 + -0.04 * f10 +  0.07 * f11 + -0.01 * f12 + -0.01 * f13 +  0.01 * f14 + -0.05 * f15 + -0.00 * f16 + -0.02 * f17 +  0.07 * f18 +  0.10 * f19 + -0.11 * f20 +  0.13 * f21 +  0.00 * f22 +  0.01 * f23 + -0.23 * f24 +  0.09 * f25 +  0.01 * f26 + -0.10 * f27 + -0.18 * f28 +  0.03 * f29 + -0.01 * f30 + -0.22 * f31 +  0.54 * f32 + -0.08 * f33 + -0.12 * f34 +  0.04 * f35 +  0.06 * f36 + -0.11 * f37 + -0.01 * f38 + -0.02 * f39 + -0.01 * f40 + -0.02 * f41 + -0.05 * f42 +  0.22 * f43 + -0.05 * f44 + -0.06 * f45 +  0.02 * f46 + -0.02 * f47 +  0.00 * f48 + -0.05 * f49 +  0.12 * f50 + -0.03 * f51 + -0.01 * f52 +  0.19 * f53 +  0.10 * f54 + -0.14 * f55 +  0.06 * f56 + -0.08 * f57 +  0.03 * f58 +  0.08 * f59 + -0.04 * f60 +  0.08 * f61 + -0.04 * f62 + -0.01 * f63 +  0.21 * f64 + -0.01 * f65 +  0.09 * f66 +  0.02 * f67 +  0.03 * f68 + -0.01 * f69 + -0.01 * f70 +  0.05 * f71 +  0.16 * f72 + -0.11 * f73 +  0.03 * f74 +  0.02 * f75 +  0.02 * f76 +  0.02 * f77 +  0.02 * f78 + -0.02 * f79 +  0.37 * f80 +  0.17 * f81\n",
      " 1.2%:     0.11 * f1 +  0.38 * f2 + -0.06 * f3 +  0.04 * f4 +  0.00 * f5 +  0.01 * f6 +  0.08 * f7 +  0.03 * f8 +  0.06 * f9 + -0.01 * f10 +  0.05 * f11 +  0.03 * f12 +  0.00 * f13 + -0.01 * f14 +  0.00 * f15 + -0.05 * f16 + -0.05 * f17 + -0.02 * f18 +  0.07 * f19 + -0.05 * f20 +  0.02 * f21 +  0.03 * f22 + -0.07 * f23 + -0.10 * f24 + -0.04 * f25 +  0.05 * f26 + -0.02 * f27 +  0.12 * f28 +  0.08 * f29 +  0.02 * f30 +  0.20 * f31 +  0.14 * f32 +  0.14 * f33 + -0.24 * f34 + -0.15 * f35 +  0.00 * f36 +  0.04 * f37 + -0.03 * f38 + -0.04 * f39 + -0.04 * f40 + -0.02 * f41 +  0.00 * f42 + -0.06 * f43 + -0.01 * f44 + -0.03 * f45 + -0.09 * f46 + -0.04 * f47 +  0.03 * f48 +  0.04 * f49 + -0.09 * f50 +  0.07 * f51 + -0.07 * f52 + -0.28 * f53 + -0.05 * f54 + -0.11 * f55 +  0.04 * f56 + -0.05 * f57 +  0.04 * f58 +  0.02 * f59 +  0.07 * f60 + -0.01 * f61 +  0.02 * f62 +  0.06 * f63 +  0.02 * f64 +  0.02 * f65 + -0.03 * f66 + -0.01 * f67 +  0.04 * f68 +  0.02 * f69 +  0.02 * f70 +  0.03 * f71 + -0.08 * f72 +  0.53 * f73 +  0.03 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 +  0.09 * f79 +  0.18 * f80 +  0.37 * f81\n",
      " 1.2%:     0.00 * f1 +  0.24 * f2 + -0.24 * f3 + -0.01 * f4 +  0.03 * f5 +  0.16 * f6 + -0.03 * f7 + -0.01 * f8 +  0.01 * f9 + -0.09 * f10 + -0.00 * f11 +  0.01 * f12 +  0.14 * f13 + -0.06 * f14 +  0.06 * f15 + -0.05 * f16 + -0.05 * f17 +  0.10 * f18 +  0.00 * f19 +  0.04 * f20 +  0.17 * f21 +  0.02 * f22 + -0.11 * f23 +  0.01 * f24 + -0.00 * f25 +  0.02 * f26 + -0.01 * f27 + -0.12 * f28 +  0.01 * f29 + -0.01 * f30 +  0.02 * f31 +  0.05 * f32 +  0.04 * f33 + -0.06 * f34 + -0.16 * f35 +  0.05 * f36 +  0.04 * f37 + -0.01 * f38 + -0.21 * f39 + -0.01 * f40 + -0.02 * f41 +  0.13 * f42 + -0.01 * f43 + -0.03 * f44 +  0.04 * f45 + -0.08 * f46 + -0.07 * f47 + -0.01 * f48 + -0.23 * f49 +  0.02 * f50 + -0.15 * f51 + -0.03 * f52 + -0.17 * f53 +  0.03 * f54 + -0.06 * f55 + -0.02 * f56 + -0.02 * f57 +  0.02 * f58 +  0.03 * f59 +  0.14 * f60 +  0.10 * f61 +  0.00 * f62 + -0.00 * f63 + -0.12 * f64 + -0.02 * f65 +  0.01 * f66 +  0.00 * f67 +  0.03 * f68 + -0.02 * f69 + -0.02 * f70 + -0.00 * f71 + -0.23 * f72 + -0.57 * f73 +  0.07 * f74 +  0.02 * f75 +  0.02 * f76 +  0.02 * f77 +  0.02 * f78 +  0.12 * f79 + -0.17 * f80 +  0.22 * f81\n",
      " 1.2%:    -0.02 * f1 + -0.11 * f2 + -0.23 * f3 + -0.02 * f4 + -0.08 * f5 + -0.13 * f6 +  0.00 * f7 + -0.00 * f8 +  0.04 * f9 +  0.10 * f10 +  0.04 * f11 +  0.01 * f12 + -0.13 * f13 + -0.01 * f14 +  0.04 * f15 + -0.03 * f16 + -0.02 * f17 +  0.03 * f18 + -0.01 * f19 + -0.04 * f20 + -0.03 * f21 +  0.07 * f22 +  0.04 * f23 + -0.01 * f24 + -0.07 * f25 + -0.08 * f26 +  0.00 * f27 + -0.10 * f28 + -0.09 * f29 + -0.01 * f30 +  0.01 * f31 + -0.01 * f32 +  0.01 * f33 +  0.04 * f34 +  0.12 * f35 +  0.05 * f36 + -0.11 * f37 + -0.06 * f38 +  0.20 * f39 + -0.06 * f40 + -0.03 * f41 + -0.01 * f42 +  0.18 * f43 + -0.04 * f44 + -0.06 * f45 + -0.04 * f46 + -0.17 * f47 +  0.00 * f48 +  0.11 * f49 +  0.10 * f50 +  0.06 * f51 + -0.03 * f52 +  0.15 * f53 +  0.14 * f54 + -0.07 * f55 + -0.01 * f56 + -0.11 * f57 + -0.02 * f58 + -0.00 * f59 +  0.05 * f60 + -0.09 * f61 +  0.07 * f62 + -0.02 * f63 +  0.20 * f64 + -0.02 * f65 + -0.04 * f66 + -0.09 * f67 +  0.02 * f68 + -0.02 * f69 + -0.02 * f70 +  0.06 * f71 + -0.02 * f72 +  0.11 * f73 +  0.05 * f74 + -0.02 * f75 + -0.02 * f76 + -0.02 * f77 + -0.02 * f78 +  0.01 * f79 + -0.59 * f80 +  0.41 * f81\n",
      " 1.1%:    -0.00 * f1 +  0.15 * f2 +  0.38 * f3 + -0.02 * f4 +  0.01 * f5 +  0.04 * f6 + -0.07 * f7 +  0.00 * f8 +  0.30 * f9 + -0.10 * f10 +  0.04 * f11 + -0.06 * f12 + -0.03 * f13 + -0.07 * f14 + -0.08 * f15 +  0.06 * f16 +  0.06 * f17 +  0.11 * f18 + -0.10 * f19 +  0.01 * f20 + -0.01 * f21 +  0.02 * f22 +  0.07 * f23 + -0.02 * f24 +  0.04 * f25 + -0.17 * f26 +  0.01 * f27 +  0.05 * f28 +  0.07 * f29 + -0.00 * f30 +  0.02 * f31 +  0.28 * f32 + -0.02 * f33 + -0.06 * f34 + -0.14 * f35 + -0.05 * f36 +  0.12 * f37 +  0.06 * f38 + -0.05 * f39 +  0.06 * f40 +  0.05 * f41 +  0.04 * f42 +  0.14 * f43 +  0.03 * f44 + -0.09 * f45 + -0.11 * f46 +  0.18 * f47 +  0.02 * f48 +  0.20 * f49 + -0.08 * f50 + -0.08 * f51 + -0.12 * f52 + -0.25 * f53 +  0.01 * f54 +  0.06 * f55 + -0.02 * f56 +  0.02 * f57 + -0.05 * f58 + -0.09 * f59 + -0.09 * f60 +  0.02 * f61 + -0.02 * f62 +  0.04 * f63 +  0.16 * f64 + -0.01 * f65 +  0.06 * f66 + -0.01 * f67 +  0.03 * f68 + -0.02 * f69 + -0.01 * f70 +  0.02 * f71 +  0.21 * f72 + -0.05 * f73 +  0.02 * f74 +  0.01 * f75 +  0.02 * f76 +  0.01 * f77 +  0.01 * f78 +  0.10 * f79 + -0.40 * f80 + -0.17 * f81\n",
      " 1.1%:     0.06 * f1 +  0.10 * f2 + -0.28 * f3 + -0.04 * f4 + -0.05 * f5 + -0.22 * f6 +  0.01 * f7 +  0.00 * f8 +  0.19 * f9 +  0.18 * f10 + -0.05 * f11 + -0.01 * f12 + -0.05 * f13 + -0.02 * f14 +  0.03 * f15 + -0.07 * f16 + -0.06 * f17 +  0.14 * f18 +  0.06 * f19 +  0.00 * f20 +  0.15 * f21 +  0.10 * f22 + -0.07 * f23 + -0.14 * f24 + -0.09 * f25 + -0.09 * f26 +  0.00 * f27 + -0.02 * f28 + -0.06 * f29 + -0.00 * f30 +  0.14 * f31 +  0.26 * f32 +  0.07 * f33 + -0.02 * f34 + -0.02 * f35 +  0.04 * f36 + -0.03 * f37 + -0.06 * f38 +  0.21 * f39 + -0.07 * f40 + -0.04 * f41 +  0.02 * f42 + -0.04 * f43 + -0.03 * f44 +  0.02 * f45 +  0.04 * f46 +  0.02 * f47 + -0.01 * f48 + -0.09 * f49 +  0.05 * f50 +  0.21 * f51 +  0.05 * f52 + -0.09 * f53 +  0.11 * f54 + -0.04 * f55 + -0.03 * f56 + -0.05 * f57 +  0.01 * f58 +  0.11 * f59 +  0.13 * f60 + -0.13 * f61 +  0.10 * f62 +  0.00 * f63 +  0.05 * f64 +  0.01 * f65 + -0.04 * f66 +  0.00 * f67 + -0.02 * f68 +  0.01 * f69 +  0.01 * f70 + -0.00 * f71 + -0.19 * f72 + -0.02 * f73 + -0.07 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 +  0.00 * f79 + -0.00 * f80 + -0.58 * f81\n",
      " 0.9%:    -0.14 * f1 +  0.12 * f2 + -0.05 * f3 +  0.00 * f4 + -0.03 * f5 +  0.03 * f6 + -0.08 * f7 + -0.01 * f8 + -0.41 * f9 +  0.04 * f10 + -0.12 * f11 + -0.03 * f12 + -0.08 * f13 +  0.08 * f14 +  0.04 * f15 +  0.07 * f16 +  0.05 * f17 +  0.36 * f18 +  0.05 * f19 + -0.04 * f20 + -0.12 * f21 + -0.01 * f22 +  0.04 * f23 + -0.05 * f24 +  0.09 * f25 + -0.09 * f26 +  0.02 * f27 + -0.09 * f28 +  0.03 * f29 +  0.02 * f30 + -0.09 * f31 + -0.09 * f32 + -0.02 * f33 +  0.12 * f34 + -0.11 * f35 +  0.01 * f36 +  0.08 * f37 +  0.06 * f38 +  0.01 * f39 +  0.07 * f40 +  0.06 * f41 +  0.07 * f42 +  0.19 * f43 +  0.02 * f44 + -0.02 * f45 + -0.01 * f46 + -0.36 * f47 +  0.01 * f48 +  0.01 * f49 +  0.03 * f50 + -0.34 * f51 +  0.00 * f52 + -0.21 * f53 +  0.12 * f54 +  0.00 * f55 +  0.00 * f56 + -0.01 * f57 + -0.05 * f58 +  0.08 * f59 +  0.02 * f60 + -0.00 * f61 + -0.06 * f62 + -0.01 * f63 +  0.20 * f64 +  0.01 * f65 + -0.00 * f66 + -0.16 * f67 +  0.05 * f68 +  0.00 * f69 +  0.01 * f70 + -0.08 * f71 + -0.01 * f72 +  0.17 * f73 +  0.00 * f74 +  0.01 * f75 +  0.00 * f76 +  0.01 * f77 +  0.01 * f78 +  0.07 * f79 +  0.08 * f80 + -0.18 * f81\n",
      " 0.9%:     0.05 * f1 + -0.00 * f2 +  0.09 * f3 +  0.01 * f4 + -0.15 * f5 + -0.02 * f6 +  0.01 * f7 + -0.01 * f8 + -0.31 * f9 + -0.01 * f10 + -0.13 * f11 + -0.09 * f12 +  0.08 * f13 +  0.07 * f14 +  0.06 * f15 + -0.03 * f16 + -0.03 * f17 + -0.07 * f18 +  0.17 * f19 + -0.14 * f20 +  0.62 * f21 + -0.00 * f22 + -0.03 * f23 + -0.10 * f24 + -0.05 * f25 + -0.03 * f26 +  0.05 * f27 + -0.03 * f28 + -0.03 * f29 + -0.03 * f30 + -0.01 * f31 + -0.08 * f32 + -0.04 * f33 + -0.07 * f34 +  0.00 * f35 +  0.03 * f36 + -0.04 * f37 + -0.02 * f38 + -0.19 * f39 + -0.02 * f40 +  0.01 * f41 + -0.04 * f42 + -0.14 * f43 + -0.02 * f44 + -0.03 * f45 +  0.03 * f46 +  0.09 * f47 + -0.03 * f48 +  0.10 * f49 + -0.01 * f50 + -0.03 * f51 +  0.01 * f52 +  0.15 * f53 + -0.11 * f54 + -0.12 * f55 +  0.01 * f56 + -0.11 * f57 + -0.03 * f58 + -0.07 * f59 + -0.02 * f60 +  0.20 * f61 +  0.06 * f62 +  0.01 * f63 +  0.02 * f64 + -0.01 * f65 +  0.02 * f66 +  0.05 * f67 +  0.02 * f68 + -0.01 * f69 + -0.01 * f70 + -0.10 * f71 +  0.08 * f72 +  0.17 * f73 +  0.11 * f74 + -0.01 * f75 + -0.01 * f76 + -0.01 * f77 + -0.01 * f78 +  0.18 * f79 + -0.22 * f80 + -0.14 * f81\n"
     ]
    }
   ],
   "source": [
    "vars = pca.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10',\n",
    "           'f11','f12','f13','f14','f15','f16','f17','f18','f19','f20',\n",
    "           'f21','f22','f23','f24','f25','f26','f27','f28','f29','f30',\n",
    "           'f31','f32','f33','f34','f35','f36','f37','f38','f39','f40',\n",
    "           'f41','f42','f43','f44','f45','f46','f47','f48','f49','f50',\n",
    "           'f51','f52','f53','f54','f55','f56','f57','f58','f59','f60',\n",
    "           'f61','f62','f63','f64','f65','f66','f67','f68','f69','f70',\n",
    "           'f71','f72','f73','f74','f75','f76','f77','f78','f79','f80',\n",
    "           'f81','f82']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(pca.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "reduced = pca.fit_transform(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.457071</td>\n",
       "      <td>-0.523728</td>\n",
       "      <td>-2.156216</td>\n",
       "      <td>-0.045154</td>\n",
       "      <td>-0.771425</td>\n",
       "      <td>0.655774</td>\n",
       "      <td>0.435635</td>\n",
       "      <td>-1.287651</td>\n",
       "      <td>0.709629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>0.058232</td>\n",
       "      <td>-0.142471</td>\n",
       "      <td>-0.552857</td>\n",
       "      <td>-0.047765</td>\n",
       "      <td>-0.955456</td>\n",
       "      <td>0.769690</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>-1.241286</td>\n",
       "      <td>1.097445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.827453</td>\n",
       "      <td>-0.276551</td>\n",
       "      <td>-1.713066</td>\n",
       "      <td>0.047274</td>\n",
       "      <td>-0.450880</td>\n",
       "      <td>1.385299</td>\n",
       "      <td>0.706473</td>\n",
       "      <td>-1.452406</td>\n",
       "      <td>1.192144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515025</td>\n",
       "      <td>-0.174743</td>\n",
       "      <td>-0.766355</td>\n",
       "      <td>-1.187277</td>\n",
       "      <td>-0.585611</td>\n",
       "      <td>-1.267406</td>\n",
       "      <td>0.484515</td>\n",
       "      <td>0.443640</td>\n",
       "      <td>-0.580105</td>\n",
       "      <td>0.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.492694</td>\n",
       "      <td>1.122087</td>\n",
       "      <td>-0.909513</td>\n",
       "      <td>0.232302</td>\n",
       "      <td>-0.346639</td>\n",
       "      <td>0.085384</td>\n",
       "      <td>-0.196430</td>\n",
       "      <td>-0.913378</td>\n",
       "      <td>0.359606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815817</td>\n",
       "      <td>0.108854</td>\n",
       "      <td>0.296950</td>\n",
       "      <td>-0.859227</td>\n",
       "      <td>-0.025868</td>\n",
       "      <td>-0.795227</td>\n",
       "      <td>0.278938</td>\n",
       "      <td>0.539054</td>\n",
       "      <td>-0.520791</td>\n",
       "      <td>-0.234904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.321122</td>\n",
       "      <td>1.461731</td>\n",
       "      <td>-0.899096</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>-0.041099</td>\n",
       "      <td>0.010702</td>\n",
       "      <td>-0.167971</td>\n",
       "      <td>-0.270415</td>\n",
       "      <td>0.134538</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341069</td>\n",
       "      <td>-1.013491</td>\n",
       "      <td>0.150453</td>\n",
       "      <td>-1.014577</td>\n",
       "      <td>0.378935</td>\n",
       "      <td>-0.035479</td>\n",
       "      <td>-0.139811</td>\n",
       "      <td>0.141502</td>\n",
       "      <td>0.203001</td>\n",
       "      <td>-0.170075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679561</td>\n",
       "      <td>0.685771</td>\n",
       "      <td>0.538065</td>\n",
       "      <td>1.340784</td>\n",
       "      <td>0.640833</td>\n",
       "      <td>1.700319</td>\n",
       "      <td>-1.685896</td>\n",
       "      <td>1.122334</td>\n",
       "      <td>0.098372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672627</td>\n",
       "      <td>-0.647640</td>\n",
       "      <td>0.079995</td>\n",
       "      <td>1.259658</td>\n",
       "      <td>-1.086763</td>\n",
       "      <td>-1.020304</td>\n",
       "      <td>-0.737110</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>-0.296795</td>\n",
       "      <td>0.750157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trend         0         1         2         3         4         5  \\\n",
       "0      0 -1.457071 -0.523728 -2.156216 -0.045154 -0.771425  0.655774   \n",
       "1      0 -0.827453 -0.276551 -1.713066  0.047274 -0.450880  1.385299   \n",
       "2      1  1.492694  1.122087 -0.909513  0.232302 -0.346639  0.085384   \n",
       "3      1  2.321122  1.461731 -0.899096  0.089489 -0.041099  0.010702   \n",
       "4      1  0.679561  0.685771  0.538065  1.340784  0.640833  1.700319   \n",
       "\n",
       "          6         7         8    ...           10        11        12  \\\n",
       "0  0.435635 -1.287651  0.709629    ...     0.043738  0.058232 -0.142471   \n",
       "1  0.706473 -1.452406  1.192144    ...     0.515025 -0.174743 -0.766355   \n",
       "2 -0.196430 -0.913378  0.359606    ...     0.815817  0.108854  0.296950   \n",
       "3 -0.167971 -0.270415  0.134538    ...     1.341069 -1.013491  0.150453   \n",
       "4 -1.685896  1.122334  0.098372    ...     0.672627 -0.647640  0.079995   \n",
       "\n",
       "         13        14        15        16        17        18        19  \n",
       "0 -0.552857 -0.047765 -0.955456  0.769690  0.263870 -1.241286  1.097445  \n",
       "1 -1.187277 -0.585611 -1.267406  0.484515  0.443640 -0.580105  0.786000  \n",
       "2 -0.859227 -0.025868 -0.795227  0.278938  0.539054 -0.520791 -0.234904  \n",
       "3 -1.014577  0.378935 -0.035479 -0.139811  0.141502  0.203001 -0.170075  \n",
       "4  1.259658 -1.086763 -1.020304 -0.737110  0.009530 -0.296795  0.750157  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df = pd.DataFrame.from_records(reduced)\n",
    "reduced_df.insert(0, column='trend', value=clean_data.trend)\n",
    "reduced_df['trend']=reduced_df['trend'].astype(np.int)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_df.iloc[:,1:], reduced_df['trend'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 89.99\n",
      "Accuracy score (test): 91.18\n"
     ]
    }
   ],
   "source": [
    "#lbfgs would not converge\n",
    "#For small datasets, â€˜liblinearâ€™ is a good choice, whereas â€˜sagâ€™ and â€˜sagaâ€™ are faster for large ones.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "log_model = logreg.fit(X_train, Y_train)\n",
    "\n",
    "log_Y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_log = round(logreg.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_log)\n",
    "print(\"Accuracy score (test):\",test_acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.60 | ROC Train Error: 0.40\n",
      "ROC Test Accuracy: 0.59 | ROC Test Error: 0.41\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.19      0.31        42\n",
      "           1       0.91      0.99      0.95       366\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       408\n",
      "   macro avg       0.86      0.59      0.63       408\n",
      "weighted avg       0.90      0.91      0.89       408\n",
      "\n",
      "F1: 0.9528795811518324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=logreg\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, log_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, log_Y_pred))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "log_f1 = f1_score(Y_test,log_Y_pred)\n",
    "\n",
    "print('F1:',log_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 30, 'n_neighbors': 10, 'p': 1}\n",
      "0.8956796628029505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_neighbors': [2, 5, 10, 50, 100],\n",
    "    'p' : [1, 2],\n",
    "    'leaf_size' :[30,50]\n",
    "}\n",
    "\n",
    "knn_CV = GridSearchCV(estimator=knn, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "knn_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(knn_CV.best_params_)\n",
    "print(knn_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 90.31\n",
      "Accuracy score (test): 89.95\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=30, n_neighbors=10, p=1) \n",
    "knn_model = knn.fit(X_train, Y_train)  \n",
    "knn_Y_pred = knn.predict(X_test)  \n",
    "\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_knn = round(knn.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_knn)\n",
    "print(\"Accuracy score (test):\",test_acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.62 | ROC Train Error: 0.38\n",
      "ROC Test Accuracy: 0.58 | ROC Test Error: 0.42\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.17      0.25        42\n",
      "           1       0.91      0.98      0.95       366\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       408\n",
      "   macro avg       0.72      0.58      0.60       408\n",
      "weighted avg       0.87      0.90      0.87       408\n",
      "\n",
      "F1: 0.9461235216819973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=knn\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, knn_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, knn_Y_pred))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "knn_f1 = f1_score(Y_test,knn_Y_pred)\n",
    "\n",
    "print('F1:',knn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 43.1\n",
      "Accuracy score (test): 32.6\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian_model = gaussian.fit(X_train, Y_train) \n",
    "\n",
    "gaussian_Y_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_gaussian = round(gaussian.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_gaussian)\n",
    "print(\"Accuracy score (test):\",test_acc_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.59 | ROC Train Error: 0.41\n",
      "ROC Test Accuracy: 0.54 | ROC Test Error: 0.46\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.81      0.20        42\n",
      "           1       0.93      0.27      0.42       366\n",
      "\n",
      "   micro avg       0.33      0.33      0.33       408\n",
      "   macro avg       0.52      0.54      0.31       408\n",
      "weighted avg       0.84      0.33      0.40       408\n",
      "\n",
      "F1: 0.4186046511627908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=gaussian\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, gaussian_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, gaussian_Y_pred))\n",
    "\n",
    "gaussian_f1 = f1_score(Y_test,gaussian_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',gaussian_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 91.04\n",
      "Accuracy score (test): 89.95\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "svc_model = svc.fit(X_train, Y_train)\n",
    "\n",
    "svc_Y_pred = svc.predict(X_test)\n",
    "\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_svc = round(svc.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_svc)\n",
    "print(\"Accuracy score (test):\",test_acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.64 | ROC Train Error: 0.36\n",
      "ROC Test Accuracy: 0.52 | ROC Test Error: 0.48\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.05      0.09        42\n",
      "           1       0.90      1.00      0.95       366\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       408\n",
      "   macro avg       0.78      0.52      0.52       408\n",
      "weighted avg       0.88      0.90      0.86       408\n",
      "\n",
      "F1: 0.9468223086900129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=svc\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, svc_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, svc_Y_pred))\n",
    "\n",
    "svc_f1 = f1_score(Y_test,svc_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',svc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 20}\n",
      "0.880927291886196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : depths,\n",
    "    'min_samples_leaf' :[1, 5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "decision_tree_CV = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv= 10, n_jobs=-1)\n",
    "decision_tree_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(decision_tree_CV.best_params_)\n",
    "print(decision_tree_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 89.15\n",
      "Accuracy score (test): 89.71\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=20) \n",
    "decision_tree_model = decision_tree.fit(X_train, Y_train)  \n",
    "decision_tree_Y_pred = decision_tree.predict(X_test)  \n",
    "\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_decision_tree = round(decision_tree.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_decision_tree)\n",
    "print(\"Accuracy score (test):\",test_acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.57 | ROC Train Error: 0.43\n",
      "ROC Test Accuracy: 0.54 | ROC Test Error: 0.46\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.16        42\n",
      "           1       0.91      0.99      0.95       366\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       408\n",
      "   macro avg       0.70      0.54      0.55       408\n",
      "weighted avg       0.86      0.90      0.86       408\n",
      "\n",
      "F1: 0.9451697127937337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=decision_tree\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, decision_tree_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, decision_tree_Y_pred))\n",
    "\n",
    "dt_f1 = f1_score(Y_test,decision_tree_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',dt_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 100.0\n",
      "Accuracy score (test): 83.58\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=decision_tree, n_estimators=180, random_state=1)\n",
    "ada_model = ada.fit(X_train, Y_train)\n",
    "\n",
    "ada_Y_pred = ada.predict(X_test)\n",
    "\n",
    "acc_ada = round(ada.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_ada = round(ada.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_ada)\n",
    "print(\"Accuracy score (test):\",test_acc_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 1.00 | ROC Train Error: 0.00\n",
      "ROC Test Accuracy: 0.59 | ROC Test Error: 0.41\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.29      0.26        42\n",
      "           1       0.92      0.90      0.91       366\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       408\n",
      "   macro avg       0.58      0.59      0.59       408\n",
      "weighted avg       0.85      0.84      0.84       408\n",
      "\n",
      "F1: 0.9075862068965518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=ada\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, ada_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, ada_Y_pred))\n",
    "\n",
    "ada_f1 = f1_score(Y_test,ada_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',ada_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 94.94\n",
      "Accuracy score (test): 87.99\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n",
    "    gt_model = gb.fit(X_train, Y_train)\n",
    "    \n",
    "    acc_gb = round(gb.score(X_train, Y_train) * 100, 2)\n",
    "    test_acc_gb = round(gb.score(X_test, Y_test) * 100, 2)\n",
    "    \n",
    "    gb_Y_pred = gb.predict(X_test)\n",
    "    \n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training):\",acc_gb)\n",
    "print(\"Accuracy score (test):\",test_acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.82 | ROC Train Error: 0.18\n",
      "ROC Test Accuracy: 0.61 | ROC Test Error: 0.39\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.26      0.31        42\n",
      "           1       0.92      0.95      0.93       366\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       408\n",
      "   macro avg       0.65      0.61      0.62       408\n",
      "weighted avg       0.86      0.88      0.87       408\n",
      "\n",
      "F1: 0.934228187919463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=gb\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, gb_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, gb_Y_pred))\n",
    "\n",
    "gb_f1 = f1_score(Y_test,gb_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 12, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.9020021074815595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : depths,\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "rf_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(rf_CV.best_params_)\n",
    "print(rf_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 99.79\n",
      "Accuracy score (test): 90.44\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini', max_depth=12, max_features='sqrt', n_estimators=100)\n",
    "random_forest_model = random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_random_forest = round(random_forest.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_random_forest)\n",
    "print(\"Accuracy score (test):\",test_acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.99 | ROC Train Error: 0.01\n",
      "ROC Test Accuracy: 0.57 | ROC Test Error: 0.43\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.14      0.24        42\n",
      "           1       0.91      0.99      0.95       366\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       408\n",
      "   macro avg       0.79      0.57      0.59       408\n",
      "weighted avg       0.88      0.90      0.88       408\n",
      "\n",
      "F1: 0.9490196078431372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=random_forest\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, random_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, random_Y_pred))\n",
    "\n",
    "rf_f1 = f1_score(Y_test,random_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "feature            \n",
       "0             0.087\n",
       "1             0.075\n",
       "17            0.074\n",
       "2             0.070\n",
       "10            0.068\n",
       "13            0.056\n",
       "4             0.055\n",
       "9             0.051\n",
       "8             0.044\n",
       "3             0.044\n",
       "5             0.043\n",
       "18            0.042\n",
       "19            0.041\n",
       "6             0.039\n",
       "7             0.039"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier()\n",
    "sgd.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'log', 'penalty': 'l2'}\n",
      "0.8977871443624869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Sasha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "sgd_CV = GridSearchCV(estimator=sgd, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "sgd_CV.fit(X_train, Y_train)\n",
    "\n",
    "print(sgd_CV.best_params_)\n",
    "print(sgd_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 90.41\n",
      "Accuracy score (test): 91.42\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier(loss='log', penalty='l2',max_iter=1000)\n",
    "sgd_model = sgd.fit(X_train, Y_train)\n",
    "sgd_Y_pred = sgd.predict(X_test)\n",
    "\n",
    "sgd.score(X_train, Y_train)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_sgd = round(sgd.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_sgd)\n",
    "print(\"Accuracy score (test):\",test_acc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.61 | ROC Train Error: 0.39\n",
      "ROC Test Accuracy: 0.59 | ROC Test Error: 0.41\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.19      0.31        42\n",
      "           1       0.91      1.00      0.95       366\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       408\n",
      "   macro avg       0.90      0.59      0.63       408\n",
      "weighted avg       0.91      0.91      0.89       408\n",
      "\n",
      "F1: 0.954248366013072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=sgd\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, sgd_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, sgd_Y_pred))\n",
    "\n",
    "sgd_f1 = f1_score(Y_test,sgd_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',sgd_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 87.67\n",
      "Accuracy score (test): 87.99\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(max_iter=5)\n",
    "perceptron_model = perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_Y_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "test_acc_perceptron = round(perceptron.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_perceptron)\n",
    "print(\"Accuracy score (test):\",test_acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.61 | ROC Train Error: 0.39\n",
      "ROC Test Accuracy: 0.56 | ROC Test Error: 0.44\n",
      "OVERFIT: True\n",
      "UNDERFIT: False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22        42\n",
      "           1       0.91      0.96      0.93       366\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       408\n",
      "   macro avg       0.62      0.56      0.58       408\n",
      "weighted avg       0.85      0.88      0.86       408\n",
      "\n",
      "F1: 0.9349269588313414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=perceptron\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = roc_auc_score(Y_train, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, perceptron_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, perceptron_Y_pred))\n",
    "\n",
    "perceptron_f1 = f1_score(Y_test,perceptron_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',perceptron_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91.42</th>\n",
       "      <td>Stochastic Gradient Descent (SGD)</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91.18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.44</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.95</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.95</th>\n",
       "      <td>Support Vector Classifier (SVC)</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.71</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.99</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.99</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83.58</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.60</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model    F1\n",
       "Score                                         \n",
       "91.42  Stochastic Gradient Descent (SGD)  0.95\n",
       "91.18                Logistic Regression  0.95\n",
       "90.44                      Random Forest  0.95\n",
       "89.95                K-Nearest Neighbors  0.95\n",
       "89.95    Support Vector Classifier (SVC)  0.95\n",
       "89.71                     Decision Trees  0.95\n",
       "87.99             Gradient Tree Boosting  0.93\n",
       "87.99                         Perceptron  0.93\n",
       "83.58                           AdaBoost  0.91\n",
       "32.60               Gaussian Naive Bayes  0.42"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression','K-Nearest Neighbors',\n",
    "             'Gaussian Naive Bayes','Support Vector Classifier (SVC)',\n",
    "             'Decision Trees','AdaBoost','Gradient Tree Boosting',\n",
    "             'Random Forest','Stochastic Gradient Descent (SGD)','Perceptron'],\n",
    "    'Score': [test_acc_log,\n",
    "              test_acc_knn,\n",
    "              test_acc_gaussian,\n",
    "              test_acc_svc,\n",
    "              test_acc_decision_tree,\n",
    "              test_acc_ada,\n",
    "              test_acc_gb,\n",
    "              test_acc_random_forest,\n",
    "              test_acc_sgd,\n",
    "              test_acc_perceptron],\n",
    "    'F1': [round(log_f1, 2),\n",
    "                round(knn_f1, 2),\n",
    "                round(gaussian_f1, 2),\n",
    "                round(svc_f1, 2),\n",
    "                round(dt_f1, 2),\n",
    "                round(ada_f1, 2),\n",
    "                round(gb_f1, 2),\n",
    "                round(rf_f1, 2),\n",
    "                round(sgd_f1, 2),\n",
    "                round(perceptron_f1, 2)\n",
    "                ]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to improve Random Forest w/ SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>Changes in Inventories</th>\n",
       "      <th>Common Stocks</th>\n",
       "      <th>...</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.330000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.350000e+08</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>13.680000</td>\n",
       "      <td>7005600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.175000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.630222e+08</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>24.629999</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>7166600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.768000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.169154e+08</td>\n",
       "      <td>53.900002</td>\n",
       "      <td>53.630001</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>10626000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.085000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.681299e+08</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>6788900.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.448000e+09</td>\n",
       "      <td>681000000.0</td>\n",
       "      <td>-5.400000e+07</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-4.910000e+08</td>\n",
       "      <td>3.671000e+09</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9.595000e+09</td>\n",
       "      <td>-56000000.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>52.990002</td>\n",
       "      <td>52.810001</td>\n",
       "      <td>52.360001</td>\n",
       "      <td>53.060001</td>\n",
       "      <td>3019700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accounts Payable  Accounts Receivable  Add'l income/expense items  \\\n",
       "0      3.068000e+09         -222000000.0               -1.961000e+09   \n",
       "1      4.975000e+09          -93000000.0               -2.723000e+09   \n",
       "2      4.668000e+09         -160000000.0               -1.500000e+08   \n",
       "3      5.102000e+09          352000000.0               -7.080000e+08   \n",
       "4      6.448000e+09          681000000.0               -5.400000e+07   \n",
       "\n",
       "   After Tax ROE  Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
       "0           23.0         -1.888000e+09     4.695000e+09        53.0   \n",
       "1           67.0         -3.114000e+09     1.059200e+10        75.0   \n",
       "2          143.0         -5.311000e+09     1.513500e+10        60.0   \n",
       "3          135.0         -6.151000e+09     1.159100e+10        51.0   \n",
       "4           92.0         -4.910000e+08     3.671000e+09       144.0   \n",
       "\n",
       "   Cash and Cash Equivalents  Changes in Inventories  Common Stocks  ...    \\\n",
       "0               1.330000e+09                     0.0    127000000.0  ...     \n",
       "1               2.175000e+09                     0.0      5000000.0  ...     \n",
       "2               1.768000e+09                     0.0      7000000.0  ...     \n",
       "3               1.085000e+09                     0.0      6000000.0  ...     \n",
       "4               9.595000e+09             -56000000.0     16000000.0  ...     \n",
       "\n",
       "   For Year  Estimated Shares Outstanding       open      close        low  \\\n",
       "0      2012                  3.350000e+08  12.850000  13.500000  12.840000   \n",
       "1      2013                  1.630222e+08  24.740000  25.250000  24.629999   \n",
       "2      2014                  7.169154e+08  53.900002  53.630001  53.320000   \n",
       "3      2015                  6.681299e+08  42.540001  42.349998  41.830002   \n",
       "4      2013                  1.600000e+09  52.990002  52.810001  52.360001   \n",
       "\n",
       "        high      volume  GICS Sector  GICS Sub Industry  trend  \n",
       "0  13.680000   7005600.0            5                  4    0.0  \n",
       "1  25.250000   7166600.0            5                  4    0.0  \n",
       "2  54.639999  10626000.0            5                  4    1.0  \n",
       "3  42.570000   6788900.0            5                  4    1.0  \n",
       "4  53.060001   3019700.0            4                 87    1.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data3=clean_data.copy()\n",
    "clean_data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(clean_data3.loc[:, clean_data3.columns != 'trend'], clean_data3['trend'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=45, ratio = .4)\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 18, 'n_estimators': 100}\n",
      "0.9853951890034365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth' : depths,\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "rf_CV.fit(x_train_res, y_train_res)\n",
    "\n",
    "print(rf_CV.best_params_)\n",
    "print(rf_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 97.51\n",
      "Accuracy score (test): 99.26\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='entropy', max_depth=18, max_features='auto', n_estimators=100)\n",
    "random_forest_model = random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(x_train_res, y_train_res)\n",
    "acc_random_forest = round(random_forest.score(x_train_res, y_train_res) * 100, 2)\n",
    "test_acc_random_forest = round(random_forest.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print(\"Accuracy score (training):\",acc_random_forest)\n",
    "print(\"Accuracy score (test):\",test_acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Train Accuracy: 0.96 | ROC Train Error: 0.04\n",
      "ROC Test Accuracy: 0.99 | ROC Test Error: 0.01\n",
      "OVERFIT: False\n",
      "UNDERFIT: True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96        42\n",
      "         1.0       1.00      0.99      1.00       366\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       408\n",
      "   macro avg       0.98      0.99      0.98       408\n",
      "weighted avg       0.99      0.99      0.99       408\n",
      "\n",
      "F1: 0.9958960328317372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "model=random_forest\n",
    "\n",
    "train_predictions = model.predict(x_train_res)\n",
    "\n",
    "train_accuracy = roc_auc_score(y_train_res, train_predictions)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "test_accuracy = roc_auc_score(Y_test, random_Y_pred)\n",
    "test_error_rate = 1 - test_accuracy\n",
    "print('ROC Train Accuracy: {:.2f} | ROC Train Error: {:.2f}'.format(train_accuracy, train_error_rate))\n",
    "print('ROC Test Accuracy: {:.2f} | ROC Test Error: {:.2f}'.format(test_accuracy, test_error_rate))\n",
    "\n",
    "#error test > error train => OVER FITTING of the data.\n",
    "#error test < error train => UNDER FITTING of the data\n",
    "\n",
    "print('OVERFIT:',test_error_rate > train_error_rate)\n",
    "print('UNDERFIT:',test_error_rate < train_error_rate)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, random_Y_pred))\n",
    "\n",
    "rf_f1 = f1_score(Y_test,random_Y_pred)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1:',rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.9681620209059233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n",
    "\n",
    "# cross-validation\n",
    "# cv = KFold(n_splits=3, shuffle=True) # shuffle and divide in 3 equal parts\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True) # KFold with 'stratify' option\n",
    "# # test_size is available in ShuffleSplit\n",
    "# cv = ShuffleSplit(n_splits=3, test_size=0.2)\n",
    "scores = cross_val_score(model, X_test, Y_test, cv=cv)\n",
    "print(\"Mean score:\", np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
