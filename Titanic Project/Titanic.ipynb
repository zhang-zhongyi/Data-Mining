{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hwk 3 - Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Troy Zhongyi Zhang   \n",
    "Netid: zhongyiz@uchicago.edu  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df1 = pd.read_csv(\"train.csv\", header = None)\n",
    "titanic = df1.drop([0, 3,8,9,10],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic\n",
    "#titanic.iloc[1,3] -> 0 -> str\n",
    "#titanic.iloc[6,3] -> Nan -> float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic = titanic.dropna(axis=0)\n",
    "#df['Embarked'] = df['Embarked'].fillna('S')\n",
    "#df['family'] = df['sbisp']+df['farch']\n",
    "#df = df.drop(['sibsp','parch'],axis=1)\n",
    "#test['Fare']=test['Fare'].fillna(test['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop titles\n",
    "titanic = titanic.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change age column data type from string to float\n",
    "titanic[5]=titanic[5].replace('',np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#type(titanic.iloc[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "titanic[5] = titanic[5].fillna((titanic[5].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.699117647058763\n"
     ]
    }
   ],
   "source": [
    "print(titanic[5].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check\n",
    "#print(titanic.iloc[45:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['3'] = pd.factorize(titanic[4])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['8'] = pd.factorize(titanic[11])[0]\n",
    "titanic = titanic.drop([11],axis=1)\n",
    "titanic = titanic.drop([4],axis=1)\n",
    "#print (titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita = titanic[[1,2,'3',5,6,7,'8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita.columns = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived Pclass  Sex        Age SibSp Parch  Embarked\n",
       "1          0      3    0  22.000000     1     0         0\n",
       "2          1      1    1  38.000000     1     0         1\n",
       "3          1      3    1  26.000000     0     0         0\n",
       "4          1      1    1  35.000000     1     0         0\n",
       "5          0      3    0  35.000000     0     0         0\n",
       "6          0      3    0  29.699118     0     0         2\n",
       "7          0      1    0  54.000000     0     0         0\n",
       "8          0      3    0   2.000000     3     1         0\n",
       "9          1      3    1  27.000000     0     2         0\n",
       "10         1      2    1  14.000000     1     0         1\n",
       "11         1      3    1   4.000000     1     1         0\n",
       "12         1      1    1  58.000000     0     0         0\n",
       "13         0      3    0  20.000000     0     0         0\n",
       "14         0      3    0  39.000000     1     5         0\n",
       "15         0      3    1  14.000000     0     0         0\n",
       "16         1      2    1  55.000000     0     0         0\n",
       "17         0      3    0   2.000000     4     1         2\n",
       "18         1      2    0  29.699118     0     0         0\n",
       "19         0      3    1  31.000000     1     0         0\n",
       "20         1      3    1  29.699118     0     0         1\n",
       "21         0      2    0  35.000000     0     0         0\n",
       "22         1      2    0  34.000000     0     0         0\n",
       "23         1      3    1  15.000000     0     0         2\n",
       "24         1      1    0  28.000000     0     0         0\n",
       "25         0      3    1   8.000000     3     1         0\n",
       "26         1      3    1  38.000000     1     5         0\n",
       "27         0      3    0  29.699118     0     0         1\n",
       "28         0      1    0  19.000000     3     2         0\n",
       "29         1      3    1  29.699118     0     0         2\n",
       "30         0      3    0  29.699118     0     0         0\n",
       "..       ...    ...  ...        ...   ...   ...       ...\n",
       "862        0      2    0  21.000000     1     0         0\n",
       "863        1      1    1  48.000000     0     0         0\n",
       "864        0      3    1  29.699118     8     2         0\n",
       "865        0      2    0  24.000000     0     0         0\n",
       "866        1      2    1  42.000000     0     0         0\n",
       "867        1      2    1  27.000000     1     0         1\n",
       "868        0      1    0  31.000000     0     0         0\n",
       "869        0      3    0  29.699118     0     0         0\n",
       "870        1      3    0   4.000000     1     1         0\n",
       "871        0      3    0  26.000000     0     0         0\n",
       "872        1      1    1  47.000000     1     1         0\n",
       "873        0      1    0  33.000000     0     0         0\n",
       "874        0      3    0  47.000000     0     0         0\n",
       "875        1      2    1  28.000000     1     0         1\n",
       "876        1      3    1  15.000000     0     0         1\n",
       "877        0      3    0  20.000000     0     0         0\n",
       "878        0      3    0  19.000000     0     0         0\n",
       "879        0      3    0  29.699118     0     0         0\n",
       "880        1      1    1  56.000000     0     1         1\n",
       "881        1      2    1  25.000000     0     1         0\n",
       "882        0      3    0  33.000000     0     0         0\n",
       "883        0      3    1  22.000000     0     0         0\n",
       "884        0      2    0  28.000000     0     0         0\n",
       "885        0      3    0  25.000000     0     0         0\n",
       "886        0      3    1  39.000000     0     5         2\n",
       "887        0      2    0  27.000000     0     0         0\n",
       "888        1      1    1  19.000000     0     0         0\n",
       "889        0      3    1  29.699118     1     2         0\n",
       "890        1      1    0  26.000000     0     0         1\n",
       "891        0      3    0  32.000000     0     0         2\n",
       "\n",
       "[889 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a23ed68d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(tita['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning holdout_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"holdout_test.csv\", header = None)\n",
    "test = df2.drop([1, 3,8,9,10],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived Pclass  Sex       Age SibSp Parch  Embarked\n",
       "1        NaN      3    0  34.50000     0     0         0\n",
       "2        NaN      3    1  47.00000     1     0         1\n",
       "3        NaN      2    0  62.00000     0     0         0\n",
       "4        NaN      3    0  27.00000     0     0         1\n",
       "5        NaN      3    1  22.00000     1     1         1\n",
       "6        NaN      3    0  14.00000     0     0         1\n",
       "7        NaN      3    1  30.00000     0     0         0\n",
       "8        NaN      2    0  26.00000     1     1         1\n",
       "9        NaN      3    1  18.00000     0     0         2\n",
       "10       NaN      3    0  21.00000     2     0         1\n",
       "11       NaN      3    0  30.27259     0     0         1\n",
       "12       NaN      1    0  46.00000     0     0         1\n",
       "13       NaN      1    1  23.00000     1     0         1\n",
       "14       NaN      2    0  63.00000     1     0         1\n",
       "15       NaN      1    1  47.00000     1     0         1\n",
       "16       NaN      2    1  24.00000     1     0         2\n",
       "17       NaN      2    0  35.00000     0     0         0\n",
       "18       NaN      3    0  21.00000     0     0         2\n",
       "19       NaN      3    1  27.00000     1     0         1\n",
       "20       NaN      3    1  45.00000     0     0         2\n",
       "21       NaN      1    0  55.00000     1     0         2\n",
       "22       NaN      3    0   9.00000     0     1         1\n",
       "23       NaN      1    1  30.27259     0     0         1\n",
       "24       NaN      1    0  21.00000     0     1         2\n",
       "25       NaN      1    1  48.00000     1     3         2\n",
       "26       NaN      3    0  50.00000     1     0         1\n",
       "27       NaN      1    1  22.00000     0     1         2\n",
       "28       NaN      3    0  22.50000     0     0         2\n",
       "29       NaN      1    0  41.00000     0     0         1\n",
       "30       NaN      3    0  30.27259     2     0         2\n",
       "..       ...    ...  ...       ...   ...   ...       ...\n",
       "389      NaN      3    0  21.00000     0     0         0\n",
       "390      NaN      3    0   6.00000     3     1         1\n",
       "391      NaN      1    0  23.00000     0     0         1\n",
       "392      NaN      1    1  51.00000     0     1         1\n",
       "393      NaN      3    0  13.00000     0     2         1\n",
       "394      NaN      2    0  47.00000     0     0         1\n",
       "395      NaN      3    0  29.00000     3     1         1\n",
       "396      NaN      1    1  18.00000     1     0         1\n",
       "397      NaN      3    0  24.00000     0     0         0\n",
       "398      NaN      1    1  48.00000     1     1         2\n",
       "399      NaN      3    0  22.00000     0     0         1\n",
       "400      NaN      3    0  31.00000     0     0         0\n",
       "401      NaN      1    1  30.00000     0     0         1\n",
       "402      NaN      2    0  38.00000     1     0         1\n",
       "403      NaN      1    1  22.00000     0     1         2\n",
       "404      NaN      1    0  17.00000     0     0         1\n",
       "405      NaN      1    0  43.00000     1     0         2\n",
       "406      NaN      2    0  20.00000     0     0         2\n",
       "407      NaN      2    0  23.00000     1     0         1\n",
       "408      NaN      1    0  50.00000     1     1         2\n",
       "409      NaN      3    1  30.27259     0     0         0\n",
       "410      NaN      3    1   3.00000     1     1         1\n",
       "411      NaN      3    1  30.27259     0     0         0\n",
       "412      NaN      1    1  37.00000     1     0         0\n",
       "413      NaN      3    1  28.00000     0     0         1\n",
       "414      NaN      3    0  30.27259     0     0         1\n",
       "415      NaN      1    1  39.00000     0     0         2\n",
       "416      NaN      3    0  38.50000     0     0         1\n",
       "417      NaN      3    0  30.27259     0     0         1\n",
       "418      NaN      3    0  30.27259     1     1         2\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop([0])\n",
    "test[5]=test[5].replace('',np.nan).astype(float)\n",
    "test[5] = test[5].fillna((test[5].mean()))\n",
    "#test = test.dropna(axis=0)\n",
    "test['3'] = pd.factorize(test[4])[0]\n",
    "test['8'] = pd.factorize(test[11])[0]\n",
    "test = test.drop([11],axis=1)\n",
    "test = test.drop([4],axis=1)\n",
    "#print (titanic)\n",
    "test = test[[0,2,'3',5,6,7,'8']]\n",
    "test.columns = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tita.iloc[:,0]\n",
    "x=tita.iloc[:,1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=0.11,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=3, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = cv.train_test_split(x, y, test_size=.20)\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_leaf=0.11,\n",
    "                           random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred_dt = dt.predict(x_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt = MSE(y_test, y_pred_dt)\n",
    "\n",
    "# Compute rmse_dt\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 0.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, x_train, y_train, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1) \n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.37\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(x_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)\n",
    "\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1) \n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth= 3 , min_samples_leaf= 0.26 , random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree training set accuracy score: 94.05 %\n",
      "Decision Tree testing set accuracy score: 79.78 %\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree_model = decision_tree.fit(X_train, y_train)  \n",
    "decision_tree_Y_pred = decision_tree.predict(X_test)  \n",
    "\n",
    "acc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\n",
    "acc_decision_tree_test = round(decision_tree.score(X_test, y_test) * 100, 2)\n",
    "print('Decision Tree training set accuracy score:',acc_decision_tree,'%')\n",
    "print('Decision Tree testing set accuracy score:',acc_decision_tree_test,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "y=tita.iloc[:,0]\n",
    "X=tita.iloc[:,1:7]\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y,\n",
    "test_size=0.3,\n",
    "random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 0.3843\n",
      "Train set RMSE of rf: 0.4154\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a random forests regressor 'rf' 400 estimators\n",
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "min_samples_leaf=0.16,\n",
    "random_state=SEED)\n",
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train=rf.predict(X_train)\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.4f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.4f}'.format(rmse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances_rf = pd.Series(rf.feature_importances_,\n",
    "index = X.columns)\n",
    "# Sort importances_rf\n",
    "sorted_importances_rf = importances_rf.sort_values()\n",
    "# Make a horizontal bar plot\n",
    "sorted_importances_rf.plot(kind='barh', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "min_samples_leaf=0.12,\n",
    "random_state=SEED)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.astype(float)\n",
    "y_pred_rf=y_pred.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.8786\n"
     ]
    }
   ],
   "source": [
    "#y_pred_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "rf_roc_auc = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.4f}'.format(rf_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training set accuracy score: 84.08 %\n",
      "Random Forest testing set accuracy score: 85.02 %\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=400,\n",
    "min_samples_leaf=0.011,\n",
    "random_state=SEED)\n",
    "random_forest_model = random_forest.fit(X_train, y_train)\n",
    "\n",
    "random_Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "acc_random_forest_test = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "print('Random Forest training set accuracy score:',acc_random_forest,'%')\n",
    "print('Random Forest testing set accuracy score:',acc_random_forest_test,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=140, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred = ada.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.astype(float)\n",
    "y_pred_ada=y_pred.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.8563\n"
     ]
    }
   ],
   "source": [
    "# Import roc_jauc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_ada)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.4f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training set accuracy score: 94.05 %\n",
      "Random Forest testing set accuracy score: 80.9 %\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=decision_tree, n_estimators=180, random_state=1)\n",
    "ada_model = ada.fit(X_train, y_train)\n",
    "\n",
    "ada_Y_pred = ada.predict(X_test)\n",
    "\n",
    "acc_ada = round(ada.score(X_train, y_train) * 100, 2)\n",
    "acc_ada_test = round(ada.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "print('Random Forest training set accuracy score:',acc_ada,'%')\n",
    "print('Random Forest testing set accuracy score:',acc_ada_test,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC training set accuracy score: 77.17 %\n",
      "SVC testing set accuracy score: 82.02 %\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "\n",
    "svc = SVC(kernel='linear', C=1)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, y_train) * 100, 2)\n",
    "print('SVC training set accuracy score:',acc_svc,'%')\n",
    "\n",
    "acc_svc_test = round(svc.score(X_test, y_test) * 100, 2)\n",
    "print('SVC testing set accuracy score:',acc_svc_test,'%')\n",
    "\n",
    "#X_test = X_test.astype(str)\n",
    "#y_test = y_test.astype(str)\n",
    "#y_pred_svc = y_pred.astype(float)\n",
    "#svc_roc_auc = roc_auc_score(y_test, y_pred_svc)\n",
    "\n",
    "#print('ROC AUC score: {:.4f}'.format(svc_roc_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD training set accuracy score: 74.6 %\n",
      "SGD testing set accuracy score: 76.78 %\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(max_iter=5, tol=None)\n",
    "sgd_model = sgd.fit(X_train, y_train)\n",
    "sgd_Y_pred = sgd.predict(X_test)\n",
    "y_pred = sgd_Y_pred\n",
    "sgd.score(X_train, y_train)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train, y_train) * 100, 2)\n",
    "print('SGD training set accuracy score:',acc_sgd,'%')\n",
    "\n",
    "acc_sgd_test = round(sgd.score(X_test, y_test) * 100, 2)\n",
    "print('SGD testing set accuracy score:',acc_sgd_test,'%')\n",
    "\n",
    "#y_test = y_test.astype(float)\n",
    "#y_pred = y_pred.astype(float)\n",
    "#sgd_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "#print('ROC AUC score: {:.4f}'.format(sgd_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score: 78.62 %\n",
      "Logistic regression testing set accuracy score: 83.9 %\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "log_model = logreg.fit(X_train, y_train)\n",
    "\n",
    "log_y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc_log = round(logreg.score(X_train, y_train) * 100, 2)\n",
    "acc_log_test = round(logreg.score(X_test, y_test) * 100, 2)\n",
    "print('Logistic regression training set accuracy score:',acc_log,'%')\n",
    "print('Logistic regression testing set accuracy score:',acc_log_test,'%')\n",
    "\n",
    "\n",
    "#y_test = y_test.astype(float)\n",
    "#y_pred = log_y_pred.astype(float)\n",
    "#lr_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "#print('ROC AUC score: {:.4f}'.format(lr_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nearest Neighbors training set accuracy score: 86.98 %\n",
      "K-nearest Neighbors testing set accuracy score: 76.4 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "knn_model = knn.fit(X_train, y_train)  \n",
    "knn_y_pred = knn.predict(X_test)  \n",
    "\n",
    "acc_knn = round(knn.score(X_train, y_train) * 100, 2)\n",
    "print('K-nearest Neighbors training set accuracy score:',acc_knn,'%')\n",
    "acc_knn_test = round(knn.score(X_test, y_test) * 100, 2)\n",
    "print('K-nearest Neighbors testing set accuracy score:',acc_knn_test,'%')\n",
    "\n",
    "#y_test = y_test.astype(float)\n",
    "#y_pred = knn_y_pred.astype(float)\n",
    "#knn_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "#print('ROC AUC score: {:.4f}'.format(knn_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes training set accuracy score: 78.3 %\n",
      "Gaussian Naive Bayes testing set accuracy score: 81.27 %\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian_model = gaussian.fit(X_train, y_train) \n",
    "\n",
    "gaussian_y_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "print('Gaussian Naive Bayes training set accuracy score:',acc_gaussian,'%')\n",
    "acc_gaussian_test = round(gaussian.score(X_test, y_test) * 100, 2)\n",
    "print('Gaussian Naive Bayes testing set accuracy score:',acc_gaussian_test,'%')\n",
    "\n",
    "#y_test = y_test.astype(float)\n",
    "#y_pred = gaussian_y_pred.astype(float)\n",
    "#gaussian_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "#testscore = round(gaussian.score(X_test, y_test) * 100, 2)\n",
    "#print(testscore)\n",
    "#print('ROC AUC score: {:.4f}'.format(gaussian_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores: \n",
      " Logistic Regression: 83.9 % \n",
      " Decision Tree: 79.78 % \n",
      " Random Forest: 85.02 % \n",
      " Ada boost: 80.9 % \n",
      " SVC: 82.02 % \n",
      " Stochastic Gradient Descent: 76.78 % \n",
      " K-nearest Neighbors: 76.4 % \n",
      " Gaussian Naive Bayes: 81.27 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Scores:', '\\n',\n",
    "'Logistic Regression:', round(acc_log_test,2), '%', '\\n',\n",
    "'Decision Tree:', round(acc_decision_tree_test,2), '%', '\\n',\n",
    "'Random Forest:', round(acc_random_forest_test,2), '%','\\n',\n",
    "'Ada boost:', round(acc_ada_test, 2), '%','\\n',\n",
    "'SVC:', round(acc_svc_test,2), '%','\\n',\n",
    "'Stochastic Gradient Descent:', round(acc_sgd_test,2), '%','\\n',\n",
    "'K-nearest Neighbors:', round(acc_knn_test,2), '%','\\n',\n",
    "'Gaussian Naive Bayes:', round(acc_gaussian_test,2), '%' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest gave me the highest accuracy score, which is over 85%. I will choose the random forest for my predictions. In logistic regression, SVC, Stochastic Gradient Descent, Gaussian Naive Bayes, and random forest models, the testing set accuracy score is higher than the training set accuracy score. In K-nearest neighbors, AdaBoost, and decision tree, the testing accuracy score is lower than the training accuracy score. If the CV RMSE is greater than training RMSE, my model will be overfitting, If CV error almost equal to my training error but they both greater than desired error, my model will be underfitting. With 80% and 20% training and testing set division, when Cross Validation = 10, my CV RMSE is 0.38, my Test set RMSE is 0.39, and Train set RMSE is 0.37. They are good, but I can make my model fits better. I tried 70% and 30% training and testing set division. In this case, my both CV RMSE and Train RMSE are 0.42. They are equal, which means my model is not overfitting. Finally, I choose the 0.7 and 0.3 division for my dataset in order to modeling work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 1 to 418\n",
      "Data columns (total 7 columns):\n",
      "Survived    0 non-null object\n",
      "Pclass      418 non-null object\n",
      "Sex         418 non-null int64\n",
      "Age         418 non-null float64\n",
      "SibSp       418 non-null object\n",
      "Parch       418 non-null object\n",
      "Embarked    418 non-null int64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 26.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '1' '0' '1' '1' '0' '0'\n",
      " '1' '1' '0' '1' '1' '0' '1' '0' '1' '0' '0' '0' '0' '0' '1' '1' '0' '0'\n",
      " '1' '1' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '1' '1' '1' '0' '1' '1'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '1' '0' '0' '0' '1' '0' '0'\n",
      " '1' '0' '1' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0' '1'\n",
      " '1' '0' '1' '0' '0' '0' '1' '0' '1' '0' '1' '0' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '1' '0' '1' '0' '0' '1' '0' '1' '1' '0' '1' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '1' '1' '0' '1' '0' '1'\n",
      " '1' '0' '0' '1' '0' '0' '1' '1' '0' '0' '0' '0' '0' '1' '1' '0' '1' '1'\n",
      " '0' '0' '1' '0' '1' '0' '1' '0' '0' '0' '0' '0' '1' '0' '1' '0' '1' '1'\n",
      " '0' '1' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '1' '0' '1' '0' '1' '1' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '1' '1' '1' '1' '0' '0' '0' '1' '1' '0' '1' '1' '1' '0'\n",
      " '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1' '1' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '1' '1' '0' '1' '1' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '1' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '1' '0' '1' '0' '1' '1' '0' '0' '0' '1' '0' '1' '0' '0' '1'\n",
      " '0' '1' '1' '0' '1' '0' '0' '1' '1' '0' '0' '1' '0' '0' '1' '1' '1' '0'\n",
      " '0' '0' '0' '0' '1' '1' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1'\n",
      " '0' '1' '0' '0' '1' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0' '1' '1' '0'\n",
      " '1' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "test = test.loc[:,test.columns != \"Survived\"]\n",
    "pred_test = random_forest.predict(test)\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"holdout_test.csv\", header = None)\n",
    "df3 = df3.drop([0])\n",
    "df3[0] = pred_test\n",
    "df3.columns = ['Survived','PassengerId','Survived','Pclass','Name','Sex','Age',\n",
    "               'SibSp','Parch','Ticke','Cabin','Embarked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('/Users/zhongyizhang/Desktop/Homework3_finalize/RandomForest_titanic_holdout_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
